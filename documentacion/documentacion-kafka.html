<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<meta name="author" content="v1.3.5 2020-11-30">
<title>Kafka: Instalación y operaciones</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body class="book">
<div id="header">
<h1>Kafka: Instalación y operaciones</h1>
<div class="details">
<span id="author" class="author">v1.3.5 2020-11-30</span><br>
</div>
<div id="toc" class="toc">
<div id="toctitle">Contenidos</div>
<ul class="sectlevel1">
<li><a href="#_introducción_a_kafka">1. Introducción a Kafka</a></li>
<li><a href="#_zookeeper">2. Zookeeper</a>
<ul class="sectlevel2">
<li><a href="#_introducción">2.1. Introducción</a></li>
<li><a href="#_instalación_de_zookeeper">2.2. Instalación de Zookeeper</a>
<ul class="sectlevel3">
<li><a href="#_sistemas_operativos">2.2.1. Sistemas operativos</a></li>
<li><a href="#_java">2.2.2. java</a></li>
<li><a href="#_producción">2.2.3. Producción</a></li>
<li><a href="#_lab_instalación_de_zookeeper">2.2.4. Lab: Instalación de Zookeeper</a></li>
</ul>
</li>
<li><a href="#_configuración">2.3. Configuración</a></li>
<li><a href="#_ejecución">2.4. Ejecución</a></li>
<li><a href="#_operaciones_de_zookeeper">2.5. Operaciones de Zookeeper</a>
<ul class="sectlevel3">
<li><a href="#_ejemplos">2.5.1. Ejemplos</a></li>
<li><a href="#_creación_del_grupo">2.5.2. Creación del grupo</a></li>
<li><a href="#_unirse_a_un_grupo">2.5.3. Unirse a un grupo</a></li>
<li><a href="#_encontrar_a_los_miembros_en_un_grupo">2.5.4. Encontrar a los miembros en un grupo</a></li>
<li><a href="#_eliminar_un_miembro">2.5.5. Eliminar un miembro</a></li>
<li><a href="#_eliminación_de_un_grupo">2.5.6. Eliminación de un grupo</a></li>
<li><a href="#_lab_operaciones_con_zookeeper">2.5.7. Lab: Operaciones con Zookeeper</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_instalación_de_kafka">3. Instalación de Kafka</a>
<ul class="sectlevel2">
<li><a href="#_lab_instalación_de_kafka">3.1. Lab: Instalación de kafka</a>
<ul class="sectlevel3">
<li><a href="#_instalación_de_software">3.1.1. Instalación de software</a></li>
<li><a href="#_puesta_en_marcha">3.1.2. Puesta en marcha</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_topics">4. Topics</a>
<ul class="sectlevel2">
<li><a href="#_lab_creación_de_topics_y_particionado">4.1. Lab: Creación de Topics y particionado</a>
<ul class="sectlevel3">
<li><a href="#_creación_de_topic">4.1.1. Creación de topic</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_productores_y_consumidores">5. Productores y consumidores</a>
<ul class="sectlevel2">
<li><a href="#_lab_produciendo_y_consumiendo">5.1. Lab: Produciendo y consumiendo</a></li>
</ul>
</li>
<li><a href="#_log_compaction">6. Log Compaction</a>
<ul class="sectlevel2">
<li><a href="#_configuración_2">6.1. Configuración</a></li>
<li><a href="#_tuning">6.2. Tuning</a>
<ul class="sectlevel3">
<li><a href="#_log_cleaner_dedupe_buffer_size">6.2.1. log.cleaner.dedupe.buffer.size</a></li>
<li><a href="#_log_cleaner_threads">6.2.2. log.cleaner.threads</a></li>
<li><a href="#_particiones">6.2.3. particiones</a></li>
<li><a href="#_min_cleanable_dirty_ratio">6.2.4. min.cleanable.dirty.ratio</a></li>
</ul>
</li>
<li><a href="#_lab_log_compaction">6.3. Lab: Log compaction</a></li>
</ul>
</li>
<li><a href="#_configuración_de_kafka">7. Configuración de kafka</a>
<ul class="sectlevel2">
<li><a href="#_configuración_del_broker">7.1. Configuración del Broker</a></li>
<li><a href="#_optimización">7.2. Optimización</a>
<ul class="sectlevel3">
<li><a href="#_message_max_bytes">7.2.1. message.max.bytes</a></li>
<li><a href="#_num_replica_fetchers">7.2.2. num.replica.fetchers</a></li>
<li><a href="#_replica_fetch_max_bytes">7.2.3. replica.fetch.max.bytes</a></li>
<li><a href="#_replica_socket_receive_buffer_bytes">7.2.4. replica.socket.receive.buffer.bytes</a></li>
<li><a href="#_num_partitions">7.2.5. num.partitions</a></li>
<li><a href="#_num_io_threads">7.2.6. num.io.threads</a></li>
<li><a href="#_num_recovery_threads_per_data_dir">7.2.7. num.recovery.threads.per.data.dir</a></li>
</ul>
</li>
<li><a href="#_lab_creación_de_un_clúster_multi_broker">7.3. Lab: Creación de un Clúster Multi-Broker</a></li>
<li><a href="#_configuración_del_topic">7.4. Configuración del Topic</a></li>
<li><a href="#_lab_configurar_particiones_y_réplicas">7.5. Lab: Configurar particiones y réplicas</a></li>
<li><a href="#_configuración_de_producers">7.6. Configuración de Producers</a></li>
<li><a href="#_configuración_de_consumers">7.7. Configuración de Consumers</a></li>
</ul>
</li>
<li><a href="#_operaciones_con_kafka">8. Operaciones con Kafka</a>
<ul class="sectlevel2">
<li><a href="#_utilidades_y_herramientas">8.1. Utilidades y herramientas</a>
<ul class="sectlevel3">
<li><a href="#_kafka_preferred_replica_election_sh_deprecada">8.1.1. kafka-preferred-replica-election.sh (deprecada)</a></li>
<li><a href="#_kafka_leader_election_sh">8.1.2. kafka-leader-election.sh</a></li>
<li><a href="#_kafka_mirror_maker_sh">8.1.3. kafka-mirror-maker.sh</a></li>
<li><a href="#_kafka_replay_log_producer_sh">8.1.4. kafka-replay-log-producer.sh</a></li>
<li><a href="#_kafka_replica_verification_sh">8.1.5. kafka-replica-verification.sh</a></li>
<li><a href="#_kafka_broker_api_versions_sh">8.1.6. kafka-broker-api-versions.sh</a></li>
<li><a href="#_kafka_consumer_groups_sh">8.1.7. kafka-consumer-groups.sh</a></li>
</ul>
</li>
<li><a href="#_lab_balanceando_las_particiones">8.2. Lab: Balanceando las particiones</a></li>
<li><a href="#_crecimiento_de_un_clúster">8.3. Crecimiento de un clúster</a></li>
<li><a href="#_lab_crecimiento_del_cluster">8.4. Lab: Crecimiento del cluster</a></li>
<li><a href="#_kafka_tools">8.5. Kafka Tools</a>
<ul class="sectlevel3">
<li><a href="#_clone">8.5.1. Clone</a></li>
<li><a href="#_trim">8.5.2. trim</a></li>
<li><a href="#_remove">8.5.3. remove</a></li>
<li><a href="#_elect">8.5.4. elect</a></li>
<li><a href="#_set_replication_factor">8.5.5. set-replication-factor</a></li>
<li><a href="#_reorder">8.5.6. reorder</a></li>
<li><a href="#_balance">8.5.7. balance</a></li>
</ul>
</li>
<li><a href="#_lab_usando_kafka_tools">8.6. Lab: Usando Kafka Tools</a></li>
</ul>
</li>
<li><a href="#_desarrollo_con_kafka">9. Desarrollo con kafka</a>
<ul class="sectlevel2">
<li><a href="#_implementación_kafka">9.1. Implementación kafka</a></li>
<li><a href="#_lenguaje_de_programación">9.2. Lenguaje De programación</a></li>
<li><a href="#_objetivo">9.3. Objetivo</a></li>
<li><a href="#_lab_instalación_del_entorno_de_desarrollo_de_kafka">9.4. Lab: Instalación del entorno de desarrollo de Kafka</a>
<ul class="sectlevel3">
<li><a href="#_ejecución_de_prueba">9.4.1. Ejecución de prueba</a></li>
<li><a href="#_preparación_de_proyecto_plantilla">9.4.2. Preparación de proyecto plantilla</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_kafka_java_api">10. Kafka Java API</a>
<ul class="sectlevel2">
<li><a href="#_dependencias">10.1. Dependencias</a></li>
<li><a href="#_api_para_producer">10.2. API para Producer</a></li>
<li><a href="#_api_para_consumer">10.3. API para Consumer</a></li>
<li><a href="#_garantía_de_entrega">10.4. Garantía de entrega</a>
<ul class="sectlevel3">
<li><a href="#_at_most_once">10.4.1. At most once</a></li>
<li><a href="#_at_least_once">10.4.2. At least once</a></li>
<li><a href="#_exactly_once">10.4.3. Exactly-once</a></li>
</ul>
</li>
<li><a href="#_lab_invocando_productores_y_consumidores">10.5. Lab: Invocando productores y consumidores</a>
<ul class="sectlevel3">
<li><a href="#_creación_de_topics">10.5.1. Creación de topics</a></li>
<li><a href="#_creación_de_productor">10.5.2. Creación de productor</a></li>
<li><a href="#_simple_consumer">10.5.3. Simple Consumer</a></li>
<li><a href="#_prueba_de_ejecución">10.5.4. Prueba de ejecución</a></li>
<li><a href="#_partitionproducer">10.5.5. PartitionProducer</a></li>
<li><a href="#_groups">10.5.6. Groups</a></li>
<li><a href="#_autocommit">10.5.7. Autocommit</a></li>
<li><a href="#_partitionconsumer">10.5.8. PartitionConsumer</a></li>
<li><a href="#_seekconsumer">10.5.9. SeekConsumer</a></li>
<li><a href="#_consumer_info">10.5.10. Consumer Info</a></li>
<li><a href="#_transaccionalidad">10.5.11. Transaccionalidad</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_esquemas_en_kafka">11. Esquemas en Kafka</a>
<ul class="sectlevel2">
<li><a href="#_tipos_de_serialización_en_kafka">11.1. Tipos de serialización en kafka</a>
<ul class="sectlevel3">
<li><a href="#_ejemplos_esquemas_idl">11.1.1. Ejemplos Esquemas-IDL</a></li>
</ul>
</li>
<li><a href="#_avro">11.2. Avro</a></li>
<li><a href="#_esquemas_de_avro">11.3. Esquemas de Avro</a></li>
<li><a href="#_tipos_de_datos">11.4. Tipos de datos</a>
<ul class="sectlevel3">
<li><a href="#_compactación">11.4.1. Compactación</a></li>
<li><a href="#_integración">11.4.2. Integración</a></li>
</ul>
</li>
<li><a href="#_esquemas_en_avro">11.5. Esquemas en Avro</a></li>
</ul>
</li>
<li><a href="#_schema_registry">12. Schema Registry</a>
<ul class="sectlevel2">
<li><a href="#_integración_de_datos">12.1. Integración de datos</a></li>
<li><a href="#_flujo_de_trabajo">12.2. Flujo de trabajo</a></li>
<li><a href="#_ejemplos_2">12.3. Ejemplos</a></li>
<li><a href="#_estrategias_de_nombres">12.4. Estrategias de nombres.</a></li>
</ul>
</li>
<li><a href="#_kafka_streams_api">13. Kafka Streams API</a>
<ul class="sectlevel2">
<li><a href="#_características">13.1. Características</a></li>
<li><a href="#_streams">13.2. Streams</a></li>
<li><a href="#_kstreams_y_ktables">13.3. KStreams y KTables</a>
<ul class="sectlevel3">
<li><a href="#_kstream">13.3.1. KStream</a></li>
<li><a href="#_ktable">13.3.2. KTable</a></li>
<li><a href="#_gobalktable">13.3.3. GobalKTable</a></li>
</ul>
</li>
<li><a href="#_ventanas_windows">13.4. Ventanas (Windows)</a></li>
<li><a href="#_transformaciones">13.5. Transformaciones</a>
<ul class="sectlevel3">
<li><a href="#_transformaciones_sin_estado">13.5.1. Transformaciones sin estado</a></li>
<li><a href="#_transformaciones_con_estado">13.5.2. Transformaciones con estado</a></li>
</ul>
</li>
<li><a href="#_salida_de_datos">13.6. Salida de datos</a></li>
<li><a href="#_estado_en_streams">13.7. Estado en Streams</a>
<ul class="sectlevel3">
<li><a href="#_transform_processor">13.7.1. Transform Processor</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_kafka_connect">14. Kafka Connect</a>
<ul class="sectlevel2">
<li><a href="#_tipos">14.1. Tipos</a></li>
<li><a href="#_modos_de_ejecución">14.2. Modos de ejecución</a></li>
<li><a href="#_replicator">14.3. Replicator</a>
<ul class="sectlevel3">
<li><a href="#_características_2">14.3.1. Características</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_monitorización_de_kafka">15. Monitorización de Kafka</a>
<ul class="sectlevel2">
<li><a href="#_métricas_de_los_brokers">15.1. Métricas de los Brokers</a>
<ul class="sectlevel3">
<li><a href="#_sistemas">15.1.1. Sistemas</a></li>
</ul>
</li>
<li><a href="#_métricas_de_los_consumidores_y_productores">15.2. Métricas de los Consumidores y Productores</a></li>
<li><a href="#_herramientas_java_para_monitorizar">15.3. Herramientas JAVA para monitorizar</a>
<ul class="sectlevel3">
<li><a href="#_gcviewer">15.3.1. GCViewer</a></li>
<li><a href="#_visualgc">15.3.2. visualgc</a></li>
<li><a href="#_jconsole">15.3.3. JConsole</a></li>
<li><a href="#_jvisualvm">15.3.4. JVisualVM</a></li>
<li><a href="#_jcmd">15.3.5. JCMD</a></li>
<li><a href="#_jmc">15.3.6. JMC</a></li>
</ul>
</li>
<li><a href="#_jmx_brokers">15.4. JMX - Brokers</a>
<ul class="sectlevel3">
<li><a href="#_jmx_mbean_kafka_servertypereplicamanager_underreplicatedpartitions">15.4.1. JMX MBean: kafka.server:type=ReplicaManager.UnderReplicatedPartitions</a></li>
<li><a href="#_jmx_mbean_kafka_controllertypekafkacontroller_offlinepartitionscount">15.4.2. JMX MBean: kafka.controller:type=KafkaController.OfflinePartitionsCount</a></li>
<li><a href="#_jmx_mbean_kafka_controllertypekafkacontroller_activecontrollercount">15.4.3. JMX MBean: kafka.controller:type=KafkaController.ActiveControllerCount*</a></li>
<li><a href="#_jmx_mbean_kafka_servertypebrokertopicmetrics_bytesinoutpersec">15.4.4. JMX MBean: kafka.server:type=BrokerTopicMetrics.Bytes[In,Out]PerSec</a></li>
<li><a href="#_jmx_mbean_kafka_servertypebrokertopicmetrics_messagesinpersec">15.4.5. JMX MBean: kafka.server:type=BrokerTopicMetrics.MessagesInPerSec</a></li>
<li><a href="#_jmx_mbean_kafka_servertypereplicamanager_partitionscount">15.4.6. JMX MBean: kafka.server:type=ReplicaManager.PartitionsCount</a></li>
<li><a href="#_jmx_mbean_kafka_servertypereplicamanager_leadercount">15.4.7. JMX MBean: kafka.server:type=ReplicaManager.LeaderCount</a></li>
<li><a href="#_jmx_mbean_kafka_networktyperequestmetrics_tipo_nombre">15.4.8. JMX MBean: kafka.network:type=RequestMetrics.[tipo].[nombre]</a></li>
<li><a href="#_topicnombre_topicpartitionparticion">15.4.9. &#8230;&#8203;,topic=[nombre_topic],partition=[particion]</a></li>
<li><a href="#_jmx_mbean_kafka_controllertypecontrollerstats_uncleanleaderelectionspersec">15.4.10. JMX MBean: kafka.controller:type=ControllerStats.UncleanLeaderElectionsPerSec</a></li>
</ul>
</li>
<li><a href="#_jmx_productores">15.5. JMX - Productores</a></li>
<li><a href="#_jmx_consumidores">15.6. JMX - Consumidores</a>
<ul class="sectlevel3">
<li><a href="#_jmx_mbeankafka_consumertypeconsumer_fetch_manager_metricsclient_idclient_idtopictopic_name">15.6.1. JMX MBean:kafka.consumer:type=consumer-fetch-manager-metrics,client-id=[client_id][,topic=&lt;topic_name]</a></li>
<li><a href="#_jmx_mbeankafka_consumertypeconsumer_coordinator_metricsclient_idclient_idtopictopic_name">15.6.2. JMX MBean:kafka.consumer:type=consumer-coordinator-metrics,client-id=[client_id][,topic=&lt;topic_name]</a></li>
<li><a href="#_lag">15.6.3. Lag</a></li>
<li><a href="#_cuotas">15.6.4. Cuotas</a></li>
</ul>
</li>
<li><a href="#_lab_monitorizacion">15.7. Lab: Monitorizacion</a>
<ul class="sectlevel3">
<li><a href="#_cmak">15.7.1. CMAK</a></li>
<li><a href="#_burrow">15.7.2. Burrow</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_seguridad_en_kafka">16. Seguridad en Kafka</a>
<ul class="sectlevel2">
<li><a href="#_cómo_funciona_la_seguridad">16.1. Cómo funciona la seguridad</a></li>
<li><a href="#_certificados_keystores_y_trustores">16.2. Certificados, Keystores y Trustores</a></li>
<li><a href="#_seguridad_en_clientes">16.3. Seguridad en clientes</a>
<ul class="sectlevel3">
<li><a href="#_sasl">16.3.1. SASL</a></li>
</ul>
</li>
<li><a href="#_autenticación_sasl">16.4. Autenticación SASL</a>
<ul class="sectlevel3">
<li><a href="#_sasl_plaintext">16.4.1. SASL PLAINTEXT</a></li>
<li><a href="#_sasl_scram">16.4.2. SASL SCRAM</a></li>
<li><a href="#_sasl_gssapi_kerberos">16.4.3. SASL GSSAPI (Kerberos)</a></li>
</ul>
</li>
<li><a href="#_autorización">16.5. Autorización</a>
<ul class="sectlevel3">
<li><a href="#_operaciones">16.5.1. Operaciones</a></li>
<li><a href="#_recursos">16.5.2. Recursos</a></li>
</ul>
</li>
<li><a href="#_lab_aplicando_seguridad_en_kafka">16.6. Lab: Aplicando seguridad en Kafka</a>
<ul class="sectlevel3">
<li><a href="#_creación_del_keystore_y_la_pareja_de_claves_públicaprivada">16.6.1. Creación del keystore y la pareja de claves pública/privada</a></li>
<li><a href="#_securizando_los_brokers">16.6.2. Securizando los Brokers</a></li>
<li><a href="#_securizando_los_clientes">16.6.3. Securizando los Clientes</a></li>
<li><a href="#_autenticar_clientes">16.6.4. Autenticar clientes</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_introducción_a_kafka">1. Introducción a Kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>Kafka</strong> es un sistema <strong>distribuido</strong> para el procesamiento de <strong>streams</strong>, escrito en <strong>Scala</strong> y <strong>Java</strong>.</p>
</li>
<li>
<p>El objetivo de <strong>Kafka</strong> es ofrecer una plataforma de baja latencia y alto rendimiento para gestionar feedings en tiempo real. Para ello, dispone de una capa de almacenamiento de tipo publicador/suscriptor altamente escalable (basado en transaction logs).</p>
</li>
<li>
<p><strong>Kafka</strong> permite conectar a múltiples sistemas para importar o exportar información, y ofrece un <strong>API</strong> de <strong>Java</strong> para procesar los streams.</p>
</li>
<li>
<p>Para usar <strong>Kafka</strong>, es imprescindible disponer de <strong>Zookeeper</strong>, ya que es vital para descubrir los <strong>brokers</strong>, y también para guardar la configuración a nivel de <strong>topic</strong></p>
</li>
<li>
<p><strong>Kafka</strong> es un proyecto desarrollado por <strong>LinkedIn</strong>.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-introduccion-01.png" alt="kafka introduccion 01" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En 2011, <strong>Kafka</strong> es liberado y se convierte en un proyecto de <strong>código abierto</strong>, gestionado por la <strong>Apache software foundation</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-introduccion-02.png" alt="kafka introduccion 02" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En noviembre de 2014, varios ingenieros que trabajaban desarrollando <strong>Kafka</strong> en <strong>LinkedIn</strong>, crearon una nueva compañía llamada <strong>Confluent</strong>, centrada en dicho proyecto.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-introduccion-03.png" alt="kafka introduccion 03" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El nombre del proyecto, se debe al escritor <strong>Franz Kafka</strong>, puesto que es un "sistema optimizado para escribir"</p>
</li>
<li>
<p><strong>Kafka</strong> está compuesto por tres tipos de componentes:</p>
<div class="ulist">
<ul>
<li>
<p><strong>Productores</strong></p>
</li>
<li>
<p><strong>Consumidores</strong></p>
</li>
<li>
<p><strong>Colas</strong> (o topics)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Kafka</strong> Puede usarse de dos formas:</p>
<div class="ulist">
<ul>
<li>
<p>Como un modelo de colas, donde los mensajes son distribuidos a los clientes</p>
</li>
<li>
<p>Como un modelo de publicador/suscriptor, donde el mismo mensaje es enviado a los distintos clientes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-introduccion-04.png" alt="kafka introduccion 04" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para ello, <strong>Kafka</strong> dispone de un <strong>Broker</strong>. Este es el servidor principal de <strong>Kafka</strong>, sus funciones son:</p>
<div class="ulist">
<ul>
<li>
<p>Almacena los distintos topics</p>
</li>
<li>
<p>Se encarga de gestionar las particiones</p>
</li>
<li>
<p>Se encarga de gestionar dónde se realizan las escrituras en disco</p>
</li>
<li>
<p>También controla la seguridad</p>
</li>
<li>
<p>Se utiliza para crear clústers y poder escalar el servicio (para ello, usa <strong>Zookeeper</strong>)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect1">
<h2 id="_zookeeper">2. Zookeeper</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_introducción">2.1. Introducción</h3>
<div class="ulist">
<ul>
<li>
<p>ZooKeeper es un servicio de coordinación distribuido para la construcción de aplicaciones distribuidas generales.</p>
</li>
<li>
<p>Escribir aplicaciones distribuidas es difícil. Es duro principalmente debido al fracaso parcial.</p>
</li>
<li>
<p>ZooKeeper no puede hacer que los fallos parciales desaparezcan, ya que son intrínsecos a los sistemas distribuidos.</p>
</li>
<li>
<p>Lo que hace ZooKeeper es proporcionar un grupo de herramientas para construir aplicaciones distribuidas que pueden manejar de forma segura
los fallos.</p>
</li>
<li>
<p>Características:</p>
<div class="ulist">
<ul>
<li>
<p><strong>Simple</strong>: es, en su núcleo, un sistema de archivos desnudo que expone algunas simples operaciones y algunas extraciones extra, tales como ordenaciones y notificaciones.</p>
</li>
<li>
<p><strong>Expresivo</strong>: las primitivas de ZooKeeper son un grupo rico de bloques de construcción que se pueden utilizar para construir una gran clase de estructuras de datos de coordinación y protocolos.
Por ejemplo se incluyen colas distribuidas, bloqueos distribuidas y elección de líderes entre un grupo de compañeros.</p>
</li>
<li>
<p><strong>Disponible</strong>: se ejecuta en una colección de máquinas y está diseñado para tener alta disponibilidad. Puede ayudarnos a evitar la introducción de puntos individuales de fallos en su sistema.</p>
</li>
<li>
<p><strong>Facilita las interacciones poco acopladas</strong>: las interacciones se apoyan en los participantes, que no necesitan saber unos de otros, utilizando un mecanismo de encuentro.</p>
</li>
<li>
<p><strong>Es una librería</strong>: que proporciona un repositorio compartido de implementaciones y recetas de código abierto y patrones comunes de coordinación. A los programadores individuales se les ahorra la carga de
escribiendo protocolos comunes ellos mismos.</p>
</li>
<li>
<p><strong>Es de alto rendimiento</strong>. En Yahoo!, donde se creó, el rendimiento de un grupo de ZooKeeper se ha comparado con más de 10.000 operaciones por segundo para escritura dominantes generadas por cientos de clientes.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_instalación_de_zookeeper">2.2. Instalación de Zookeeper</h3>
<div class="ulist">
<ul>
<li>
<p>Hay que tener en cuenta cuales son los requisitos de instalación de Zookeeper.</p>
</li>
<li>
<p>Se trata de una herramienta java, pero que debe instalarse en ciertos sistemas operativos.</p>
</li>
<li>
<p>Hay que tener en cuenta que tenemos cuatro componentes de instalación distintos:</p>
<div class="ulist">
<ul>
<li>
<p>Client: Se trata de las librerias java cliente, que permiten conectarse a Zookeeper</p>
</li>
<li>
<p>Server: Se trata del servicio java que se ejecuta en los nodos de Zookeeper</p>
</li>
<li>
<p>Native Client: Se trata de un cliente implementado en C que permite conectarse a Zookeeper</p>
</li>
<li>
<p>Contrib: Se trata de los add-ons opcionales de zookeeper.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para ver como instalarlo, debemos observar las limitaciones de sistemas operativos:</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_sistemas_operativos">2.2.1. Sistemas operativos</h4>
<div class="ulist">
<ul>
<li>
<p>Dependiendo si está orientado para desarrollo o producción, existen distintas opciones:</p>
<div class="ulist">
<ul>
<li>
<p>GNU/Linux: Sirve tanto para cliente, servidor, cliente nativo y addons en entornos de desarrollo y producción</p>
</li>
<li>
<p>Solaris, FreeBSD, Windows: Sirve para cliente y servidor en entornos de desarrollo y producción, sin embargo no está soportado el cliente nativo ni los addons de terceros</p>
</li>
<li>
<p>OSX: Solo sirve para cliente y servidor en modo desarrollo. No está soportado el cliente nativo ni los addons de terceros</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_java">2.2.2. java</h4>
<div class="ulist">
<ul>
<li>
<p>En cuanto a la versión de java, es imprescindible conocer que versión de java es compatible con Zookeeper.</p>
<div class="ulist">
<ul>
<li>
<p>Java 8 (OpenJDK, Oracle)como versión mínima</p>
</li>
<li>
<p>Java 11 OpenJDK LTS</p>
</li>
</ul>
</div>
</li>
<li>
<p>También es posible instalarlo en java 12 y 13, pero no en java 9 y 10</p>
</li>
<li>
<p>La recomendación es usar la última LTS compatible, que en este caso es la 11</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect3">
<h4 id="_producción">2.2.3. Producción</h4>
<div class="ulist">
<ul>
<li>
<p>Hay que tener en cuenta que zookeeper es la base de múltiples aplicaciones.</p>
</li>
<li>
<p>Kafka usa Zookeeper para los metadatos del cluster y es un sistema crítico.</p>
</li>
<li>
<p>En caso de perder Zookeeper, el mapa de las particiones asignadas a los brokers y las configuraciones de los topics se perderán, perdiendo la funcionalidad, y por ende, todos los datos.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_memoria">2.2.3.1. Memoria</h5>
<div class="ulist">
<ul>
<li>
<p>Un cluster de zookeeper no posee un uso intensivo de memoria. La memoria física necesaria escala según el número de znodes que posea.</p>
</li>
<li>
<p>A mayor número de particiones, mayor el uso de memoria de Zookeeper.</p>
</li>
<li>
<p>Un punto de partida sería los 4GB de ram para entornos de producción.</p>
</li>
<li>
<p>Se debe evitar el uso de SWAP en estos sistemas.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_cpu">2.2.3.2. CPU</h5>
<div class="ulist">
<ul>
<li>
<p>Zookeeper no posee un uso intensivo de cpu.</p>
</li>
<li>
<p>Si el sistema está compartido con otros servicios, es imprescindible la dedicación de una CPU a zookeeper, ya que es sensible a la latencia.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_discos">2.2.3.3. Discos</h5>
<div class="ulist">
<ul>
<li>
<p>Se recomienda el uso de SSDs para poseer baja latencia de escritura en disco con un tamaño de 64GB.</p>
</li>
<li>
<p>Cada petición en Zookeeper se debe almacenar en disco en cada servidor en el quorum antes de que esté disponible para lectura.</p>
</li>
<li>
<p>Para evitar mantenimientos es recomendable definir (para versiones superiores a la 3.4.0):</p>
<div class="ulist">
<ul>
<li>
<p><strong>autopurge.purgeInterval</strong>: Intervalo en horas para que la tarea de purga se dispare. Por defecto está deshabilitado</p>
</li>
<li>
<p><strong>autopurge.snapRetainCount</strong>: Permite definir el almacenamiento de los últimos snapshots y logs de transacciones en el directorio de datos. Por defecto es 3</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>autopurge.purgeInterval: 12
autopurge.snapRetainCount: 4</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>De esta forma conseguimos limpiar zookeeper y evitar mantenimientos costosos.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_máquina_virtual">2.2.3.4. Máquina virtual</h5>
<div class="ulist">
<ul>
<li>
<p>El uso del heap en Zookeeper no es intensivo, con 1GB debería ser suficiente, aunque se debe monitorizar para comprobar que las recolecciones de basura de la máquina virtual no pasan continuamente.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_alta_disponibilidad">2.2.3.5. Alta disponibilidad</h5>
<div class="ulist">
<ul>
<li>
<p>En un entorno de producción, los servidores de zookeeper deben desplegarse en múltiples nodos.</p>
<div class="ulist">
<ul>
<li>
<p>Los servidores deben estar en un conjunto de 2n+1, donde n debe ser 0 o más. Es decir, deben ser impares.</p>
</li>
<li>
<p>Permite poseer elecciones de mayoría en caso de la caida de n servidores.</p>
</li>
<li>
<p>Si queremos una tolerancia de dos servidores fallidos, debemos usar n=2:</p>
<div class="ulist">
<ul>
<li>
<p>2*2 + 1 = 5</p>
</li>
</ul>
</div>
</li>
<li>
<p>De esta forma mantendremos el sistema en alta disponibilidad.</p>
</li>
<li>
<p>Se suele comenzar con sistemas de tolerancia 1 o 2, con 3 o 5 instancias de servidor.</p>
</li>
<li>
<p>Hay que pensar que cuando se realiza una operación de escritura, se debe propagar y confirmar en todos los miembros.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Se recomienda poseer un sistema redundado de red y no alojarlo en el mismo rack</p>
</li>
<li>
<p>En caso de usar virtualización, es recomendable usar distintas zonas de disponibilidad</p>
</li>
<li>
<p>Ante la duda, es mejor comenzar con un sistema simple y controlado de tres nodos en producción y ampliarlo solo si es necesario.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect3">
<h4 id="_lab_instalación_de_zookeeper">2.2.4. Lab: Instalación de Zookeeper</h4>
<div class="ulist">
<ul>
<li>
<p>Para probar ZooKeeper, es más sencillo ejecutarlo en modo independiente con un solo servidor de ZooKeeper.</p>
</li>
<li>
<p>Podemos hacerlo en una máquina de desarrollo, por ejemplo.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_requisitos">2.2.4.1. Requisitos</h5>
<div class="ulist">
<ul>
<li>
<p>Java.</p>
</li>
<li>
<p>Descargar una versión estable de ZooKeeper de Apache ZooKeeper, y desempaquetar el tarball en un lugar adecuado (/usr/local/zookeeper o /opt/zookeeper):</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En nuestra máquina virtual, el software del curso se ha descargado en /home/kafka/Desktop/software</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_instalación">2.2.4.2. Instalación</h5>
<div class="ulist">
<ul>
<li>
<p>Para instalarlo, primero comprobamos que poseemos la versión de java correcta, ya que en sistema operativo, cumplimos las mejores condiciones con Linux.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Prueba de versión de java</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java -version
openjdk version &quot;11.0.8&quot; 2020-07-14 LTS
OpenJDK Runtime Environment 18.9 (build 11.0.8+10-LTS)
OpenJDK 64-Bit Server VM 18.9 (build 11.0.8+10-LTS, mixed mode, sharing)</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos comprobar como la versión de java es la 11</p>
</li>
<li>
<p>Ahora descomprimimos el software de kafka en /opt</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Comandos de instalación de zookeeper</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cd Desktop/software/
[kafka@kafka-server software]$ tar xf apache-zookeeper-*-bin.tar.gz
[kafka@kafka-server software]$ sudo mv apache-zookeeper-*-bin /opt/apache-zookeeper</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Añadimos las variables de entorno al sistema para facilitar su uso:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Creación de variables de inicio para todos los usuarios</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ echo export ZOOKEEPER_HOME=/opt/apache-zookeeper &gt;&gt; zookeeper_path.sh
[kafka@kafka-server software]$ echo 'export PATH=${PATH}:${ZOOKEEPER_HOME}/bin' &gt;&gt; zookeeper_path.sh
[kafka@kafka-server software]$ sudo mv zookeeper_path.sh /etc/profile.d/
[kafka@kafka-server software]$ sudo chmod ugo+x /etc/profile.d/zookeeper_path.sh</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por último, para evitar tener que reiniciar el entorno gráfico para aplicar las variables lanzamos la siguiente sentencia</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Creación de variables de inicio para todos los usuarios</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ source /etc/profile.d/zookeeper_path.sh</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Fin del laboratorio</p>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_configuración">2.3. Configuración</h3>
<div class="paragraph">
<p>Los archivos de configuración se llama convencionalmente <strong>zoo.cfg</strong> y se coloca en el subdirectorio <strong>conf</strong>
(normalmente se colocar en <strong>/etc/zookeeper</strong>, o en el directorio definido por la variable <strong>ZOOCFGDIR</strong>, si se establece).</p>
</div>
<div class="listingblock">
<div class="title">Ejemplo de variables de zoo.conf</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">tickTime=2000
dataDir=/disk1/zookeeper
dataLogDir=/disk2/zookeeper
clientPort=2181
initLimit=5
syncLimit=2
server.1=zookeeper1:2888:3888
server.2=zookeeper2:2888:3888
server.3=zookeeper3:2888:3888
maxClientCnxns=0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Es un archivo de propiedades estándar de Java, y las tres propiedades siguientes son las minimas requeridas para ZooKeeper:</p>
<div class="ulist">
<ul>
<li>
<p><strong>tickTime</strong> : es la unidad de tiempo básica en ZooKeeper (especificada en milisegundos). Se usa para los heartbeats, la sesión mínima es dos veces el tickTime</p>
</li>
<li>
<p><strong>dataDir</strong> : es la ubicación local del sistema de archivos donde ZooKeeper almacena datos persistentes</p>
</li>
<li>
<p><strong>clientPort</strong> : es el puerto donde escucha las conexiones del cliente (2181 es una opción común).</p>
</li>
</ul>
</div>
</li>
<li>
<p>Cada servidor del grupo de servidores de ZooKeeper tiene un identificador numérico que es único
dentro del grupo y debe estar comprendido entre 1 y 255.</p>
</li>
<li>
<p>El número de servidor se especifica en <strong>texto sin formato</strong> en un archivo denominado <strong>myid</strong> en el directorio especificado por la propiedad <strong>dataDir</strong>.</p>
</li>
<li>
<p>También necesitamos dar a todos los servidores las identidades y ubicaciones de red de los demás servidores pertenecientes al grupo.</p>
</li>
<li>
<p>En Zookeeper, el archivo de configuración debe incluir una línea para cada servidor:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Formato</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">server.n = hostname:port:port</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El valor de <strong>n</strong> se sustituye por el <strong>número de servidor</strong>.</p>
</li>
<li>
<p>Hay dos configuraciones para los puertos:</p>
<div class="ulist">
<ul>
<li>
<p><strong>puerto que los seguidores</strong> utilizan para <strong>conectar con el líder</strong></p>
</li>
<li>
<p><strong>puerto para la elección del líder</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Los servidores escuchan en tres puertos:</p>
<div class="ulist">
<ul>
<li>
<p>El <strong>2181</strong> para conexiones de cliente;</p>
</li>
<li>
<p>El <strong>2888</strong> para conexiones seguidoras, si ellos son el líder;</p>
</li>
<li>
<p>El <strong>3888</strong> para otras conexiones de servidor durante la fase de elección de líder.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Cuando un servidor ZooKeeper se inicia, lee el archivo <strong>myid</strong> para determinar qué tipo de servidor es,
y luego lee el <strong>archivo de configuración</strong> para determinar los puertos que debe escuchar y descubrir las direcciones de red de los otros servidores del grupo.</p>
</li>
<li>
<p>Los clientes que se conecten a este grupo ZooKeeper deben usar</p>
<div class="ulist">
<ul>
<li>
<p>Zookeeper1: 2181</p>
</li>
<li>
<p>Zookeeper2: 2181</p>
</li>
<li>
<p>Zookeeper3: 2181</p>
</li>
</ul>
</div>
</li>
<li>
<p>Es similar a la cadena del host en el constructor para el objeto ZooKeeper.</p>
</li>
<li>
<p>En el grupo de replica (<strong>replicaSet</strong>), <strong>hay dos propiedades obligatorias adicionales</strong>:</p>
<div class="ulist">
<ul>
<li>
<p><strong>initLimit</strong></p>
</li>
<li>
<p><strong>syncLimit</strong></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Medidas múltiples de tickTime</strong>.</p>
<div class="ulist">
<ul>
<li>
<p><strong>InitLimit</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cantidad de tiempo que permite a los seguidores conectarse y sincronizarse con el
líder.</p>
</li>
<li>
<p>Si la mayoría de seguidores no sincronizan dentro de este período, el líder renuncia a su
liderazgo y otra elección de líder tiene lugar.</p>
</li>
<li>
<p>Si esto ocurre a menudo (se puede ver en el registro), es un signo de que la <strong>configuración es demasiado baja</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>SyncLimit</strong> es la cantidad de tiempo que permite a un seguidor sincronizar con el líder.</p>
<div class="ulist">
<ul>
<li>
<p>Si un seguidor no se sincroniza dentro de este período, se reiniciará.</p>
</li>
<li>
<p>Los clientes que estuvieron vinculados a este seguidor se conectarán a otro.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>La siguiente directiva se recomienda definir para evitar rechazos de conexión de zookeeper cuando el cluster crece:</p>
</li>
<li>
<p><strong>maxClientCnxns</strong>: Indica el número máximo de clientes que podemos tener. Por defecto son 60, es recomendable poner infinito.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>maxClientCnxns=0</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_ejecución">2.4. Ejecución</h3>
<div class="ulist">
<ul>
<li>
<p>Para ejecutarlo, solo necesitamos usar el siguiente comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start</code></pre>
</div>
</div>
<div class="paragraph">
<p>o bien:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Ejecución para la versión 3.4.14, para otras, hay que cambiar las versiones de paquetes</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>[kafka@kafka-server zookeeper-3.4.14]$ java -cp zookeeper-3.4.14.jar:lib/slf4j-a.25.jar:lib/slf4j-log4j12-1.7.25.jar:lib/log4j-1.2.17.jar:conf org.apache.zookeeper.server.quorum.QuorumPeerMain conf/zoo.cfg</pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para comprobar si ZooKeeper se está ejecutando, ejecutamos comando ruok ("¿Está bien?") al puerto cliente utilizando <strong>nc</strong> (telnet también funciona):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ echo ruok| nc localhost 2181
imok</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>ZooKeeper nos indica, "Estoy bien".</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_operaciones_de_zookeeper">2.5. Operaciones de Zookeeper</h3>
<div class="ulist">
<ul>
<li>
<p>Aquí podemos observar el listado de comandos que podemos ejecutar en Zookeeper</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/zookeeper-operaciones-01.png" alt="zookeeper operaciones 01" width="600">
</div>
<div class="title">Figure 1. Listado de operaciones</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Además del comando <strong>mntr</strong>, ZooKeeper expone estadísticas a través de JMX.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En la documentación de zookeeper explica como se exponen las estadísticas JMX</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Tenemos las herramientas de monitorización y recipientes en <strong>src/contrib</strong> de la distribución.</p>
</li>
<li>
<p>Desde la versión 3.5.0 de ZooKeeper, hay un servidor web incorporado para proporcionar la misma información, en <strong><a href="http://localhost:8080/commands" class="bare">http://localhost:8080/commands</a></strong> para obtener una lista de los comandos de la versión.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_ejemplos">2.5.1. Ejemplos</h4>
<div class="ulist">
<ul>
<li>
<p>Imaginemos un grupo de servidores que proporcionan algún servicio a los clientes.</p>
</li>
<li>
<p>Queremos:</p>
<div class="ulist">
<ul>
<li>
<p>Que los clientes puedan localizar a uno de los servidores para que puedan utilizar el servicio y mantener la lista de servidores perteneciente al grupo.</p>
</li>
<li>
<p>La lista de miembros no puede almacenarse en un solo nodo de la red, ya que un fallo de ese nodo significaría la caida de todo el sistema (<strong>alta disponibilidad</strong>).</p>
</li>
<li>
<p>¿Como eliminamos un servidor de la lista del grupo si falla?. Algunos procesos deben ser los responsables de la eliminación de servidores caidos, pero no pueden ser los servidores, ya que no están en ejecución!</p>
</li>
</ul>
</div>
</li>
<li>
<p>En definitiva es una <strong>estructura de datos distribuida activa</strong>, y puede cambiar su estado con una entrada cuando se produce algún evento externo.</p>
</li>
<li>
<p>ZooKeeper nos proporciona este servicio.</p>
</li>
<li>
<p><strong>Pertenencia al grupo en ZooKeeper</strong></p>
<div class="ulist">
<ul>
<li>
<p>Pensemos que ZooKeeper proporciona un sistema de archivos con una alta disponibilidad.</p>
</li>
<li>
<p>No tiene archivos y directorios, sino un concepto unificado de un <strong>nodo</strong>, llamado
<strong>znode</strong>, que actúa tanto como un contenedor de datos (como un archivo) y un contenedor de otros <strong>znodes</strong> (como un directorio).</p>
</li>
<li>
<p>Los <strong>znodes</strong> forman un espacio de nombres jerárquico, y la de crear la lista de miembros es un <strong>znode padre</strong> con el nombre del grupo y <strong>znodes secundarios</strong> con los nombres de los miembros del grupo (servidores).</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/zookeeper-operaciones-02.png" alt="zookeeper operaciones 02" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En una aplicación real debemos imaginarnos el almacenamiento de datos sobre los miembros, como nombres de host, con sus <strong>znodes</strong>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_creación_del_grupo">2.5.2. Creación del grupo</h4>
<div class="ulist">
<ul>
<li>
<p>Vemos mediante el API JavaKeeper de Java la escritura de un programa para <strong>crear un znode</strong> de ejemplo</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">java.io.IOException</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.CountDownLatch</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.CreateMode</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.KeeperException</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.WatchedEvent</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.Watcher</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.Watcher.Event.KeeperState</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.ZooDefs.Ids</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.ZooKeeper</span>;

<span class="directive">public</span>        <span class="type">class</span> <span class="class">CreateGroup</span>        <span class="directive">implements</span>        Watcher        {

                <span class="directive">private</span>        <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> SESSION_TIMEOUT = <span class="integer">5000</span>;
                <span class="directive">private</span>        ZooKeeper zk;
                <span class="directive">private</span>        <span class="predefined-type">CountDownLatch</span>        connectedSignal        = <span class="keyword">new</span> <span class="predefined-type">CountDownLatch</span>(<span class="integer">1</span>);

                <span class="directive">public</span> <span class="type">void</span> connect(<span class="predefined-type">String</span> hosts) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span>        {
                                zk        = <span class="keyword">new</span> ZooKeeper(hosts, SESSION_TIMEOUT,        <span class="local-variable">this</span>);
                                connectedSignal.await();
                }

                <span class="annotation">@Override</span>
                <span class="directive">public</span> <span class="type">void</span> process(WatchedEvent event)        { <span class="comment">//        Interfaz observadora</span>
                                <span class="keyword">if</span>        (event.getState()        ==        KeeperState.SyncConnected)        {
                                                connectedSignal.countDown();
                                }
                }

                <span class="directive">public</span> <span class="type">void</span>        create(<span class="predefined-type">String</span> groupName) <span class="directive">throws</span>        KeeperException,
                                                <span class="exception">InterruptedException</span> {
                                <span class="predefined-type">String</span>        path = <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + groupName;
                                <span class="predefined-type">String</span>        createdPath        = zk.create(path, <span class="predefined-constant">null</span><span class="comment">/*data*/</span>,        Ids.OPEN_ACL_UNSAFE,
                                                                CreateMode.PERSISTENT);
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Created        </span><span class="delimiter">&quot;</span></span> +        createdPath);
                }

                <span class="directive">public</span> <span class="type">void</span> close() <span class="directive">throws</span>        <span class="exception">InterruptedException</span>        {
                                zk.close();
                }
                <span class="directive">public</span>        <span class="directive">static</span>        <span class="type">void</span>        main(<span class="predefined-type">String</span><span class="type">[]</span>        args)        <span class="directive">throws</span>        <span class="exception">Exception</span>        {
                                CreateGroup        createGroup        =        <span class="keyword">new</span>        CreateGroup();
                                createGroup.connect(args[<span class="integer">0</span>]);
                                createGroup.create(args[<span class="integer">1</span>]);
                                createGroup.close();
                }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando se ejecuta el método <strong>main()</strong>, se crea una instancia de <strong>CreateGroup</strong> y luego llama al método <strong>Connect()</strong> que instancia un nuevo <strong>objeto ZooKeeper</strong>, que es el objeto principal del cliente y la que <strong>mantiene la conexión entre el cliente y el servicio ZooKeeper</strong>.</p>
</li>
<li>
<p>El constructor toma <strong>3 argumentos</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Dirección del host (y opcionalmente su puerto 2181) del servicio ZooKeeper</p>
</li>
<li>
<p>Tiempo de espera de la sesión en milisegundos (establecido a 5 segundos)</p>
</li>
<li>
<p>Una instancia de un objeto <strong>Watcher</strong> (observador).</p>
</li>
<li>
<p>El objeto Watcher recibe devoluciones de llamada de ZooKeeper para informarle de varios eventos.</p>
</li>
</ul>
</div>
</li>
<li>
<p>En este escenario, <strong>CreateGroup</strong> es un <strong>Watcher</strong>, así que pasamos esto al <strong>constructor</strong> de ZooKeeper.</p>
</li>
<li>
<p>Cuando se crea una instancia de ZooKeeper, <strong>se inicia un subproceso para conectarse al servicio ZooKeeper</strong>.</p>
</li>
<li>
<p>La llamada al constructor debe volver de inmediato, por lo que es importante esperar la conexión antes de utilizar el objeto ZooKeeper.</p>
</li>
<li>
<p>Se hace uso de Java <strong>CountDownLatch</strong> (del paquete <strong>java.util.concurrent</strong>) para el <strong>bloqueo</strong> hasta que la instancia de ZooKeeper está lista.</p>
</li>
<li>
<p>Aquí es donde entra el <strong>Watcher</strong>.</p>
</li>
<li>
<p>La interfaz <strong>Watcher</strong> tiene un solo método:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">void</span> process(evento WatchedEvent);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando el cliente se ha conectado al servidor de ZooKeeper, el <strong>watcher</strong> recibe una llamada a su método <strong>process()</strong> con un evento que indica que se ha conectado.</p>
</li>
<li>
<p>Al recibir un evento de conexión (representado por <strong>enum Watcher.Event.KeeperState</strong>, con el valor <strong>SyncConnected</strong>), nosotros decrementamos el contador en <strong>CountDownLatch</strong>, utilizando su método <strong>countDown()</strong>.</p>
</li>
<li>
<p>El <strong>CountDownLatch</strong> (cerrojo) se creó con un recuento a 1, que representa el número de eventos que deben ocurrir antes de que libere todos los hilos en espera.</p>
</li>
<li>
<p>Después de llamar a <strong>countDown()</strong> una vez, el contador alcanzará 0 y devuelve el <strong>método await()</strong>.</p>
</li>
<li>
<p>El método <strong>connect()</strong> ahora ha regresado, y el método siguiente a ser invocado es el método <strong>create()</strong> en la instancia de ZooKeeper.</p>
</li>
<li>
<p>Los argumentos que toma son:</p>
<div class="ulist">
<ul>
<li>
<p>El camino (representado por una cadena recibida en arg[1])</p>
</li>
<li>
<p>Contenido del znode (una matriz de bytes nula en este caso)</p>
</li>
<li>
<p>Un acceso a la lista de control (o ACL para abreviar, que aquí está completamente abierta, permitiendo que cualquier cliente las lea o escriba en el znode)</p>
</li>
<li>
<p>Naturaleza del znode que se va a crear: efímeros, <strong>ephemeral</strong> o persistentes, <strong>persistent</strong>.</p>
</li>
<li>
<p>Un <strong>znode efímero</strong> será borrado por el servicio de ZooKeeper cuando el cliente que lo creó se desconecta, explícitamente o porque el cliente lo termina por cualquier razón.</p>
</li>
<li>
<p>Un <strong>znode persistent</strong>, por otro lado, <strong>NO</strong> es eliminado cuando el cliente se desconecta ya que queremos que vida más tiempo el znode que representa que la vida del programa que lo crea.</p>
</li>
</ul>
</div>
</li>
<li>
<p>El valor de retorno del método <strong>create()</strong> es la camino creado por ZooKeeper.</p>
</li>
<li>
<p>Lo imprimirmos como mensaje de que la ruta de acceso se creó correctamente.</p>
</li>
<li>
<p>Notaremos cómo el camino devuelta por create() puede diferir del pasado al método cuando vemos znodes secuenciales.</p>
</li>
<li>
<p>Para ver el programa en acción, necesitamos tener ZooKeeper corriendo en la máquina local, y ejecutamos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ export CLASSPATH=/home/kafka/Desktop/software/libs/*:$ZOOKEEPER_HOME/*:\ $ZOOKEEPER_HOME/lib/*:$ZOOKEEPER_HOME/conf
[kafka@kafka-server ~]$ java com.kafka.zookeeper.CreateGroup localhost zoo</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_unirse_a_un_grupo">2.5.3. Unirse a un grupo</h4>
<div class="ulist">
<ul>
<li>
<p>Una vez creado el Grupo necesitamos registrar a un miembro en el grupo.</p>
</li>
<li>
<p><strong>Cada miembro se ejecutará como un programa y se unirá al grupo</strong>.</p>
</li>
<li>
<p>Cuando el programa salga, debe ser eliminado del grupo, creandolo como <strong>znode efímero</strong> en el espacio de nombres de ZooKeeper.</p>
</li>
<li>
<p>El programa <strong>JoinGroup</strong> implementa esta idea:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">JoinGroup.java</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.CreateMode</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.KeeperException</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.ZooDefs.Ids</span>;

<span class="directive">public</span>        <span class="type">class</span>        <span class="class">JoinGroup</span>        <span class="directive">extends</span>        ConnectionWatcher        {

                <span class="directive">public</span> <span class="type">void</span>        join(<span class="predefined-type">String</span>        groupName, <span class="predefined-type">String</span> memberName) <span class="directive">throws</span> KeeperException,
                                                <span class="exception">InterruptedException</span>        {
                                <span class="predefined-type">String</span>        path = <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + groupName + <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + memberName;
                                <span class="predefined-type">String</span>        createdPath        = zk.create(path,        <span class="predefined-constant">null</span><span class="comment">/*data*/</span>, Ids.OPEN_ACL_UNSAFE,
                                                CreateMode.EPHEMERAL);
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Created        </span><span class="delimiter">&quot;</span></span> +        createdPath);
                }

                <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">Exception</span>        {
                                JoinGroup joinGroup        = <span class="keyword">new</span> JoinGroup();
                                joinGroup.connect(args[<span class="integer">0</span>]);
                                joinGroup.join(args[<span class="integer">1</span>],        args[<span class="integer">2</span>]);

                                <span class="comment">//        Se mantiene durmiendo hasta que el proceso sea matado o interrumpido el hilo de ejecuciión</span>
                                <span class="predefined-type">Thread</span>.sleep(<span class="predefined-type">Long</span>.MAX_VALUE);
                }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La lógica para crear y conectarse ha sido refactorizada en <strong>ConnectionWatcher</strong> :</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">ConnectionWatcher.java</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">java.io.IOException</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.CountDownLatch</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.WatchedEvent</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.Watcher</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.Watcher.Event.KeeperState</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.ZooKeeper</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ConnectionWatcher</span> <span class="directive">implements</span> Watcher {

                <span class="directive">private</span>        <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> SESSION_TIMEOUT = <span class="integer">5000</span>;
                <span class="directive">protected</span> ZooKeeper zk;
                <span class="directive">private</span>        <span class="predefined-type">CountDownLatch</span>        connectedSignal        = <span class="keyword">new</span> <span class="predefined-type">CountDownLatch</span>(<span class="integer">1</span>);
                <span class="directive">public</span>        <span class="type">void</span> connect(<span class="predefined-type">String</span>        hosts) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span>        {
                                zk = <span class="keyword">new</span> ZooKeeper(hosts, SESSION_TIMEOUT, <span class="local-variable">this</span>);
                                connectedSignal.await();
                }

                <span class="annotation">@Override</span>
                <span class="directive">public</span> <span class="type">void</span>        process(WatchedEvent event)        {
                                <span class="keyword">if</span>        (event.getState() == KeeperState.SyncConnected)        {
                                                connectedSignal.countDown();
                                }
                }

                <span class="directive">public</span> <span class="type">void</span> close() <span class="directive">throws</span> <span class="exception">InterruptedException</span>        {
                                zk.close();
                }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El código para <strong>JoinGroup</strong> es muy similar a <strong>CreateGroup</strong>.</p>
</li>
<li>
<p>Crea un <strong>znode efímero</strong> como hijo del grupo znode en su método <strong>join()</strong>, luego simula hacer trabajo de algún tipo
durmiendo hasta que el proceso se termine por fuerza.</p>
</li>
<li>
<p>Más adelante, vemos que un <strong>znode efímero</strong> es eliminado por ZooKeeper.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_encontrar_a_los_miembros_en_un_grupo">2.5.4. Encontrar a los miembros en un grupo</h4>
<div class="listingblock">
<div class="title">ListGroup</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">java.util.List</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.KeeperException</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ListGroup</span>        <span class="directive">extends</span>        ConnectionWatcher        {
                                                <span class="directive">public</span>        <span class="type">void</span>        list(<span class="predefined-type">String</span>        groupName)        <span class="directive">throws</span>        KeeperException,
                                                <span class="exception">InterruptedException</span> {
                                <span class="predefined-type">String</span>        path = <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + groupName;

                                <span class="keyword">try</span>        {
                                                <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; children =        zk.getChildren(path, <span class="predefined-constant">false</span>);
                                                <span class="keyword">if</span>        (children.isEmpty())        {
                                                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">No members in group %s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,        groupName);
                                                                <span class="predefined-type">System</span>.exit(<span class="integer">1</span>);
                                                }
                                                <span class="keyword">for</span>        (<span class="predefined-type">String</span>        child : children)        {
                                                                <span class="predefined-type">System</span>.out.println(child);
                                                }
                                }        <span class="keyword">catch</span>        (KeeperException.NoNodeException e)        {
                                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">Group %s        does not exist</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,        groupName);
                                                <span class="predefined-type">System</span>.exit(<span class="integer">1</span>);
                                }
                }

                <span class="directive">public</span>        <span class="directive">static</span>        <span class="type">void</span>        main(<span class="predefined-type">String</span><span class="type">[]</span>        args)        <span class="directive">throws</span>        <span class="exception">Exception</span>        {
                                ListGroup        listGroup        =        <span class="keyword">new</span>        ListGroup();
                                listGroup.connect(args[<span class="integer">0</span>]);
                                listGroup.list(args[<span class="integer">1</span>]);
                                listGroup.close();
                }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el método <strong>list()</strong>, llamamos <strong>getChildren()</strong> con la ruta del <strong>znode</strong> y un indicador <strong>watch</strong> para recuperar una lista de rutas secundarias para el znode, que imprimimos.</p>
</li>
<li>
<p>Colocamos un <strong>watch</strong> en un <strong>znode</strong> para hacer que el <strong>watcher</strong> quede registrado como activo si el znode cambia de estado.</p>
</li>
<li>
<p>Viendo a los hijos de un znode se permitirá a un programa recibir notificaciones de los miembros que se unan o abandonan el grupo, o del grupo que se elimina.</p>
</li>
<li>
<p>Capturamos <strong>KeeperException.NoNodeException</strong>, que se lanza en el caso cuando el <strong>grupo del znode no existe</strong>.</p>
</li>
<li>
<p>Vemos <strong>ListGroup</strong> en ejecución, y comprobamos que el <strong>grupo zoo</strong> está vacío, ya que no tenemos agregado a ningún miembro aún:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> java ListGroup localhost zoo
no members in group zoo</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos usar el programa <strong>JoinGroup</strong> para agregar algunos miembros al grupo.</p>
</li>
<li>
<p>Los lanzamos como procesos en background, ya que no terminan por sí mismos (debido a la declaración de sleep):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  java JoinGroup localhost zoo pato &amp;
[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  java JoinGroup localhost zoo vaca &amp;
[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  java JoinGroup localhost zoo cabra &amp;
[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  nuestra_cabra_pid = <span class="error">$</span>!</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En la última línea nos <strong>guardamos el ID de proceso del proceso Java que ejecuta el programa que agrega</strong> como un miembro.</p>
</li>
<li>
<p>Necesitamos recordar el ID para poder matar el proceso en un momento dado,</p>
</li>
<li>
<p>comprobamos los miembros:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  java ListGroup localhost zoo
cabra
pato
vaca</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_eliminar_un_miembro">2.5.5. Eliminar un miembro</h4>
<div class="ulist">
<ul>
<li>
<p>Para ello matamos su proceso:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kill $nuestra_cabra_pid</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y unos segundos más tarde, ha desaparecido del grupo porque el proceso de la sesión de ZooKeeper ha finalizado (el tiempo de espera se ha establecido en 5 segundos)</p>
</li>
<li>
<p>y su <strong>znode efímero</strong> ha sido eliminado:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java ListGroup localhost zoo
pato
vaca</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Resumen</p>
<div class="ulist">
<ul>
<li>
<p>Sabemos como construir una lista del grupo de nodos que están participando en un sistema distribuido.</p>
</li>
<li>
<p>Los nodos <strong>NO</strong> tienen que tener conocimiento mutuo de su existencia.</p>
</li>
<li>
<p>Un cliente que desea utilizar los nodos de la lista para realizar algunos trabajo, por ejemplo, puede descubrir los nodos, sin que ellos sean conscientes de su existencia.</p>
</li>
<li>
<p>La pertenencia a un grupo no implica una sustitución sobre el manejo de errores de red cuando nos comunicamos con un nodo.</p>
</li>
<li>
<p>Incluso si un nodo es un miembro del grupo, las comunicaciones con él pueden fallar, y tales fallos deben ser manejados de la manera habitual (reintentar, probar con un miembro del grupo, etc.).</p>
</li>
<li>
<p><strong>Las herramientas de línea de comandos de ZooKeeper son para interactuar con el espacio de nombres de ZooKeeper</strong>.</p>
</li>
<li>
<p>Podemos usarlo para *listar los znodes bajo el znode /zoo como sigue:</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh -server localhost ls /zoo
vaca, pato</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si lo ejecutamos sin argumentos nos muestra la ayuda.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_eliminación_de_un_grupo">2.5.6. Eliminación de un grupo</h4>
<div class="ulist">
<ul>
<li>
<p>La clase ZooKeeper proporciona una método <strong>Delete()</strong> que toma una ruta de acceso y un número de versión.</p>
</li>
<li>
<p>Se eliminará un <strong>znode</strong> sólo si el <strong>número de versión especificado</strong> es el mismo que el <strong>número de versión del znode</strong> que es tratado de eliminar, pues se trata de un mecanismo de bloqueo optimista que permite a los clientes detectar conflictos sobre la modificación de un <strong>znode</strong>.</p>
</li>
<li>
<p>Sin embargo, podemos omitir la comprobación de versiones mediante una versión con <strong>valor -1</strong> para eliminar el znode independientemente de su número de versión.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>No hay ninguna operación de borrado recursivo en ZooKeeper</strong>, por lo que enemos que eliminar los <strong>znodes hijos antes de los padres</strong>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Esto es lo que hace la clase <strong>DeleteGroup</strong>, que eliminará un grupo y todos sus miembros:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">java.util.List</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.KeeperException</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">DeleteGroup</span> <span class="directive">extends</span> ConnectionWatcher {


        <span class="directive">public</span> <span class="type">void</span> delete(<span class="predefined-type">String</span> groupName) <span class="directive">throws</span> KeeperException, <span class="exception">InterruptedException</span> {
                <span class="predefined-type">String</span> path = <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + groupName;

                <span class="keyword">try</span> {
                        <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; children = zk.getChildren(path, <span class="predefined-constant">false</span>);
                        <span class="keyword">for</span> (<span class="predefined-type">String</span> child : children) {
                                zk.delete(path + <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + child, -<span class="integer">1</span>);
                        }
                        zk.delete(path, -<span class="integer">1</span>);
                } <span class="keyword">catch</span> (KeeperException.NoNodeException e) {
                        <span class="predefined-type">System</span>.out.print(<span class="string"><span class="delimiter">&quot;</span><span class="content">El grupo</span><span class="delimiter">&quot;</span></span> + groupName + <span class="string"><span class="delimiter">&quot;</span><span class="content">no existe </span><span class="char">\n</span><span class="delimiter">&quot;</span></span>);
                        <span class="predefined-type">System</span>.exit(<span class="integer">1</span>);
                }
        }

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">Exception</span> {
                DeleteGroup deleteGroup = <span class="keyword">new</span> DeleteGroup();
                deleteGroup.connect(args[<span class="integer">0</span>]);
                deleteGroup.delete(args[<span class="integer">1</span>]);
                deleteGroup.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Finalmente, podemos eliminar el grupo de zoo que creamos anteriormente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> java DeleteGroup localhost zoo
[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> java ListGroup localhost zoo
Grupo zoo no existe</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect3">
<h4 id="_lab_operaciones_con_zookeeper">2.5.7. Lab: Operaciones con Zookeeper</h4>
<div class="ulist">
<ul>
<li>
<p>El objetivo es poner en funcionamiento el servidor de zookeeper</p>
</li>
<li>
<p>Probaremos todo lo que hemos comentado en el tema anterior.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_configuración_de_zookeeper">2.5.7.1. Configuración de zookeeper</h5>
<div class="ulist">
<ul>
<li>
<p>En nuestro caso, vamos a crear nuestro fichero partiendo del ejemplo que viene en el directorio <strong>conf</strong>, vamos a renombrarlo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cd /opt/apache-zookeeper/conf/
[kafka@kafka-server conf]$ cp zoo_sample.cfg zoo.cfg</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si nos fijamos, en este archivo vienen las siguientes configuraciones ya aplicadas:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ egrep -v &quot;^#&quot; zoo.cfg
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/tmp/zookeeper
clientPort=2181</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a cambiar el directorio donde guardamos los datos a:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">dataDir=/var/zookeeper</code></pre>
</div>
</div>
<div class="paragraph">
<p>Creamos el directorio y cambiamos sus permisos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ sudo mkdir /var/zookeeper
[kafka@kafka-server conf]$ sudo chown kafka:kafka /var/zookeeper/</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En un clúster <strong>Zookeeper</strong>, es necesario que cada nodo tenga su identificador creado, y aunque aquí no vayamos a crear un <strong>ensemble</strong>, daremos un id propio a nuestro nodo.</p>
</li>
<li>
<p>Nuestro nodo va a ser el nodo <strong>1</strong>, y esto es todo lo que debe figurar en nuestro fichero <strong>myid</strong>, que recordemos, debe ubicarse en la ruta de datos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ echo &quot;1&quot; &gt; /var/zookeeper/myid</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>De la misma forma, vamos a añadir la ruta de nuestro nodo al fichero de configuración (esto mismo, deberíamos hacerlo con los demás nodos en caso de estar en un <strong>ensemble</strong>).</p>
</li>
<li>
<p>Añadimos la siguiente línea a <strong>zoo.cfg</strong> (Recordad, en un entorno real usas el interfaz de red por el que esperáis recibir conexiones, <strong>NUNCA</strong> localhost)</p>
</li>
<li>
<p>En este caso, el nombre de la máquina es master, y apunta a 127.0.0.1</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">server.1=kafka-server.local:2888:3888</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Agregamos también la autorización de recibir comandos desde el puerto por defecto de 4 caracteres, como ruok, que probaremos más tarde.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">4lw.commands.whitelist=*</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_ejecución_2">2.5.7.2. Ejecución</h5>
<div class="ulist">
<ul>
<li>
<p>Iniciamos <strong>Zookeeper</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ zkServer.sh start
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Confirmamos que está funcionando diciéndole <strong>"are you ok?"</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ echo &quot;ruok&quot; | nc kafka-server.local 2181
imok</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_pruebas_con_java">2.5.7.3. Pruebas con Java</h5>
<div class="ulist">
<ul>
<li>
<p>Para probar esto, usaremos los ejemplos que hemos visto durante el curso, (ya compilados en un jar, llamado api-zookeeper-1.0.0.jar).</p>
</li>
<li>
<p>Hay que acordarse de incluirlo en el CLASSPATH, al igual que las librerías que usamos de <strong>Zookeeper</strong> (esto, podemos añadirlo al fichero profile.d o en el fichero .bash_profile del usuario, en este ejemplo supone que el jar está en /home/kafka/Desktop/software/libs)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ export CLASSPATH=$ZOOKEEPER_HOME/dist-maven/*:$ZOOKEEPER_HOME/lib/*:/home/kafka/Desktop/software/libs/*</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Probamos a crear el grupo de servidores:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.CreateGroup kafka-server.local zoo
Created        /zoo</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora creamos los nodos efímeros (y cogemos el id del nodo cabra):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ java com.kafka.zookeeper.JoinGroup kafka-server.local zoo pato &amp;
[1] 13595
Created        /zoo/pato
[kafka@kafka-server software]$ java com.kafka.zookeeper.JoinGroup kafka-server.local zoo vaca &amp;
[2] 13633
Created        /zoo/vaca
[kafka@kafka-server software]$ java com.kafka.zookeeper.JoinGroup kafka-server.local zoo cabra &amp;
[3] 13663
Created        /zoo/cabra
[kafka@kafka-server software]$ nuestra_cabra_pid=$!</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y miramos si nuestros nodos funcionan como esperábamos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.ListGroup kafka-server.local zoo
pato
cabra
vaca</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora, matamos el servidor <strong>cabra</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kill -9 $nuestra_cabra_pid
[3]+  Killed                  java com.kafka.zookeeper.JoinGroup master zoo cabra</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Confirmamos, que al ser un nodo efímero, desaparece:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ java com.kafka.zookeeper.ListGroup kafka-server.local zoo
pato
vaca
0    [main-SendThread(kafka-server.local:2181)] WARN  org.apache.zookeeper.ClientCnxn  - An exception was thrown while closing send thread for session 0x100001ee5910005.
EndOfStreamException: Unable to read additional data from server sessionid 0x100001ee5910005, likely server has closed socket
        at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
        at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1275)</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si lo lanzamos de nuevo, comprobamos como el cliente conectado ha desaparecido del todo.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.ListGroup kafka-server.local zoo
pato
vaca</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a proceder al borrado del grupo de servidores:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.DeleteGroup kafka-server.local zoo
1    [main-SendThread(kafka-server.local:2181)] WARN  org.apache.zookeeper.ClientCnxn  - An exception was thrown while closing send thread for session 0x100001ee5910007.
EndOfStreamException: Unable to read additional data from server sessionid 0x100001ee5910007, likely server has closed socket
        at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
        at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1275)</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora, consultamos qué nodos hay en dicho grupo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.ListGroup kafka-server.local zoo
Group zoo        does not exist</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_prueba_con_zkcli_sh">2.5.7.4. Prueba con zkCli.sh</h5>
<div class="ulist">
<ul>
<li>
<p>Ahora, vamos a usar la herramienta proporcionada por <strong>Zookeeper</strong> para comunicarnos con él, el cliente.</p>
</li>
<li>
<p>Para arrancar el cliente escribimos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh -server kafka-server.local:2181
/bin/java
Connecting to kafka-server.local:2181
...
[zk: master:2181(CONNECTED) 0]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez dentro del cliente, podemos ejecutar múltiples operaciones, veremos las siguientes:</p>
<div class="ulist">
<ul>
<li>
<p>Creación de nodos</p>
</li>
<li>
<p>Obtención de datos</p>
</li>
<li>
<p>Modificación de datos</p>
</li>
<li>
<p>Listar zNodes</p>
</li>
<li>
<p>Estado de un nodo</p>
</li>
<li>
<p>Borrar nodos</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Para crear un nodo tan sólo tenemos que hacer uso de <strong>create</strong>, especificando la ruta y el contenido del nodo:</p>
</li>
<li>
<p>La sintaxis es:</p>
<div class="ulist">
<ul>
<li>
<p>create [opciones] ruta datos</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear los nodos especificando contenido o dejándolos sin él</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 0] create /vacio &quot;&quot;
Created /vacio
[zk: kafka-server.local:2181(CONNECTED) 1] create /concosas &quot;estas cosas tiene&quot;
Created /concosas</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los flags que vamos a usar son</p>
<div class="ulist">
<ul>
<li>
<p><strong>-s</strong> &#8594; Es un nodo secuencial, le asigna un número de secuencial</p>
</li>
<li>
<p><strong>-e</strong> &#8594; Es efímero, se eliminará al cerrar el cliente</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 2] create -e /concosas/tmp1 &quot;soy temporal1&quot;
Created /concosas/tmp1
[zk: kafka-server.local:2181(CONNECTED) 3] create -s /concosas/seq &quot;Primero&quot;
Created /concosas/seq0000000001
[zk: kafka-server.local:2181(CONNECTED) 4] create -s /concosas/seq &quot;Segundo&quot;
Created /concosas/seq0000000002</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para obtener información almacenada en un nodo concreto, podemos usar <strong>get</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 5] get /concosas/tmp1
soy temporal1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si se quiere modificar el contenido de un <strong>zNode</strong> puedo hacer uso de <strong>set</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 6] set /concosas/tmp1 &quot;He cambiado&quot;
[zk: kafka-server.local:2181(CONNECTED) 7] get /concosas/tmp1
He cambiado</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si se quiere consultar los <strong>zNodes</strong> existentes, debo hacer uso de <strong>ls</strong>, cuya sintaxis es análoga a la de <strong>Unix</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 8] ls /
[concosas, vacio, zookeeper]
[zk: kafka-server.local:2181(CONNECTED) 9] ls /concosas
[seq0000000001, seq0000000002, tmp1]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para consultar el estado de un nodo, puedo hacer uso de <strong>stat</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 11] stat /concosas
cZxid = 0x1a
ctime = Mon Sep 28 12:14:04 UTC 2020
mZxid = 0x1a
mtime = Mon Sep 28 12:14:04 UTC 2020
pZxid = 0x1d
cversion = 3
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 17
numChildren = 3</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por último, para borrar un nodo, puedo hacer uso de <strong>rmr</strong>, que borra un nodo <strong>de forma recursiva</strong>, es decir, también borra sus hijos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 12] deleteall /concosas
[zk: kafka-server.local:2181(CONNECTED) 13] ls /
[vacio, zookeeper]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Salimos con el comando quit</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 14] quit</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para parar nuestro servidor, primero paramos los jobs en segundo plano de java:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kill %1
[kafka@kafka-server ~]$ kill %2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora paramos el servidor, y para ello escribimos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh stop
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Stopping zookeeper ... STOPPED</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_instalación_de_kafka">3. Instalación de Kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>La instalación de kafka es muy sencilla, ya que debemos haber instalado anteriormente zookeeper.</p>
</li>
<li>
<p>Con la instalación de zookeeper lista, solo se necesita instalar kafka indicando la ruta del servidor de zookeeper disponible.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
<div class="sect2">
<h3 id="_lab_instalación_de_kafka">3.1. Lab: Instalación de kafka</h3>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Para este ejemplo debemos tener instalado <strong>Zookeeper</strong></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Antes de nada, tenemos que descargar <strong>Kafka</strong>. Para ello iremos a:</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://kafka.apache.org/downloads" class="bare">https://kafka.apache.org/downloads</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Y descargaremos la versión que queramos (Existen versiones que han sido compiladas con distintos estándares de <strong>Scala</strong>, si no vais a usar <strong>Scala</strong>, escoged la recomendada)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-laboratorio-instalacion-01.png" alt="kafka laboratorio instalacion 01" width="600">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>El software está ya predescargado en el directorio /home/kafka/Desktop/software/</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_instalación_de_software">3.1.1. Instalación de software</h4>
<div class="ulist">
<ul>
<li>
<p>Descomprimimos <strong>Kafka</strong> y movemos a la ruta destino (por ejemplo /usr/local)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Hay que cambiar la versión por la que se haya descomprimido</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ tar xf kafka*.tgz
[kafka@kafka-server software]$ sudo mv kafka_2.13-2.6.0 /opt/kafka</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos también las variables de entorno de kafka:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ echo export KAFKA_HOME=/opt/kafka &gt;&gt; kafka_path.sh
[kafka@kafka-server software]$ echo 'export PATH=$PATH:$KAFKA_HOME/bin' &gt;&gt; kafka_path.sh
[kafka@kafka-server software]$ sudo mv kafka_path.sh /etc/profile.d/</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Cambiamos los permisos para poder ejecutar el script y</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ sudo chmod ugo+x /etc/profile.d/kafka_path.sh
[kafka@kafka-server software]$ source /etc/profile.d/kafka_path.sh</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_puesta_en_marcha">3.1.2. Puesta en marcha</h4>
<div class="ulist">
<ul>
<li>
<p>Iniciamos <strong>Zookeeper</strong> en caso de que esté apagado.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos que está funcionando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ echo ruok | nc kafka-server.local 2181
imok</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Antes de ejecutar <strong>Kafka</strong>, hay que crear para él un fichero de configuración.</p>
</li>
<li>
<p>En nuestro caso, vamos a ver el fichero por defecto, que está en <strong>$KAFKA_HOME/config/server.properties</strong></p>
</li>
<li>
<p>Este fichero contiene el <strong>Broker ID</strong> que va a ser usado:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[kafka@kafka-server ~]$ cat /opt/kafka/config/server.properties | grep broker.id
broker.id=0</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Por defecto <strong>Kafka</strong> va a buscar el servidor <strong>Zookeeper</strong> en <strong>localhost:2181</strong>, si queremos cambiar esto, podemos editar la propiedad <strong>zookeeper.connect</strong>, para darle un listado de nodos del ensamble <strong>Zookeeper</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de configuración de path de Zookeeper</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">zookeeper.connect=nodo1:2181,nodo2:2181,nodo3:2181</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Para arrancar <strong>Kafka</strong> tenemos dos opciones:</p>
</li>
<li>
<p>Arrancarlo en primer plano:</p>
<div class="ulist">
<ul>
<li>
<p>kafka-server-start.sh ruta_al_fich_conf</p>
</li>
</ul>
</div>
</li>
<li>
<p>O bien, arrancarlo en segundo plano</p>
<div class="ulist">
<ul>
<li>
<p>kafka-server-start.sh -daemon ruta_al_fich_conf</p>
</li>
</ul>
</div>
</li>
<li>
<p>Vamos a arrancar <strong>Kafka</strong> usando nuestro fichero de configuración:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh ${KAFKA_HOME}/config/server.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bien, ahora ya tenemos <strong>Kafka</strong> corriendo, vamos a ver qué ha creado en <strong>Zookeeper</strong></p>
</li>
<li>
<p>Nos conectamos con el cliente de <strong>Zookeeper</strong> desde otra shell</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server vagrant]$ zkCli.sh
/bin/java
Connecting to localhost:2181
...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si consultamos qué hay ahora en <strong>Zookeeper</strong> con <strong>ls</strong>, veremos que se han creado muchas cosas:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 0] ls /
[admin, brokers, cluster, config, consumers, controller, controller_epoch, isr_change_notification, latest_producer_id_block, log_dir_event_notification, vacio, zookeeper]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos que dentro del nodo <strong>brokers</strong> existen 3 nodos hijo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 1] ls /brokers
[ids, seqid, topics]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Consultamos su contenido, vemos que no existe ningún elemento en <strong>topics</strong> (normal, no hemos creado ningún topic), mientras que debajo de <strong>ids</strong> tenemos la lista de <strong>brokers</strong> existentes (en nuestro caso sólo tenemos 1). Si queremos tener más <strong>brokers</strong> levantados, aseguraros de darles distintos ids.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 2] ls /brokers/topics
[]
[zk: localhost:2181(CONNECTED) 3] ls /brokers/ids
[0]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pedimos información del <strong>broker</strong> mediante <strong>get</strong>, que me mostrará por ejemplo dónde estamos escuchando, en que host y en que puerto.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 4] get /brokers/ids/0
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://kafka-server.local:9092&quot;],&quot;jmx_port&quot;:-1,&quot;port&quot;:9092,&quot;host&quot;:&quot;kafka-server.local&quot;,&quot;version&quot;:4,&quot;timestamp&quot;:&quot;1601301843441&quot;}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por último, comentar que dentro de un clúster, puede haber múltiples <strong>brokers</strong>, pero sólo uno de ellos puede ejercer de <strong>controlador</strong>.</p>
</li>
<li>
<p>Podemos consultar qué <strong>broker</strong> está haciendo dicha función, solicitando los datos del nodo <strong>/controller</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 5] get /controller
{&quot;version&quot;:1,&quot;brokerid&quot;:0,&quot;timestamp&quot;:&quot;1601301843543&quot;}</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_topics">4. Topics</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Los <strong>Topics</strong> son la base de <strong>Kafka</strong>, son los equivalentes a las colas de mensajería (se inserta o leen mensajes).</p>
</li>
<li>
<p>El <strong>Broker</strong> es el encargado de guardar las distintas colas (<strong>topics</strong>), se utilizan también para crear los <strong>clusters</strong>, y se sincronizan mediante <strong>Zookeeper</strong>.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-01.jpg" alt="kafka topics 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los <strong>Topics</strong> son las distintas colas de mensajes que se encuentran en <strong>Kafka</strong>.</p>
</li>
<li>
<p>Un <strong>Topic</strong> están dividido en múltiples particiones. Las particiones se asignan a los distintos <strong>Brokers</strong> para poder distribuir y escalar el sistema (aunque un único <strong>Broker</strong> puede gestionar también varias particiones.</p>
</li>
<li>
<p>Dentro de las particiones se encuentran nuestros mensajes, que es el objeto final de nuestro sistema.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-02.png" alt="kafka topics 02" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Las particiones son ficheros que se encuentran en el disco.</p>
</li>
<li>
<p>Estos ficheros se denominan <strong>logs</strong>.</p>
</li>
<li>
<p>Cada mensaje dentro de un fichero <strong>log</strong> es identificado por un <strong>offset</strong>. Este <strong>offset</strong> sirve de ordenamiento, y es generado automáticamente por <strong>kafka</strong>.</p>
</li>
<li>
<p>Los consumidores pueden leer los mensajes a partir de un <strong>offset</strong> específico, por lo que los consumidores pueden unirse al clúster en cualquier momento (empezando en el <strong>offset</strong> que consideren).</p>
</li>
<li>
<p>En <strong>Kafka</strong>, un mensaje se identifica de manera unívoca mediante su <strong>topic</strong>, su <strong>partición</strong> y su <strong>offset</strong> (dentro de dicha partición)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-03.png" alt="kafka topics 03" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ya hemos dicho que internamente, una partición se guarda en disco como un fichero de tipo <strong>log</strong>. Un productor escribe un mensaje en dicho fichero y los consumidores leen el fichero desde el <strong>offset</strong> que ellos quieran.</p>
</li>
<li>
<p><strong>Kafka</strong> mantiene estos mensajes durante un periodo de tiempo (configurable), y es el consumidor el que debe ajustarse a dicho comportamiento (e.g, si un consumidor está caído durante un tiempo mayor a dicho periodo, perderá mensajes, pero en caso contrario, podrá continuar donde lo había dejado).</p>
</li>
<li>
<p>Es decir, <strong>Kafka</strong> no guarda información de qué ha leído cada consumidor.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-04.png" alt="kafka topics 04" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bueno, ya hemos dicho que podemos particionar un <strong>Topic</strong> para poder distribuirlo a más de un <strong>Broker</strong>.</p>
</li>
<li>
<p>Tened en cuenta que si vuestro sistema está saturado, y sólo disponéis de un <strong>Broker</strong>, crear más particiones no va a solucinar el problema (ya que el <strong>Broker</strong> tendrá todas las particiones).</p>
</li>
<li>
<p>Para poder distribuir las particiones a múltiples nodos, debemos disponer de múltiples <strong>Brokers</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-05.png" alt="kafka topics 05" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bien, sabemos cómo escalar si múltiples productores están escribiendo a un ritmo superior al que es capaz de gestionar un único <strong>Broker</strong>, pero ¿qué sucede en el caso anterior si se cae un nodo?</p>
</li>
<li>
<p>Si en nuestro ejemplo anterior, se cayera el nodo que gestiona el <strong>Broker 0</strong>, dejaríamos de tener acceso a tres particiones de dos <strong>topics</strong> distintos, con lo que no seríamos capaz de funcionar correctamente</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-06.png" alt="kafka topics 06" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para asegurar la alta disponibilidad de nuestro sistema, <strong>Kafka</strong> permite gestionar <strong>réplicas</strong> de nuestras particiones.</p>
</li>
<li>
<p>Una <strong>réplica</strong> es una copia de una partición asignada a otro <strong>Broker</strong> y por lo tanto ubicada en otro nodo distinto.</p>
</li>
<li>
<p>Con ello, nos aseguramos de que en caso de caída de algún, podemos seguir trabajando ya que la información seguirá estando disponible.</p>
</li>
<li>
<p>Cada partición de cada <strong>Topic</strong> tiene un único <strong>Leader</strong>.</p>
</li>
<li>
<p>Cuando realizamos una escritura, esta se realiza siempre sobre la partición <strong>Leader</strong>, cuyo <strong>Broker</strong> se encarga de persistir el dato y de sincronizarlo con las otras réplicas (los <strong>Brokers</strong> que contienen las otras réplicas deben confirmar la escritura).</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-07.png" alt="kafka topics 07" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Es importante recordar que <strong>tanto las escrituras como las lecturas</strong> se realizan siempre desde la partición <strong>Leader</strong></p>
</li>
<li>
<p>Cuando todo funciona correctamente, los datos se replican sin problemas. pero ¿qué sucede cuando cae un nodo?</p>
<div class="ulist">
<ul>
<li>
<p>Si cae un nodo que contiene una de las réplicas no líderes, estos quedarán <strong>out of sync</strong>, y cuando se recuperen el líder se encargará de sincronizarlas.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-08.png" alt="kafka topics 08" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si el nodo que cae es el que contiene la réplica <strong>Leader</strong>, el controlador de <strong>Kafka</strong> detectará la caída del líder, y elegirá un nuevo <strong>Leader</strong> de las réplicas que estén sincronizadas.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-09.png" alt="kafka topics 09" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hay varios puntos que tenemos que tener en cuenta</p>
<div class="ulist">
<ul>
<li>
<p>Nunca debemos poner un número de <strong>réplicas</strong> superior al número de <strong>Brokers</strong>, ya que no tiene sentido que un único <strong>Broker</strong> contenga dos réplicas</p>
</li>
<li>
<p>Aumentar las réplicas aumentamos la disponibilidad, nuestro sistema es más robusto ante caídas</p>
</li>
<li>
<p>Incrementar las réplicas aumenta el consumo de red, ya que el líder debe enviar los datos a las réplicas</p>
</li>
<li>
<p>Las réplicas disminuyen el rendimiento, porque el líder debe enviar los datos a las réplicas y recibir confirmaciones antes de dar la operación por buena (se puede configurar para no esperar tantos ack)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por último, vamos a hablar de los mensajes.</p>
</li>
<li>
<p>Los mensajes en <strong>Kafka</strong> están formados por tres partes:</p>
<div class="ulist">
<ul>
<li>
<p>Un Timestamp</p>
</li>
<li>
<p>Una Clave</p>
</li>
<li>
<p>Un valor</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Tanto la clave como el valor pueden ser de muchos tipos (ya que son conjuntos de bytes). La Clave puede ser usada para realizar el particionado (envías un mensaje a un <strong>Topic</strong>, pero podemos usar la clave para conseguir que el mensaje acabe en una partición determinada).</p>
</div>
<div style="page-break-after: always;"></div>
<div class="sect2">
<h3 id="_lab_creación_de_topics_y_particionado">4.1. Lab: Creación de Topics y particionado</h3>
<div class="ulist">
<ul>
<li>
<p>Para esta práctica, tenemos que asegurarnos de tener levantado <strong>Zookeeper</strong> y <strong>Kafka</strong> con la configuración vista en el apartado anterior.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server bin]$ jps
11409 Jps
10285 QuorumPeerMain
10367 Kafka</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En caso de no ver kafka en la lista, podemos asegurarnos de que está conectando desde zookeeper:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh
/bin/java
Connecting to localhost:2181
[zk: localhost:2181(CONNECTED) 0] ls /brokers/ids
[0]
[zk: localhost:2181(CONNECTED) 1] get /brokers/ids/0
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://kafka-server.local:9092&quot;],&quot;jmx_port&quot;:-1,&quot;port&quot;:9092,&quot;host&quot;:&quot;kafka-server.local&quot;,&quot;version&quot;:4,&quot;timestamp&quot;:&quot;1604489941572&quot;}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este caso se puede ver el nodo efímero del broker con la información de conexión.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_creación_de_topic">4.1.1. Creación de topic</h4>
<div class="ulist">
<ul>
<li>
<p>Para crear un <strong>Topic</strong>, disponemos del comando <strong>kafka-topics.sh</strong>. Para lanzarlo hay que especificar:</p>
<div class="ulist">
<ul>
<li>
<p><strong>--bootstrap-server host:puerto</strong> &#8594; Es necesario indicar dónde está el servidor <strong>kafka</strong> (Anteriormente se indicaba zookeeper, pero está deprecado)</p>
</li>
<li>
<p><strong>--create</strong> &#8594; Indicamos que vamos a crear un <strong>Topic</strong></p>
</li>
<li>
<p><strong>--topic nombre</strong> &#8594; Damos nombre al <strong>Topic</strong> (cuidado, los guiones bajos y pueden colisionar)</p>
</li>
<li>
<p><strong>--partitions n</strong> &#8594; Indicamos el número de particiones que queremos crear para dicho <strong>Topic</strong></p>
</li>
<li>
<p><strong>--replication-factor n</strong> &#8594; Indicamos el número de réplicas que queremos</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --create --topic base-topic --partitions 1 --replication-factor 1
Created topic base-topic.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si usamos ahora el cliente de <strong>Zookeeper</strong>, podemos ver que bajo el <strong>zNode</strong> de <strong>/broker/topics</strong>, ya tenemos nuestro <strong>topic</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh
/bin/java
Connecting to localhost:2181
...
[zk: localhost:2181(CONNECTED) 0] ls /brokers/topics
[base-topic]
[zk: localhost:2181(CONNECTED) 1] ls /brokers/topics/base-topic
[partitions]
[zk: localhost:2181(CONNECTED) 2] get /brokers/topics/base-topic
{&quot;version&quot;:2,&quot;partitions&quot;:{&quot;0&quot;:[0]},&quot;adding_replicas&quot;:{},&quot;removing_replicas&quot;:{}}
[zk: localhost:2181(CONNECTED) 3] quit</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si pedimos información de nuestro <strong>Topic</strong>, vemos que nos indica en qué <strong>broker</strong> está cada partición</p>
</li>
<li>
<p>Pero el propio <strong>Kafka</strong> a través de <strong>kafka-topics</strong> permite realizar consultas sobre los <strong>topics</strong></p>
</li>
<li>
<p>Listar los <strong>topics</strong> existentes:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --list
base-topic</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Obtener información de un topic en concreto (Nos muestra información general en la primera línea, y la relativa a cada partición en las demás, su líder, las réplicas, y los nodos que están en sincronía)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --describe --topic base-topic
Topic: base-topic       PartitionCount: 1       ReplicationFactor: 1    Configs: segment.bytes=1073741824
        Topic: base-topic       Partition: 0    Leader: 0       Replicas: 0     Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear un nuevo <strong>topic</strong> pero esta vez con varias particiones, y consultar sus datos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --create --topic base-topic2 --partitions 5 --replication-factor 1
Created topic base-topic2.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como el base-topic2 muestra la información de las particiones</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --describe --topic base-topic2
Topic: base-topic2      PartitionCount: 5       ReplicationFactor: 1    Configs: segment.bytes=1073741824
        Topic: base-topic2      Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: base-topic2      Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: base-topic2      Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: base-topic2      Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: base-topic2      Partition: 4    Leader: 0       Replicas: 0     Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como sólo disponemos de un <strong>broker</strong>, este posee los líderes y las réplicas de todas las particiones.</p>
</li>
<li>
<p>En <strong>Isr</strong> figuran los <strong>broker</strong> que están en sincronía (y evidentemente el líder siempre está en sincronía).</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_productores_y_consumidores">5. Productores y consumidores</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Ya hemos hablado de que en <strong>Kafka</strong> existen <strong>Productores</strong> y <strong>Consumidores</strong>.</p>
<div class="ulist">
<ul>
<li>
<p>Los <strong>Productores</strong> son los que crean los mensajes y los mandan a las colas (<strong>topics</strong>)</p>
</li>
<li>
<p>Los <strong>Consumidores</strong> son los que recogen esos mensajes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-01.png" alt="kafka productores consumidores 01" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los <strong>consumidores</strong> pueden funcionar de dos maneras, siguiendo un <strong>modelo de colas</strong> o un <strong>modelo de publicador/suscriptor</strong></p>
</li>
<li>
<p>En el modelo de cola, los mensajes son repartidos entre las instancias del consumidor</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-02.png" alt="kafka productores consumidores 02" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el modelo de publicador/suscriptor, las instancias de los consumidores recibirán todos los mismos mensajes</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-03.png" alt="kafka productores consumidores 03" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los <strong>Productores</strong> son los encargados de producir los mensajes y enviarlos a los <strong>topics</strong>.</p>
</li>
<li>
<p>Estos mensajes deben ser enviados siempre a la partición líder, el <strong>productor</strong> conoce cuál es el líder de cada partición, porque al iniciarse, se conecta a uno de los <strong>broker</strong> y le pide el mapa del particionado.</p>
</li>
<li>
<p>Tras obtener este mapa del particionado, ya sabe en qué <strong>broker</strong> está cada partición líder</p>
</li>
<li>
<p>Una cosa importante, cada mensaje se va a guardar en una partición concreta.</p>
</li>
<li>
<p>Esto, a priori, es aleatorio, aunque a veces es interesante que no hagamos un reparto aleatorio, sin conocer (o decidir) de antemano en qué partición acaba cada mensaje (por ejemplo, queremos tener todos los mensajes asociados al id de un cliente en una misma partición).</p>
</li>
<li>
<p>Para saber en qué partición acaba nuestro mensaje, usaremos su <strong>clave</strong></p>
</li>
<li>
<p>Por temas de rendimiento, los mensajes no se envían de uno en uno, se agrupan en paquetes. Estos paquetes se definen mediante dos condiciones:</p>
<div class="ulist">
<ul>
<li>
<p>Por número &#8594; Si llegas a un número determinado de mensajes, envía el paquetes</p>
</li>
<li>
<p>Por tiempo &#8594; Si durante un intervalo de tiempo definido, no se llega a acumular el número de mensajes indicado, realizamos el envío igualmente.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por su parte, los <strong>consumidores</strong> serán los encargados de leer los mensajes de los distintos <strong>topics</strong> (pero recordad, siempre se leen de las particiones líderes).</p>
</li>
<li>
<p>En versiones antiguas de <strong>Kafka</strong> (0.8 y anteriores), se hacía uso de <strong>Zookeeper</strong> para saber por dónde estaban leyendo, ahora ya no (lo gestiona <strong>kafka</strong> internamente).</p>
</li>
<li>
<p>Para llevar esta gestión, <strong>Kafka</strong> hace uso de un <strong>topic</strong> especial denominado <strong>__consumer_offsets</strong>.</p>
</li>
<li>
<p>Este <strong>topic</strong> tiene el identificador de cada <strong>grupo de consumidores</strong> y el <strong>offset</strong> por el que va leyendo.</p>
</li>
<li>
<p>Un <strong>grupo de consumidores</strong> es un identificador compartido por varios consumidores. Un <strong>grupo de consumidores</strong> puede tener 1 o varias instancias de consumidores.</p>
</li>
<li>
<p>Si hay más de uno, los consumidores balancean las particiones.</p>
</li>
<li>
<p>Si algún consumidor se cae, su partición se asigna a otro consumidor.</p>
</li>
<li>
<p><strong>No se pueden tener más consumidores que particiones</strong>, pero si podemos tener varios <strong>grupos de consumidores</strong> leyendo de una misma partición (pero sólo un cliente de cada grupo puede leer de una partición concreta)</p>
</li>
<li>
<p>Un <strong>Grupo de consumidores</strong> puede tener una única instancia de consumidor, en cuyo caso  procesa los mensajes de todas las particiones del <strong>topic</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-04.png" alt="kafka productores consumidores 04" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si para el mismo grupo de consumidores, creo una nueva instancia del consumidor, se balancean las particiones</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-05.png" alt="kafka productores consumidores 05" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con otra instancia adicional, se vuelven balancean las particiones (recordad, no puede haber más consumidores que particiones)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-06.png" alt="kafka productores consumidores 06" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si alguna instancia cae, la partición (o particiones) asignadas al consumidor que ha caído se reasignan a los consumidores existentes.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-05.png" alt="kafka productores consumidores 05" width="400">
</div>
</div>
<div style="page-break-after: always;"></div>
<div class="sect2">
<h3 id="_lab_produciendo_y_consumiendo">5.1. Lab: Produciendo y consumiendo</h3>
<div class="ulist">
<ul>
<li>
<p>Aunque no sea lo habitual, para probar <strong>kafka</strong>, disponemos de dos herramientas de línea de comandos para poder producir y consumir mensajes:</p>
<div class="ulist">
<ul>
<li>
<p><strong>kafka-console-producer.sh</strong> &#8594; Un productor que nos permite enviar mensajes a un <strong>Topic</strong>, escribiendo directamente desde una shell</p>
</li>
<li>
<p><strong>kafka-console-consumer.sh</strong> &#8594; Un consumidor que nos permite consumir mensajes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Por defecto, el puerto en el que <strong>Kafka</strong> está escuchando es el 9092
Para esta prueba, tanto <strong>Zookeeper</strong> como <strong>Kafka</strong> deben estar levantados, y vamos a dar por hecho que existe un <strong>Topic</strong> creado (en nuestro caso <strong>base-topic2</strong>)</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Bien, vamos a lanzar un productor, para ello usaremos <strong>kafka-console-producer.sh</strong>, con las siguientes opciones:</p>
<div class="ulist">
<ul>
<li>
<p><strong>--broker-list</strong> &#8594; lista de los brokers (en nuestro caso sólo hay uno, nuestra máquina)</p>
</li>
<li>
<p><strong>--topic</strong> &#8594; El topic sobre el que queremos enviar mensajes</p>
</li>
</ul>
</div>
</li>
<li>
<p>Esto nos deja la shell abierta, cada línea que escribamos a partir de ahí es un mensaje</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic base-topic2
&gt;mensaje 1
&gt;mensaje 2
&gt;otro mensaje</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>No cerreis la consola con los mensajes, ya que más adelante escribiremos más mensajes</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a arrancar ahora un consumidor (en otra shell), usando el comando <strong>kafka-console-consumer.sh</strong></p>
<div class="ulist">
<ul>
<li>
<p><strong>--bootstrap-server</strong> &#8594; Servidor al que vamos a atacar</p>
</li>
<li>
<p><strong>--new-consumer</strong> &#8594; Todavía da soporte a versiones antiguas del consumer, con esto indicamos que usamos la nueva</p>
</li>
<li>
<p><strong>--topic</strong> &#8594; el <strong>topic</strong> a consumir</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic base-topic2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si ahora escribimos "algo" en el productor, se muestra en nuestro consumidor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Shell productor</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic base-topic2
&gt;mensaje 1
&gt;mensaje 2
&gt;otro mensaje
&gt;mas mensajes</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Shell consumidor tras el evento</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2
mas mensajes</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hemos mostrado los nuevos mensajes, pero ¿y qué pasa con los creados antes de arrancar nuestro consumidor?</p>
</li>
<li>
<p>Pues podemos mostrarlos si usamos la opción <strong>--from-beginning</strong></p>
</li>
<li>
<p>Para ello paramos el consumidor con CTRL+C</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2
mas mensajes
^CProcessed a total of 1 messages</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora lo arrancamos con el nuevo argumento</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning
mensaje 2
mas mensajes
mensaje 1
otro mensaje</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si os acordáis, hemos dicho que los mensajes viajan con una clave y un valor, pero ¿qué clave hemos proporcionado para  estos mensajes?.</p>
</li>
<li>
<p>Podemos ver la clave usando la opción <strong>--property print.key=true</strong></p>
</li>
<li>
<p>Para ello volvemos a cerrarlo con CTRL+C y lo abrimos con la nueva directiva</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true
null        mensaje 2
null        mas mensajes
null        mensaje 1
null        otro mensaje</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bueno, tiene sentido. No hemos especificado clave alguna, así que es normal que esté a <strong>null</strong>. Paramos el consumidor.</p>
</li>
<li>
<p>Vamos a parar y levantar el productor, pero indicando que vamos a usar una clave, separada por el caracter que indiquemos de su valor. Esto se hace con la propiedades <strong>--property parse.key=true --property key.separator=,</strong> (indicamos que hay que parsear clave, y en este caso usaremos la coma como separador)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic base-topic2 --property parse.key=true --property key.separator=,
&gt;clave1,valor1
&gt;clave2,valor2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si intento poner una línea sin clave, da error:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">&gt;otra
org.apache.kafka.common.KafkaException: No key found on line 3: otra
        at kafka.tools.ConsoleProducer$LineMessageReader.readMessage(ConsoleProducer.scala:290)
        at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:51)
        at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Muestra de consumidor tras guardar los valores con clave</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true
null        mensaje 2
null        mas mensajes
clave1        valor1
clave2        valor2
null        mensaje 1
null        otro mensaje</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Paramos nuestro consumidor.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Pulsando CTRL+C</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">^CProcessed a total of 6 messages</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos ahora a levantar múltiples consumidores, para ello les asignaremos un mismo grupo de consumidores.</p>
</li>
<li>
<p>Usaremos el fichero <strong>consumer.properties</strong> que viene distribuido con <strong>Kafka</strong> para levantar los consumidores indicando su grupo</p>
</li>
<li>
<p>Este fichero contiene una propiedad <strong>group.id</strong> que indica cuál es el id del grupo de consumidores (en nuestro caso <strong>test-consumer-group</strong>).</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cat /opt/kafka/config/consumer.properties | grep group.id
# consumer group id
group.id=test-consumer-group</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Levantamos ahora un consumidor haciendo uso del fichero de configuración que hemos visto (y procesando desde el principio de los tiempos)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true --consumer.config ${KAFKA_HOME}/config/consumer.properties
null        mensaje 2
null        mas mensajes
clave1        valor1
clave2        valor2
null        mensaje 1
null        otro mensaje</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si ahora levanto un nuevo cliente con exactamente la misma configuración, (abrid una nueva terminal), sucede lo siguiente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true --consumer.config ${KAFKA_HOME}/config/consumer.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nada. Como seguimos consumiendo del mismo <strong>topic</strong>, y nuestro grupo de consumidores ya ha procesado esos mensajes (si ejecutáramos un nuevo grupo de consumidores, si los volveríamos a procesar).</p>
</li>
<li>
<p>Pero nuestro <strong>topic</strong> tiene varias particiones, por lo que una vez se incluye un nuevo consumidor a un grupo, se balancean las particiones.</p>
</li>
<li>
<p>Vamos a probar a crear varios mensajes nuevos en nuestro productor (con distintas claves).</p>
</li>
<li>
<p>Fijaros también como la misma clave acaba siempre en la misma partición*</p>
</li>
<li>
<p>Para probarlo, abrimos una tercera shell y ejecutamos el siguiente productor introduciendo los mensajes</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Productor con dos consumidores del mismo grupo</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic base-topic2 --property parse.key=true --property key.separator=,
&gt;1,1
&gt;2,2
&gt;5,5
&gt;3,3
&gt;5,4
&gt;5,9
&gt;5,8</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Consumidor 1 de test-consumer-group</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true --consumer.config ${KAFKA_HOME}/config/consumer.properties
null        mensaje 2
null        mas mensajes
clave1        valor1
clave2        valor2
null        mensaje 1
null        otro mensaje
5        5
5        4
5        9
5        8</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Consumidor 2 de test-consumer-group</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true --consumer.config ${KAFKA_HOME}/config/consumer.properties
1        1
2        2
3        3</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por último, vamos a ver el directorio donde <strong>Kafka</strong> guarda sus datos (<strong>logs</strong>).</p>
</li>
<li>
<p>El fichero de configuración de <strong>kafka</strong> tiene una propiedad <strong>log.dirs</strong>.</p>
</li>
<li>
<p>Esta es la ruta donde guardamos los <strong>logs</strong>.</p>
</li>
<li>
<p>En esta ruta estarán todos los <strong>topics</strong> (y los <strong>__consumer_offsets</strong>, que los crea <strong>kafka</strong> automáticamente)</p>
</li>
<li>
<p>Para ver la ruta donde están:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cat ${KAFKA_HOME}/config/server.properties | grep kafka-logs
log.dirs=/tmp/kafka-logs</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos su contenido</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ tree /tmp/kafka-logs/ -L 1
/tmp/kafka-logs/
├── base-topic-0
├── base-topic2-0
├── base-topic2-1
├── base-topic2-2
├── base-topic2-3
├── base-topic2-4
├── cleaner-offset-checkpoint
├── __consumer_offsets-0
├── __consumer_offsets-1
├── __consumer_offsets-10
...
├── log-start-offset-checkpoint
├── meta.properties
├── recovery-point-offset-checkpoint
└── replication-offset-checkpoint</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como podéis observar, cada <strong>topic</strong> no tiene un único directorio, si no un único directorio por partición.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ tree /tmp/kafka-logs/base-topic2-0 -L 1
/tmp/kafka-logs/base-topic2-0
├── 00000000000000000000.index
├── 00000000000000000000.log
├── 00000000000000000000.timeindex
└── leader-epoch-checkpoint</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El fichero <strong>.log</strong> es el que contiene los mensajes que hemos enviado.</p>
</li>
<li>
<p>Si hacemos un <strong>cat</strong> podemos ver que (entre los datos binarios), están los mensajes que yo he enviado)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-lab-01.png" alt="kafka productores consumidores lab 01" width="300">
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_log_compaction">6. Log Compaction</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>Log Compaction</strong> es una propiedad que asegura que se almacena el último valor para una clave dada.</p>
<div class="ulist">
<ul>
<li>
<p>Esto es configurable a nivel de <strong>Topic</strong> (puedes tener <strong>topics</strong> que lo usen, y otros que no).</p>
</li>
<li>
<p>Es de especial utilidad cuando hay que recuperar un estado tras un fallo, o restaurar una caché que se ha ido creando durante la ejecución de un proceso.</p>
</li>
<li>
<p>En sistemas como <strong>Kafka Stream</strong> o <strong>Apache Samza</strong> es de bastante utilidad.</p>
</li>
<li>
<p>En la siguiente imagen vemos el aspecto que tiene un <strong>topic</strong>, que recibe mensajes (clave,valor), y les asigna un <strong>offset</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-01.png" alt="kafka log compaction 01" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El <strong>Log Compaction</strong> identifica los mensajes que tienen una misma clave</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-02.png" alt="kafka log compaction 02" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Después, se queda con un único mensaje por clave, siendo este el que mayor <strong>offset</strong> posee</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-03.png" alt="kafka log compaction 03" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Dejando el log con las últimas versiones de cada clave</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-04.png" alt="kafka log compaction 04" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Un caso de uso de esto sería una aplicación de streaming que guarda una caché de los últimos valores recibidos.</p>
</li>
<li>
<p>Para ello, va leyendo de un <strong>topic</strong> la información, y actualizando su caché.</p>
</li>
<li>
<p>Al mismo tiempo, guarda en un <strong>topic</strong> propio con <strong>log compaction</strong> los datos que lee.</p>
</li>
<li>
<p>Si el sistema se cae, vuelve a levantarse leyendo todos los datos del <strong>topic</strong> en cuestión, regenerando así su caché de forma automática</p>
</li>
<li>
<p>Los productores escriben en un topic</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-05.png" alt="kafka log compaction 05" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nuestra aplicación, consume los mensajes de dicho topic</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-06.png" alt="kafka log compaction 06" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al consumir los mensajes, va creando una caché (por clave)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-07.png" alt="kafka log compaction 07" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Todos los mensajes que lee, los guarda en un topic con log compaction. Internamente, actualiza los valores de su caché si una clave ya había sido leída</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-08.png" alt="kafka log compaction 08" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La caché tendrá un subconjunto de datos, pero el topic con Log Compaction habrá recibido el total de los mensajes leídos</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-09.png" alt="kafka log compaction 09" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al hacer un Log Compaction, el topic se queda con un único mensaje por cada clave</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-10.png" alt="kafka log compaction 10" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nuestra aplicación se cae</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-11.png" alt="kafka log compaction 11" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al levantarse, se conecta a su topic como consumidor</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-12.png" alt="kafka log compaction 12" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El topic, le proporciona todos los mensajes, que contienen sólo la última versión de cada clave</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-13.png" alt="kafka log compaction 13" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con estos mensajes, la caché se ha regenerado, y la aplicación puede volver a trabajar con normalidad.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-14.png" alt="kafka log compaction 14" width="400">
</div>
</div>
<div class="sect2">
<h3 id="_configuración_2">6.1. Configuración</h3>
<div class="ulist">
<ul>
<li>
<p>La creación de un topic con log_compaction implica definir una serie de configuraciones:</p>
<div class="ulist">
<ul>
<li>
<p><strong>cleanup.policy</strong></p>
<div class="ulist">
<ul>
<li>
<p><strong>compact</strong>: Implica que se activa la compactación.</p>
</li>
<li>
<p><strong>delete</strong>: Junto con compact, se pueden purgar las entradas más antiguas.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>delete.retention.ms</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Por defecto, en la fase de limpieza, los mensajes duplicados son eliminados, y aquellos que tengan el valor a null también. Esos records se les llama tombstones.</p>
</li>
<li>
<p>Si el tiempo es menor al indicado, los tombstones permanecen, sino son eliminados.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>segment.ms</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Es el tiempo que tarda en realizar un nuevo segmento. Hay que tener en cuenta que no todos los segmentos se compactan, sino que solo se compactan los segmentos que pertenecen a la cola (tail).</p>
</li>
<li>
<p>Estos segmentos se compactan formando uno más grande.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>min.cleanable.dirty.ratio</strong></p>
<div class="ulist">
<ul>
<li>
<p>El broker de kafka crea una serie de hilos para la limpieza <strong>log.cleaner.threads</strong>. Tratará de buscar el log que peor esté y tratará de limpiarlo.</p>
</li>
<li>
<p>El calculo se realiza con: bytes_head / (bytes_head + bytes_tail)</p>
</li>
<li>
<p>Si el ratio se cumple, ejecuta la limpieza, sino el hilo es bloqueado. El tiempo de bloqueo se puede elegir con <strong>log.cleaner.backoff.ms</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_tuning">6.2. Tuning</h3>
<div class="sect3">
<h4 id="_log_cleaner_dedupe_buffer_size">6.2.1. log.cleaner.dedupe.buffer.size</h4>
<div class="ulist">
<ul>
<li>
<p>Podemos modificar el tamaño del buffer asignado para limpieza.</p>
</li>
<li>
<p>Eso permitiría que las compactaciones grandes se hicieran más rápido, sin embargo, la cantidad de memoria asignada puede tener un gran impacto.</p>
</li>
<li>
<p>No se debe superar el GB ya que también realiza operaciones IO muy costosas en limpieza.</p>
</li>
<li>
<p>Como ejemplo:</p>
<div class="ulist">
<ul>
<li>
<p>Si tenemos más de 1800 millones de mensajes para compactar, en 3 particiones, serían como 600 millones de mensajes por broker.</p>
</li>
<li>
<p>Con la configuración estándar tardaría unas 100 iteraciones del log en limpiarlo.</p>
</li>
<li>
<p>Si ampliamos a <strong>1GB de memoria</strong>, podemos alterarlo a 1GB, lo que implica unos 45 millones de mensajes por iteración.</p>
</li>
<li>
<p>Nos daría un total de 15 iteraciones para poder limpiarlo.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_log_cleaner_threads">6.2.2. log.cleaner.threads</h4>
<div class="ulist">
<ul>
<li>
<p>Si abusamos del uso de log compaction, hay que tener en cuenta los consumos asociados:</p>
</li>
<li>
<p>Estos hilos (por defecto 1), se dedicarán a hacer limpieza en vez de servir peticiones a productores y consumidores.</p>
</li>
<li>
<p>Dependiendo de la prioridad podemos ampliar el número de hilos</p>
</li>
<li>
<p>Si lo que queremos es seguir dando un óptimo servicio, dejamos a 1 el número de hilos optimizando el resto de parámetros.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_particiones">6.2.3. particiones</h4>
<div class="ulist">
<ul>
<li>
<p>Aquí está el punto crítico.</p>
</li>
<li>
<p>Podemos calcular el número óptimo de particiones para que nuestro cleaner tarde lo menos posible.</p>
</li>
<li>
<p>Para ello, dividimos el total de mensajes por 45 y nos dará el número de particiones óptima</p>
</li>
<li>
<p>Dividimos los 1800 millones por los 45, lo que nos da 40 particiones.</p>
</li>
<li>
<p>Con 40 particiones tendremos el rendimiento óptimo de un topic con log_compaction.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_min_cleanable_dirty_ratio">6.2.4. min.cleanable.dirty.ratio</h4>
<div class="ulist">
<ul>
<li>
<p>Hay que tener en cuenta que según el número de mensajes por segundo que llegan, puede que gran cantidad de mensajes queden en el head y no se procesen.</p>
</li>
<li>
<p>Por eso hay que tener en cuenta que el uso por defecto de 0.5 puede dejar una gran cantidad de mensajes almacenados sin procesar</p>
</li>
<li>
<p>Su procesamiento consume IO, pero su almacenamiento consume IO también si los clientes leen desde el principio, algo común en este tipo de topics, con lo cual compensa reducir este valor.</p>
</li>
<li>
<p>0,25 o 0,2 son valores recomendables.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_log_compaction">6.3. Lab: Log compaction</h3>
<div class="ulist">
<ul>
<li>
<p>Vamos a compactar un topic y a comprobar como el resultado de producir mensajes y de consumirlos respeta las reglas aplicadas.</p>
</li>
<li>
<p>Para ello vamos a definir los siguientes parámetros</p>
<div class="ulist">
<ul>
<li>
<p>cleanup.policy=compact: Necesitamos definir la política de compactación para el topic de forma explícita</p>
</li>
<li>
<p>delete.retention.ms=100: Indica que el consumidor verá los valores eliminados (tombstones) hasta alcanzar la cabeza del log, en menos del tiempo de retention policy. Por defecto son 24 horas.</p>
</li>
<li>
<p>log.cleaner.threads: El número de hilos que se dedican a compactar. El hilo de limpieza elige el log con mayor ratio de "suciedad".</p>
<div class="ulist">
<ul>
<li>
<p>ratio = bytes en la cabecera / total de bytes en el log</p>
</li>
</ul>
</div>
</li>
<li>
<p>min.compaction.lag.ms: Garantiza un periodo mínimo de espera antes de compactar un mensaje.</p>
</li>
<li>
<p>log.cleaner.min.compaction.lag.ms: Los registros no se compactan hasta que no tengan este tiempo sobrepasado.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Ahora creamos un nuevo topic con log compaction</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --create --topic topic-log-compaction --replication-factor 1 --partitions 1 --config &quot;cleanup.policy=compact&quot; --config &quot;delete.retention.ms=100&quot;  --config &quot;segment.ms=100&quot; --config &quot;min.cleanable.dirty.ratio=0.01&quot;
Created topic topic-log-compaction.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un productor y mandamos los siguientes mensajes</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic topic-log-compaction --property parse.key=true --property key.separator=,
&gt;K1,V1
&gt;K2,V2
&gt;K1,V3
&gt;K3,V4
&gt;K2,V5
&gt;K4,V6
&gt;K5,V7
&gt;K5,V8
&gt;K6,V9</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como se ha quedado solo con los dos ultimos valores de cada clave, el resto ha sido compactado</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic topic-log-compaction --from-beginning --property print.key=true
K1        V3
K3        V4
K2        V5
K4        V6
K5        V8
K6        V9</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Según se vayan agregando nuevos registros, hasta que no se alcanza un hito, no compacta.</p>
</li>
<li>
<p>También hay que tener en cuenta que solo se compacta la cola, con lo cual, los registros del head no se compactan, lo que da a duplicados comunmente</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_configuración_de_kafka">7. Configuración de kafka</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_configuración_del_broker">7.1. Configuración del Broker</h3>
<div class="ulist">
<ul>
<li>
<p>En <strong>Kafka</strong>, cada <strong>Broker</strong> tiene una configuración leída de un fichero <strong>server.properties</strong>, que tenemos que proporcionar al levantar el <strong>Broker</strong>.</p>
</li>
<li>
<p>Este fichero de configuración tiene varias propiedades muy interesantes, que nos conviene conocer para poder trabajar correctamente.</p>
</li>
<li>
<p>En este tema conoceremos las opciones más comunes, aunque si queréis conocer en profundidad todas las opciones disponibles, podéis consultar la documentación oficial (apartado configuración) en :</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://kafka.apache.org/documentation/#configuration" class="bare">https://kafka.apache.org/documentation/#configuration</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Un fichero de configuración del <strong>Broker</strong>, contiene configuración de distintas secciones:</p>
<div class="ulist">
<ul>
<li>
<p>Información básica del servidor</p>
</li>
<li>
<p>Sockets por los que escucha</p>
</li>
<li>
<p>Información de ficheros Log y creación automática de topics</p>
</li>
<li>
<p>Información del servidor Zookeeper</p>
</li>
<li>
<p>Gestión de espacio y retención de ficheros Log</p>
</li>
</ul>
</div>
</li>
<li>
<p>Las configuraciones en kafka desde la versión 1.1.0+ se pueden modificar desde la utilidad <strong>kafka-configs.sh</strong></p>
</li>
<li>
<p>Sin embargo, algunas de ellas siguen siendo necesario reiniciar la instancia modificando el fichero <strong>server.properties</strong></p>
</li>
<li>
<p>La información más básica para el servidor es el campo <strong>broker.id</strong>.</p>
</li>
<li>
<p>Dicho campo posee el identificador único de nuestro <strong>Broker</strong>, y no puede ser usado por ningún otro <strong>Broker</strong> del clúster.</p>
</li>
<li>
<p>No obstante, en ocasiones nos interesa que este identificador sea generado automáticamente (por ejemplo, en entornos cloud como <strong>AWS</strong> o <strong>Google Cloud Computing</strong>).</p>
</li>
<li>
<p>Si queremos que el id de nuestro <strong>broker</strong> se genere automáticamente, debemos borrar la propiedad <strong>broker.id</strong> e incluir las propiedades:</p>
<div class="ulist">
<ul>
<li>
<p><strong>broker.id.generation.enable=true</strong> &#8594; Para activar la asignación automática de ids</p>
</li>
<li>
<p><strong>reserved.broker.max.id=n</strong> &#8594; Empieza a asignar los ids a partir del número especificado, reservando los anteriores para aquellos <strong>broker</strong> cuyo id esté especificado en el fichero de configuración.</p>
</li>
</ul>
</div>
</li>
<li>
<p>El siguiente ejemplo (de una subsección del fichero server.properties) configuraría un <strong>broker</strong> con <strong>broker.id=3</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>broker.id=3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Si quisiéramos que asignara automáticamente su id, deberíamos comentar/borrar esa línea e incluir por ejemplo la siguiente (genera a partir del id=1000)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">#broker.id=3
broker.id.generation.enable=true
reserved.broker.max.id=1000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con respecto a los <strong>listeners</strong>, puedes configurar <strong>KAFKA</strong> para que escuche a través de un interfaz de red. En el ejemplo siguiente configuramos nuestro <strong>Broker</strong> para que esté escuchando en todas las direcciones de la máquina, a través del puerto <strong>9092</strong>, y en formato de texto plano (sin seguridad o cifrado)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>listeners=PLAINTEXT://0.0.0.0:9092</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si tenéis múltiples interfaces de red, tenéis que decir a través de cuál escucháis. Si tu nodo recibe información por un interfaz que no es el especificado, <strong>Kafka</strong> no lo recibirá.</p>
</li>
<li>
<p>Con respecto a la configuración de los ficheros de <strong>Log</strong> y los <strong>topics</strong>, lo principal es especificar la ruta donde vamos a almacenar nuestros ficheros. Esto lo especifica la propiedad <strong>log.dirs</strong>.</p>
</li>
<li>
<p>Esta propiedad permite recibir múltiples directorios (separados por coma).</p>
</li>
<li>
<p><strong>Kafka</strong> balanceará en estos directorios la escritura de los ficheros, permitiéndonos mejorar el rendimiento en caso de disponer de varios discos (al escribir y leer en paralelo desde más de uno gracias a esta configuración).</p>
</li>
<li>
<p>Por defecto, esta propiedad apunta a la ruta <strong>/tmp/kafka-logs</strong>. Si borramos el contenido de esta carpeta, dejaremos <strong>Kafka</strong> como recién instalado.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.dirs=/tmp/kafka-logs</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Además de la ruta de escritura en disco, <strong>Kafka</strong> nos permite realizar la creación de topics de manera automática.</p>
</li>
<li>
<p>Cuando un productor quiere escribir en un <strong>topic</strong> que no existe, podemos permitir que <strong>Kafka</strong> lo cree de forma inmediata, usando un número de particiones y factor de replicación por defecto</p>
<div class="ulist">
<ul>
<li>
<p><strong>num.partitions</strong> &#8594; El número de particiones que tendrán los <strong>topics</strong> creados de forma automática</p>
</li>
<li>
<p><strong>default.replication.factor</strong> &#8594; El factor de replicación que tendrán los <strong>topics</strong> creados de esta forma</p>
</li>
</ul>
</div>
</li>
<li>
<p>Existe una propiedad <strong>auto.create.topics.enable</strong> que por defecto vale <strong>true</strong>, que es la que nos permite la creación automática de <strong>topics</strong>.</p>
</li>
<li>
<p>Si no quisiéramos crear automáticamente <strong>topics</strong>, tendríamos que ponerla a <strong>false</strong> específicamente (si no, se especifica, se crean automáticamente)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Creación automática</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">num.partitions=1
default.replication.factor=1</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Sin creación automática</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">#num.partitions=1
#default.replication.factor=1
auto.create.topics.enable=false</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con respecto a la configuración de <strong>Zookeeper</strong>, solo tenemos que especificar la ruta al clúster y especificar un timeout para realizar dicha conexión.</p>
<div class="ulist">
<ul>
<li>
<p><strong>zookeeper.connect</strong> &#8594; Especificamos los hosts y puertos (separados por coma) de nodos que forman nuestro ensamble de Zookeeper</p>
</li>
<li>
<p><strong>zookeeper.connection.timeout.ms</strong> &#8594; Tiempo máximo que esperamos para conectarnos a un servidor (si falla, pasamos al siguiente de la lista)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">zookeeper.connect=nodo1:2181,nodo2:2181
zookeeper.connection.timeout.ms=6000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nos queda un punto importante para finalizar con la configuración del <strong>Broker</strong>, y es referente a la gestión del espacio en disco.</p>
</li>
<li>
<p>Los sistemas con los que trabajamos tienen un disco duro finito, por lo que puede darse la situación de que llenemos nuestro sistema de almacenamiento.</p>
</li>
<li>
<p>Un disco lleno imposibilita el correcto funcionamiento de <strong>Kafka</strong>, ya que en cuanto esto sucede <strong>Zookeeper</strong> ya no es capaz de realizar más escrituras y <strong>kafka</strong> no puede guardar los mensajes recibidos.</p>
</li>
<li>
<p>Para evitar estas situaciones, tenemos que controlar el espacio en disco, y para ello <strong>Kafka</strong> nos proporciona la <strong>Log Retention Policy</strong>, que nos permite establecer límites al espacio usado en disco o al tiempo que almacenamos los mensajes recibidos.</p>
</li>
<li>
<p>La <strong>Log Retention Policy</strong> permite configurar dos políticas de retención de datos:</p>
<div class="ulist">
<ul>
<li>
<p>Estableciendo unos límites al tamaño de los datos a almacenar.</p>
</li>
<li>
<p>Estableciendo un tiempo máximo en el que almacenaremos la información.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Estas políticas no son excluyentes, con lo que podemos configurar ambas, permitiendo que los datos se almacenen un tiempo máximo o bien hasta llegar a un máximo de espacio. Cuando una de las dos cotas se cumplen, se eliminan los datos antiguos.</p>
</li>
<li>
<p>Es por esto que es necesario conocer cuál va a ser el uso que vamos a tener de nuestro sistema.</p>
</li>
<li>
<p>Ejemplo:</p>
<div class="ulist">
<ul>
<li>
<p>4 topics</p>
</li>
<li>
<p>20 particiones por topic</p>
</li>
<li>
<p>Un factor de replicación 2</p>
</li>
<li>
<p>Contamos con 2 <strong>Brokers</strong> (es el mínimo, para este factor de replicación)</p>
</li>
<li>
<p>¿Cuántos <strong>Logs</strong> vamos a tener?</p>
<div class="ulist">
<ul>
<li>
<p>Número de topics X Número de particiones X Factor de replicación</p>
</li>
<li>
<p>4 X 20 X 2 = 160 Logs</p>
</li>
</ul>
</div>
</li>
<li>
<p>¿Cuántos logs vamos a tener por Broker?</p>
<div class="ulist">
<ul>
<li>
<p>160 Logs / 2 Brokers = 80 Logs por Broker</p>
</li>
</ul>
</div>
</li>
<li>
<p>Vamos a calcular cual es la cuota máxima que podemos usar en disco.</p>
<div class="ulist">
<ul>
<li>
<p>Si nuestros Brokers disponen de un disco duro con unos 450 GB libres.</p>
</li>
<li>
<p>Espacio disponible / Logs por Broker = Tamaño máximo por Log</p>
</li>
<li>
<p>450 / 80 = 5.635 &#8594; redondeamos a 5 GB para tener margen</p>
</li>
<li>
<p>Cada fichero de Log puede llegar a ocupar hasta 5 GB.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Para gestionar el espacio en disco, podemos activar la limpieza de ficheros de Log:</p>
<div class="ulist">
<ul>
<li>
<p><strong>log.cleaner.enable</strong> &#8594; lo pondremos a true para activar la limpieza</p>
</li>
<li>
<p><strong>log.retention.bytes</strong> &#8594; Indicaremos (en bytes) el espacio máximo de cada Log</p>
</li>
<li>
<p><strong>log.segment.bytes</strong> &#8594; un Log puede a su vez estar dividido en distintos ficheros más pequeños, esto especifica el tamaño máximo de cada uno. Cuando superemos el máximo total, borraremos el segmento más antiguo.</p>
</li>
<li>
<p><strong>log.retention.check.interval.ms</strong> &#8594; Cada cuanto tiempo revisamos si se ha superado el tamaño máximo (Por esto debemos dejar cierto margen)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.cleaner.enable=true
log.retention.bytes=5368709120
log.segment.bytes=1073741824
log.retention.check.interval.ms=30000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A demás de una política de espacios, podemos configurar otra política, especificando un tiempo máximo que vamos a mantener los mensajes. Para ello, usaremos las siguientes propiedades:</p>
<div class="ulist">
<ul>
<li>
<p><strong>log.cleaner.enable</strong> &#8594; lo pondremos a true para activar la limpieza</p>
</li>
<li>
<p><strong>log.retention.hours</strong> &#8594; Indicaremos (en horas) el máximo de tiempo que vamos a almacenar (hay opciones de configurar otras unidades de tiempo)</p>
</li>
<li>
<p><strong>log.segment.bytes</strong> &#8594; un Log puede a su vez estar dividido en distintos ficheros más pequeños, esto especifica el tamaño máximo de cada uno. Cuando superemos el máximo total, borraremos el segmento más antiguo.</p>
</li>
<li>
<p><strong>log.retention.check.interval.ms</strong> &#8594; Cada cuanto tiempo revisamos si se ha superado el tiempo máximo</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.cleaner.enable=true
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=30000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ambas políticas pueden estar conviviendo juntas, que es de especial utilidad para cuando estimamos una carga de datos semanal que no debería llenar nuestro disco, pero establecemos un límite por si se llega a saturar el sistema (siempre es mejor perder los datos más antiguos que dejar de dar servicio)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.cleaner.enable=true
log.retention.hours=168
log.retention.bytes=5368709120
log.segment.bytes=1073741824
log.retention.check.interval.ms=30000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una última directiva de configuración que puede resultar interesante, a nivel de <strong>broker</strong> es:</p>
<div class="ulist">
<ul>
<li>
<p><strong>controlled.shutdown.enable=true</strong>: Esta configuración asegura un apagado correcto, que evita pérdidas de datos.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Hay que tener en cuenta que cuando se apaga un <strong>broker</strong>, las particiones líderes que tenía dicho <strong>broker</strong> sufren una indisponibilidad (hasta que son reasignados).</p>
</li>
<li>
<p>Con esta configuración, el <strong>broker</strong> al recibir la señal de finalización, persiste los mensajes que todavía tuviera en memoria, y luego se asegura que otro <strong>Broker</strong> haya cogido sus particiones líderes antes de apagarse.</p>
</li>
<li>
<p>El apagado tarda ligeramente más, pero las mejoras de disponibilidad del sistema lo compensan con creces.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_optimización">7.2. Optimización</h3>
<div class="ulist">
<ul>
<li>
<p>Kafka posee una serie de configuraciones que se pueden cambiar en tres niveles:</p>
<div class="ulist">
<ul>
<li>
<p>read-only: Implica que se debe cambiar en el fichero de configuración de kafka server.properties y reiniciar el servicio</p>
</li>
<li>
<p>per-broker: Se cambia desde kafka-configs indicando el id de broker a modificar (entity-name)</p>
</li>
<li>
<p>cluster-wide: Permite indicar el valor por defecto a nivel de todo el cluster.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_message_max_bytes">7.2.1. message.max.bytes</h4>
<div class="ulist">
<ul>
<li>
<p>Por defecto 1000012 (1MB)</p>
</li>
<li>
<p>El tamaño comprimido del mensaje de mayor tamaño.</p>
</li>
<li>
<p>Debe estar en consonancia con los consumidores</p>
<div class="ulist">
<ul>
<li>
<p>La directiva en consumidores es: <strong>fetch.message.max.bytes</strong></p>
</li>
<li>
<p>Debemos asegurarnos de que message.max.bytes es mayor o igual que fetch.message.max.bytes, ya que sino, el consumidor esperará un mensaje que el productor no puede enviar.</p>
</li>
<li>
<p>Se puede sobreescribir desde los topics con max.message.bytes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_num_replica_fetchers">7.2.2. num.replica.fetchers</h4>
<div class="ulist">
<ul>
<li>
<p>Permite definir el número de hilos que se encargan de replicar los datos del lider a los seguidores.</p>
</li>
<li>
<p>Según el número de particiones del broker y réplicas en otros, podemos calcular el número de hilos óptimo a utilizar.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_replica_fetch_max_bytes">7.2.3. replica.fetch.max.bytes</h4>
<div class="ulist">
<ul>
<li>
<p>Permite indicar el tamaño del paquete a sincronizar.</p>
</li>
<li>
<p>Si se incrementa, tardará menos en sincronizar los followers</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_replica_socket_receive_buffer_bytes">7.2.4. replica.socket.receive.buffer.bytes</h4>
<div class="ulist">
<ul>
<li>
<p>Permite incrementar el buffer y reducir el número de hilos para la creación de la réplicas.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_num_partitions">7.2.5. num.partitions</h4>
<div class="ulist">
<ul>
<li>
<p>Por defecto poseemos un valor, sin embargo se puede especificar en cada topic.</p>
</li>
<li>
<p>Hay que tener en cuenta que un elevado número de particiones con pocos brokers pueden producir un cuello de botella en el sistema.</p>
</li>
<li>
<p>Este cálculo debe ser proporcional a los recursos que disponemos.</p>
</li>
<li>
<p>Si permitimos la creación automática de topics, es importante que definamos el número de particiones según nuestras necesidades genéricas.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_num_io_threads">7.2.6. num.io.threads</h4>
<div class="ulist">
<ul>
<li>
<p>Hilos para lectura/escritura en disco</p>
</li>
<li>
<p>Podemo optimizar el número de hilos según el número de peticiones que recibimos.</p>
</li>
<li>
<p>A más hilos, mas uso de io</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_num_recovery_threads_per_data_dir">7.2.7. num.recovery.threads.per.data.dir</h4>
<div class="ulist">
<ul>
<li>
<p>Por defecto 1.</p>
</li>
<li>
<p>Permite la recuperación de particiones tras una caida.</p>
</li>
<li>
<p>Para su recuperación, usa estos hilos, uno por cada directorio de datos.</p>
</li>
<li>
<p>Tambien cierra los ficheros de forma normal.</p>
</li>
<li>
<p>Tras fallo, puede retrasar la recuperación del servidor mucho tiempo.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_creación_de_un_clúster_multi_broker">7.3. Lab: Creación de un Clúster Multi-Broker</h3>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>El zookeeper debe estar iniciado para continuar la práctica.</p>
</li>
<li>
<p>Para ello, iniciamos zookeeper si no lo está usando el siguiente comando</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Para la siguiente práctica, vamos a crear un clúster en nuestra máquina virtual.</p>
</li>
<li>
<p>Esta misma práctica se puede (y sería mucho más provechosa) realizar con múltiples instancias de máquinas virtuales para crear un clúster de verdad.</p>
</li>
<li>
<p>Para ello tan solo tendríamos que sustituir las ips de bucle local por las ips de las VMs</p>
</li>
<li>
<p>Antes de empezar, vamos a dar de alta en el fichero hosts las ips y nombres de las máquinas que van a tener los <strong>brokers</strong> levantados.</p>
</li>
<li>
<p>Para ello editamos el fichero <strong>/etc/hosts/</strong>, y al final del mismo, añadimos las siguientes líneas:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>127.0.0.1   host.broker1
127.0.0.2   host.broker2
127.0.0.3   host.broker3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Guardamos y salimos, y confirmamos que el comando <strong>ping</strong> nos responde a las 3 direcciones.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ ping host.broker1
PING host.broker1 (127.0.0.1) 56(84) bytes of data.
64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.026 ms
...
[kafka@kafka-server ~]$ ping host.broker2
PING host.broker2 (127.0.0.2) 56(84) bytes of data.
64 bytes from host.broker2 (127.0.0.2): icmp_seq=1 ttl=64 time=0.036 ms
...
[kafka@kafka-server ~]$ ping host.broker3
PING host.broker3 (127.0.0.3) 56(84) bytes of data.
64 bytes from host.broker3 (127.0.0.3): icmp_seq=1 ttl=64 time=0.039 ms
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora vamos a hacer 3 copias del fichero <strong>server.properties</strong>, para configurar cada <strong>broker</strong> de manera independiente</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cp ${KAFKA_HOME}/config/server.properties ${KAFKA_HOME}/config/server.properties1
[kafka@kafka-server ~]$ cp ${KAFKA_HOME}/config/server.properties ${KAFKA_HOME}/config/server.properties2
[kafka@kafka-server ~]$ cp ${KAFKA_HOME}/config/server.properties ${KAFKA_HOME}/config/server.properties3</code></pre>
</div>
</div>
<div class="paragraph">
<p>También creamos rutas para guardar los logs de los brokers 1 y 2 (el broker 0 seguirá usando la ruta por defecto)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ mkdir /tmp/kafka-logs{2,3}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Editamos el fichero <strong>$KAFKA_HOME/config/server.propertiesX</strong> y modificamos, descomentamos para que se aplique la directiva y/o comprobamos las siguientes líneas:</p>
<div class="ulist">
<ul>
<li>
<p>broker.id &#8594; Deberá poseer cada fichero su propio id</p>
</li>
<li>
<p>listeners &#8594; Esta propiedad indica donde conectar</p>
</li>
<li>
<p>log.dirs &#8594; Path de los logs del broker</p>
</li>
<li>
<p>zookeeper.connect &#8594; Ruta de zookeeper</p>
</li>
</ul>
</div>
</li>
<li>
<p>A continuación tenemos las líneas para cada uno de los ficheros properties</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">server.properties1</div>
<div class="content">
<pre class="CodeRay highlight"><code>broker.id=0
listeners=PLAINTEXT://host.broker1:9092
log.dirs=/tmp/kafka-logs
zookeeper.connect=localhost:2181</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">server.properties2</div>
<div class="content">
<pre class="CodeRay highlight"><code>broker.id=1
listeners=PLAINTEXT://host.broker2:9092
log.dirs=/tmp/kafka-logs2
zookeeper.connect=localhost:2181</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">server.properties3</div>
<div class="content">
<pre class="CodeRay highlight"><code>broker.id=2
listeners=PLAINTEXT://host.broker3:9092
log.dirs=/tmp/kafka-logs3
zookeeper.connect=localhost:2181</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Recordad, si existe algún <strong>Broker</strong>, matarlo antes con <strong>kill -s TERM $PID</strong> o <strong>kafka-server-stop.sh</strong>:</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties1
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties2
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties3</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>OJO, todos van a escribir las trazas en el mismo fichero ($KAFKA_HOME/logs/server.log).</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Vamos a ver qué ha sucedido en <strong>Zookeeper</strong>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh
[zk: localhost:2181(CONNECTED) 0] ls /brokers/ids
[0, 1, 2]
[zk: localhost:2181(CONNECTED) 1] get /brokers/ids/0
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://host.broker1:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;host.broker1&quot;,&quot;timestamp&quot;:&quot;1548179115649&quot;,&quot;port&quot;:9092,&quot;version&quot;:4}
[...]
[zk: localhost:2181(CONNECTED) 2] get /brokers/ids/1
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://host.broker2:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;host.broker2&quot;,&quot;timestamp&quot;:&quot;1548179118553&quot;,&quot;port&quot;:9092,&quot;version&quot;:4}
[...]
[zk: localhost:2181(CONNECTED) 3] get /brokers/ids/2
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://host.broker3:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;host.broker3&quot;,&quot;timestamp&quot;:&quot;1548179212478&quot;,&quot;port&quot;:9092,&quot;version&quot;:4}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos que se han dado de alta correctamente.</p>
</li>
<li>
<p>Vamos a crear dos nuevos <strong>Topic</strong>, uno con factor de replicación 1 y otro con 3, el máximo definido por el número de <strong>brokers</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic-cluster-no-ha --partitions 3 --replication-factor 1
Created topic topic-cluster-no-ha.
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic-cluster-si-ha --partitions 3 --replication-factor 3
Created topic topic-cluster-si-ha.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a confirmar que los <strong>Topics</strong> se han creado correctamente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --list
__consumer_offsets
base-topic
base-topic2
topic-cluster-no-ha
topic-cluster-si-ha</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos la información de los dos <strong>Topics</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-cluster-no-ha
Topic:topic-cluster-no-ha        PartitionCount:3        ReplicationFactor:1        Configs:
        Topic: topic-cluster-no-ha        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topic-cluster-no-ha        Partition: 1        Leader: 1        Replicas: 1        Isr: 1
        Topic: topic-cluster-no-ha        Partition: 2        Leader: 2        Replicas: 2        Isr: 2
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-cluster-si-ha
Topic:topic-cluster-si-ha        PartitionCount:3        ReplicationFactor:3        Configs:
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 1,2,0
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 2        Replicas: 2,0,1        Isr: 2,0,1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Este es el aspecto esperado.</p>
</li>
<li>
<p>Nos informa de dónde están las réplicas y si están sincronizadas, y vemos que las particiones <strong>Leader</strong> se han balanceado entre los <strong>Brokers</strong>.</p>
</li>
<li>
<p>Ahora tenemos varios <strong>Brokers</strong>, así que podemos ver el aspecto que tiene mi antiguo <strong>Topic</strong>, que tenía 5 particiones y todas estaban en el mismo <strong>Broker</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic base-topic2
Topic:base-topic2        PartitionCount:5        ReplicationFactor:1        Configs:
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pero ¿qué ha pasado? ¿Por qué no están las particiones distribuidas entre los distintos <strong>Brokers</strong> ?</p>
</li>
<li>
<p>Por defecto, <strong>no se realiza balanceo de Particiones</strong>, se puede configurar para que se haga cada cierto tiempo o realizarse de manera manual, pero por defecto no está así.</p>
</li>
<li>
<p>Algo interesante es ver qué pasaría si uno de mis <strong>Brokers</strong> se cae.</p>
</li>
<li>
<p>Vamos a matar alguno de ellos (Obtener con un <strong>ps -edaf|grep -i kafka</strong> o con jps)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ jps
5120 QuorumPeerMain
9206 Kafka
9558 Kafka
13126 Jps
10344 Kafka

[kafka@kafka-server ~]$ kill 10344</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>¿Qué ha sucedido ahora con mi <strong>Topic</strong>?</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-cluster-si-ha
Topic:topic-cluster-si-ha        PartitionCount:3        ReplicationFactor:3        Configs:
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 1,0
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 0        Replicas: 2,0,1        Isr: 0,1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como podéis ver, el Broker 2 ya no está en sincronía (no aparece en la lista de <strong>Isr</strong>).</p>
</li>
<li>
<p>Además, como está caído, la partición que tenía asignada se ha reasignado a un nuevo <strong>Broker</strong> (Ahora el <strong>Broker 0</strong> tiene las réplicas líderes de la partición 1 y 2).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Si vuelvo a levantar mi <strong>Broker</strong>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Vemos que la situación del <strong>Topic</strong> se ha "corregido", ya está en sincronía.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-cluster-si-ha
Topic:topic-cluster-si-ha        PartitionCount:3        ReplicationFactor:3        Configs:
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 1,0,2
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 0        Replicas: 2,0,1        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Sin embargo, no se le ha "devuelto" la réplica líder. Tenemos 1 Broker con 1 partición, 1 Broker con 2 particiones, y 1 Broker con 0. Como ya dijimos anteriormente, las particiones no se balancean automáticamente.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Paramos los brokers</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-stop.sh</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_configuración_del_topic">7.4. Configuración del Topic</h3>
<div class="ulist">
<ul>
<li>
<p>Ya hemos visto anteriormente cómo crear un <strong>Topic</strong>, mediante el uso del comando <strong>kafka-topics.sh</strong>, vamos a ver con más detalle cómo funciona el comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic nombre-topic --partitions 4 --replication-factor 2 --config propiedad=valor</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Argumentos:</p>
<div class="ulist">
<ul>
<li>
<p><strong>--bootstrap-server host:puerto</strong> &#8594; Es necesario indicar dónde está el broker de kafka</p>
</li>
<li>
<p><strong>--create</strong> &#8594; Indicamos que vamos a crear un <strong>Topic</strong></p>
</li>
<li>
<p><strong>--topic nombre</strong> &#8594; Damos nombre al <strong>Topic</strong> (cuidado, los guiones bajos y pueden colisionar)</p>
</li>
<li>
<p><strong>--partitions n</strong> &#8594; Indicamos el número de particiones que queremos crear para dicho <strong>Topic</strong></p>
</li>
<li>
<p><strong>--replication-factor n</strong> &#8594; Indicamos el número de réplicas que queremos</p>
</li>
<li>
<p><strong>--config propiedad=valor</strong> &#8594; permite cambiar los valores de otras propiedades</p>
</li>
</ul>
</div>
</li>
<li>
<p>Los <strong>Topics</strong> se pueden eliminar (aunque para ello, debemos tener activada en el fichero de configuración <strong>server.properties</strong> la propiedad <strong>delete.topic.enable=true</strong>, si no, lo ignora).</p>
</li>
<li>
<p>Para borrar un <strong>Topic</strong>, usaremos la opción <strong>--delete</strong> del comando <strong>kafka-topics.sh</strong>.</p>
</li>
<li>
<p>El siguiente ejemplo muestra cómo se borraría un <strong>Topic</strong> de nombre <strong>topic-a-borrar</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic topic-a-borrar</code></pre>
</div>
</div>
<div class="paragraph">
<p>Una vez hemos creado el <strong>Topic</strong>, podemos cambiar su configuración mediante la opción <strong>--alter</strong>, a la que debemos añadir el cambio que queramos hacer (con <strong>--config propiedad=valor</strong>)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic un-topic --config propiedad=valor</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando no hemos especificado el valor de una propiedad, usa los valores por defecto para la misma. Si queremos quitar la configuración que hemos añadido y dejar sus valores por defecto, podemos usar <strong>--alter</strong> con la opción <strong>--delete-config propiedad</strong></p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En versiones anteriores a Kafka 0.9, era <strong>--deleteConfig</strong>)</p>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic un-topic --delete-config propiedad</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para añadir particiones, podemos hacer uso de <strong>--alter</strong> con la opción <strong>--partitions n</strong>, siendo <strong>n</strong> el número de particiones que queremos añadir.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic un-topic --partitions 20</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Un punto importante es que <strong>No se pueden disminuir particiones</strong>.</p>
</li>
<li>
<p>Disminuir particiones implicaría la pérdida de datos, y por lo tanto no se contempla esto.</p>
</li>
<li>
<p>También tenemos que tener en cuenta que ampliar las particiones hace que los mensajes asignados anteriormente, puedan no estar asignados a la partición correspondientes.</p>
</li>
<li>
<p>Es recomendable crear particiones de más al crear un <strong>Topic</strong>, para evitar estos problemas.</p>
</li>
<li>
<p>Cambiar las réplicas de un <strong>Topic</strong> es más complicado.</p>
</li>
<li>
<p>Hay que usar la utilidad <strong>kafka-reassign-partitions.sh</strong> y exige aportar un documento en el que especificamos para cada partición, en qué brokers queremos depositar las réplicas.</p>
</li>
<li>
<p>Por ejemplo, para un <strong>Topic</strong> que tuviera dos particiones y factor de replicación 1, podría aumentar las réplicas del <strong>topic</strong> para que estuvieran en los brokers 0, 1 y 2 con el siguiente JSON:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{<span class="key"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">partitions</span><span class="delimiter">&quot;</span></span>:[
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicAlgo</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">0</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]},
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicAlgo</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]},
]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para aplicar estos cambios (imagninando que nuestro fichero se llama cambio-replicas.json), haríamos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file cambio-replicas.json --execute</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos verificar que esto se ha realizado correctamente a través de la misma utilidad, con la opción <strong>--verify</strong> en lugar de <strong>--execute</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file cambio-replicas.json --verify</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el tema anterior hablamos del <strong>Log Compaction</strong>.</p>
</li>
<li>
<p>Esto, se debe configurar a nivel de <strong>topic</strong>, pero para poder hacer uso de ello hay que tener activado en el fichero de configuración <strong>server.properties</strong> la opción <strong>log.cleaner.enable=true</strong>.</p>
</li>
<li>
<p>Podemos crear directamente un <strong>topic</strong> con dicha configuración mediante el parámetro <strong>--create</strong> con la opción <strong>--config cleanup.policy=compact</strong>, o bien alterar uno existente con el parámetro <strong>--alter</strong> con la opción <strong>--config cleanup.policy=compact</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topicNuevo --config cleanup.policy=compact --partitions 4 --replication-factor 3
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic topicExistente --config cleanup.policy=compact</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_lab_configurar_particiones_y_réplicas">7.5. Lab: Configurar particiones y réplicas</h3>
<div class="ulist">
<ul>
<li>
<p>Para este ejercicio necesitamos tener levantado <strong>Zookeeper</strong>, y un <strong>Broker</strong> de <strong>Kafka</strong>.</p>
</li>
<li>
<p>Antes de levantar el <strong>Broker</strong> de <strong>Kafka</strong> vamos a copiar la plantilla de fichero <strong>server.properties</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cp ${KAFKA_HOME}/config/server.properties1 ${KAFKA_HOME}/config/server.properties.topics</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Activamos las opciones de cleaner y delete topic en el fichero server.properties.topics:</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>En las últimas versiones, el log cleaner está activado por defecto.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.cleaner.enable=true
delete.topic.enable=true</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez hecho esto, levantamos el <strong>Broker</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties.topics</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un <strong>Topic</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topicEjemploConf1 --partitions 1 --replication-factor 1
Created topic &quot;topicEjemploConf1&quot;.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Consultamos su configuración y vemos que se ha creado correctamente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topicEjemploConf1
Topic:topicEjemploConf1        PartitionCount:1        ReplicationFactor:1        Configs:
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Incrementamos el número de particiones:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic topicEjemploConf1 --partitions 3
WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected
Adding partitions succeeded!</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Confirmamos que se han creado correctamente</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topicEjemploConf1
Topic:topicEjemploConf1        PartitionCount:3        ReplicationFactor:1        Configs:
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos ahora a borrar un <strong>Topic</strong>, concretamente el que creamos al principio del curso.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Hemos tenido que añadir en el <strong>server.properties</strong> la opción <strong>delete.topic.enable=true</strong></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic base-topic
Topic base-topic is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como vemos, el borrado no es inmediato, se marca para borrar. Cuando haga un limpiado, borrará el <strong>Topic</strong>.</p>
</li>
<li>
<p>El próximo ejercicio consta en crear un nuevo topic con la misma configuración que topicEjemploConf1 y levantar los brokers 1 y 2 para ampliar las réplicas del topic recien creado a 2.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Levantamos los nodos 1 y 2</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties2
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties3
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topicRecienCreado --partitions 3 --replication-factor 1
Created topic &quot;topicRecienCreado&quot;.</code></pre>
</div>
</div>
<div class="paragraph">
<p>Creamos un fichero <strong>Json</strong> de nombre cambio.json con el siguiente contenido</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">partitions</span><span class="delimiter">&quot;</span></span>:[
    {
      <span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicRecienCreado</span><span class="delimiter">&quot;</span></span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">0</span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>]
    },{
      <span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicRecienCreado</span><span class="delimiter">&quot;</span></span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">1</span>,<span class="integer">2</span>]
    }]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Aplicamos el cambio (como el nombre del topic va en el json, no se tiene que especificar en el comando):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file cambio.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;topicRecienCreado&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;topicRecienCreado&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started partition reassignments for topicRecienCreado-0,topicRecienCreado-1</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>En la mayoría de scripts de administración se ha deprecado el uso de la directiva --zookeeper para desacoplar de los metadatos las operaciones, siendo sustituido por el --bootstrap-server apuntando a un broker.</p>
</li>
<li>
<p>Todavía es posible usar la directiva --zookeeper, pero dará un aviso de deprecación.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Verificamos que está todo bien:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topicRecienCreado
Topic:topicRecienCreado        PartitionCount:3        ReplicationFactor:1        Configs:
        Topic: topicRecienCreado        Partition: 0        Leader: 0        Replicas: 0,1        Isr: 0,1
        Topic: topicRecienCreado        Partition: 1        Leader: 1        Replicas: 1,2        Isr: 2,1
        Topic: topicRecienCreado        Partition: 2        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Aquí ha terminado el laboratorio. A continuación se muestran posibilidades de operaciones que podemos realizar.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Las opciones que se pueden configurar están en la documentación, aunque también pueden obtenerse si llamamos a <strong>kafka-topic.sh</strong> sin parámetros:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh
Create, delete, describe, or change a topic.
Option                                   Description
------                                   -----------
--alter                                  Alter the number of partitions,
                                           replica assignment, and/or
                                           configuration for the topic.
--at-min-isr-partitions                  if set when describing topics, only
                                           show partitions whose isr count is
                                           equal to the configured minimum. Not
                                           supported with the --zookeeper
                                           option.
--bootstrap-server &lt;String: server to    REQUIRED: The Kafka server to connect
  connect to&gt;                              to. In case of providing this, a
                                           direct Zookeeper connection won't be
                                           required.
...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos configurar un <strong>Topic</strong> para indicar que el tamaño máximo de los mensajes que puede albergar es de <strong>128 KB</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic topicLimitado --config max.message.bytes=128000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si quisiéramos eliminar esta configuraación que acabamos de aplicar, podemos hacerlo con <strong>--delete-config</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic topicLimitado --delete-config max.message.bytes</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Algunas configuraciones interesantes que no hemos revisado pero son bastante comunes son:</p>
<div class="ulist">
<ul>
<li>
<p><strong>cleanup.policy</strong> &#8594; Puede ser <strong>delete</strong> o <strong>compact</strong></p>
</li>
<li>
<p><strong>max.message.bytes</strong> &#8594; La vimos en la transparencia anterior, es el tamaño máximo de los mensajes de dicho topic</p>
</li>
<li>
<p><strong>retention.bytes</strong> &#8594; Tamaño máximo que un log puede crecer antes de que se aplique la política de borrado</p>
</li>
<li>
<p><strong>min.insync.replicas</strong> &#8594; El número de réplicas que deben dar su <strong>ACK</strong> antes de devolver el ok al productor</p>
</li>
<li>
<p><strong>flush.messages</strong> &#8594; Cada cuántos mensajes forzamos un fsync para escribir en disco a un log. Si ponemos 5, cada 5 mensajes forzará un fsync (se recomienda dejar esto al sistema operativo)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_configuración_de_producers">7.6. Configuración de Producers</h3>
<div class="ulist">
<ul>
<li>
<p>Las configuraciones que vamos a ver para los <strong>Productores</strong> son:</p>
<div class="ulist">
<ul>
<li>
<p><strong>bootstrap.servers</strong> &#8594; Lista de Brokers</p>
</li>
<li>
<p><strong>key.serializer</strong> &#8594; Clase para serializar la clave</p>
</li>
<li>
<p><strong>value.serializer</strong> &#8594; Clase para serializar el valor</p>
</li>
<li>
<p><strong>retries</strong> &#8594; Reintentos de envío</p>
</li>
<li>
<p><strong>ack</strong> &#8594; Número de respuestas ack que esperamos</p>
</li>
<li>
<p><strong>compression.type</strong> &#8594; Tipo de compresión</p>
</li>
<li>
<p><strong>batch.size</strong> &#8594; Mensajes que se acumulan antes del envío</p>
</li>
<li>
<p><strong>linger.ms</strong> &#8594; Tiempo máximo de espera para envío</p>
</li>
<li>
<p><strong>client.id</strong> &#8594; Identificador del cliente</p>
</li>
<li>
<p><strong>partitioner.class</strong> &#8594; Clase para el particionado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>bootstrap.servers</strong>: La lista de <strong>Brokers</strong>, separados por coma, indicando los puertos en los que están escuchando. Nuestro <strong>productor</strong> se pondrá en contacto con un <strong>broker</strong> de esta lista para crear el mapa de particionados.</p>
</li>
<li>
<p><strong>key.serializer</strong>: La clase que se debe utilizar por este <strong>productor</strong> para serializar la clave del mensaje. En nuestros ejemplos serializábamos los mensajes directamente como <strong>Strings</strong>. <strong>Kafka</strong> posee varios serializadores ya incluídos:</p>
<div class="ulist">
<ul>
<li>
<p>String &#8594; org.apache.kafka.common.serialization.StringSerializer</p>
</li>
<li>
<p>Long &#8594; org.apache.kafka.common.serialization.LongSerializer</p>
</li>
<li>
<p>Integer &#8594; org.apache.kafka.common.serialization.IntegerSerializer</p>
</li>
<li>
<p>Double &#8594; org.apache.kafka.common.serialization.DoubleSerializer</p>
</li>
<li>
<p>Bytes &#8594; org.apache.kafka.common.serialization.BytesSerializer</p>
</li>
<li>
<p>ByteArray &#8594; org.apache.kafka.common.serialization.ByteArraySerializer</p>
</li>
<li>
<p>ByteBuffer &#8594; org.apache.kafka.common.serialization.ByteBufferSerializer</p>
</li>
</ul>
</div>
</li>
<li>
<p>Podemos crear nuestro propio serializador, implementando el interfaz <strong>Serializer&lt;T&gt;</strong> (org.apache.kafka.common.serialization.Serializer), si queremos usar nuestros propios tipos en los mensajes.</p>
</li>
<li>
<p><strong>value.serializer</strong>: La clase que se usa para serializar el valor de los mensajes. Al igual que en el caso anterior, podemos hacer uso de una de las clases predefinidas o implementar nuestra propia serialización</p>
</li>
<li>
<p><strong>retries</strong>: Número de intentos que se van a realizar de enviar un mensaje. Cuidado, podemos obtener un fallo y eso no quiere decir que nuestro mensaje no se haya enviado (sencillamente que no se nos ha confirmado), con lo que se podría dar la situación de que enviáramos el mismo mensaje (podríamos duplicar mensajes)</p>
</li>
<li>
<p><strong>ack</strong>: Podemos configurar nuestros <strong>productores</strong> para esperar un número concreto de respuestas antes de dar por buena la escritura. Algunos valores son:</p>
<div class="ulist">
<ul>
<li>
<p>0 &#8594; "fire and forget", no esperamos confirmación. Es el que mayor rendimiento ofrece, pero el más susceptible a errores.</p>
</li>
<li>
<p>1 &#8594; Sólo esperamos la respuesta de la partición líder</p>
</li>
<li>
<p>all &#8594; Esperamos la respuesta de todas las réplicas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>compression.type</strong> &#8594; Podemos realizar compresión a la hora de enviar nuestros mensajes (aunque por defecto no se realiza). Por cierto, los topics también se pueden configurar para que guarden comprimidos los datos</p>
<div class="ulist">
<ul>
<li>
<p>none &#8594; No se realiza compresión</p>
</li>
<li>
<p>gzip &#8594; Compresión gzip</p>
</li>
<li>
<p>snappy &#8594; Compresión snappy</p>
</li>
<li>
<p>lz4 &#8594; Compresión lz4</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>batch.size</strong>: Número de mensajes que van a agruparse antes de realizar el envío. Un valor de 1 envía todos los mensajes automáticamente según se generen.</p>
</li>
<li>
<p><strong>linger.ms</strong>: Tiempo máximo de espera antes del envío. Si este tiempo se cumple, los mensajes se envíen aunque no hayan alcanzado el número definido por <strong>batch.size</strong></p>
</li>
<li>
<p><strong>client.id</strong>: Es el identificador de cliente. Aunque existan varios <strong>productores</strong>, si todos comparten el mismo <strong>client.id</strong>, <strong>Kafka</strong> los considera el mismo cliente. Es de especial utilidad para definir cuotas.</p>
</li>
<li>
<p>En el siguiente ejemplo vemos cómo se define una cuota de tasa de producción para el cliente "clienteAlgo" de 1024 bytes por segundo (si supera esta tasa, <strong>kafka</strong> relentizará el cliente para no superarla):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-configs.sh --zookeeper localhost:2181 --alter --add-config 'producer_byte_rate=1024' --entity-name clienteAlgo --entity-type clients</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>partitioner.class</strong>: Por último, indicar que a la hora de enviar mensajes, estos van a acabar en una partición. Tenemos dos opciones:</p>
<div class="ulist">
<ul>
<li>
<p>Indicar explícitamente para cada mensaje en qué partición queremos que acabe.</p>
</li>
<li>
<p>Usar un sistema de particionado.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Kafka</strong> posee un particionador por defecto (basado en la clave hash obtenida mediante murmur3), pero podemos implementar nuestro propio particionador implementando el interfaz <strong>Partitioner</strong> (org.apache.kafka.clients.producer.Partitioner), y por supuesto especificando su uso en <strong>partitioner.class</strong>.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_configuración_de_consumers">7.7. Configuración de Consumers</h3>
<div class="ulist">
<ul>
<li>
<p>Las configuraciones que vamos a ver para los <strong>Consumidores</strong> son:</p>
<div class="ulist">
<ul>
<li>
<p><strong>bootstrap.servers</strong> &#8594; Lista de Brokers (análogo a la del productor)</p>
</li>
<li>
<p><strong>key.deserializer</strong> &#8594; Clase para deserializar la clave (análogo a la del productor)</p>
</li>
<li>
<p><strong>value.deserializer</strong> &#8594; Clase para deserializar el valor (análogo a la del productor)</p>
</li>
<li>
<p><strong>group.id</strong> &#8594; Identificador del grupo de consumidores</p>
</li>
<li>
<p><strong>enable.auto.commit</strong> &#8594; Control automático del offset</p>
</li>
<li>
<p><strong>auto.commit.interval.ms</strong> &#8594; Cada cuantos milisegundos se actualiza el control del offset</p>
</li>
<li>
<p><strong>auto.offset.reset</strong> &#8594; Para indicar dónde empieza un cliente nuevo</p>
</li>
<li>
<p><strong>client.id</strong> &#8594; Identificador del cliente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>group.id</strong>: Servía para identificar un grupo de consumidores. Las instancias del consumidor que posean un mismo <strong>group.id</strong>, se reparten las particiones para procesar los mensajes de forma escalable. Los consumidores con distintos <strong>group.id</strong>, leerán los mismos mensajes.</p>
</li>
<li>
<p><strong>enable.auto.commit</strong>: Los clientes llevan un control de los mensajes leídos, para ello sencillamente tienen que recordar el último <strong>offset</strong> procesado para continuar (en caso de caída o parada, cuando vuelven a ejecutarse) donde lo habían dejado. Este control puede ser manual (hacemos desde la aplicación el control y guardamos el <strong>offset</strong> en momentos concretos), pero normalmente se hace de forma automática. Activando esta opción, hacemos que cada cierto tiempo, se guarde información del último <strong>offset</strong> leído.</p>
</li>
<li>
<p><strong>auto.commit.interval.ms</strong>: Cada cuánto tiempo se actualiza la información de los offsets</p>
</li>
<li>
<p><strong>auto.offset.reset</strong>: Cuando un cliente nuevo empieza a leer mensajes por primera vez, no hay información del último <strong>offset</strong> procesado. Tenemos dos opciones, leer desde el principio de los tiempos, o leer sólo los nuevos mensajes</p>
<div class="ulist">
<ul>
<li>
<p>smallest &#8594; Leemos desde el primer mensaje (como cuando usábamos la opción "--from-beginning" en "kafka-console-consumer.sh")</p>
</li>
<li>
<p>largest &#8594; Sólo leemos los mensajes nuevos (desde que mi cliente se levantó).</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>client.id</strong>: Es el identificador de cliente. Aunque existan varios <strong>consumidores</strong>, si todos comparten el mismo <strong>client.id</strong>, <strong>Kafka</strong> los considera el mismo cliente. Es de especial utilidad para definir cuotas.</p>
</li>
<li>
<p>En el siguiente ejemplo vemos cómo se define una cuota de tasa de consumo para el cliente "clienteAlgo" de 1024 bytes por segundo (si supera esta tasa, <strong>kafka</strong> relentizará el cliente para no superarla):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-configs.sh --zookeeper localhost:2181 --alter --add-config 'consumer_byte_rate=1024' --entity-name clienteAlgo --entity-type clients</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como se puede ver, es análogo al ejemplo en el que poníamos una cuota al productor, pero en este caso al cliente le añadimos la opción "consumer_byte_rate"</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_operaciones_con_kafka">8. Operaciones con Kafka</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_utilidades_y_herramientas">8.1. Utilidades y herramientas</h3>
<div class="ulist">
<ul>
<li>
<p>En este apartado vamos a ver 4 herramientas que vienen proporcionadas por <strong>Kafka</strong>, que son bastante útiles en distintos escenarios:</p>
<div class="ulist">
<ul>
<li>
<p><strong>kafka-preferred-replica-election.sh</strong> &#8594; Para balancear las particiones líderes. Deprecado.</p>
</li>
<li>
<p><strong>kafka-leader-election.sh</strong> &#8594; Sustituye al anterior.</p>
</li>
<li>
<p><strong>kafka-mirror-maker.sh</strong> &#8594; Para copiar datos de un clúster a otro</p>
</li>
<li>
<p><strong>kafka-replay-log-producer.sh</strong> &#8594; Para reproducir los mensajes de un Topic en otro</p>
</li>
<li>
<p><strong>kafka-replica-verification.sh</strong> &#8594; Para verificar la validez de las réplicas</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_kafka_preferred_replica_election_sh_deprecada">8.1.1. kafka-preferred-replica-election.sh (deprecada)</h4>
<div class="ulist">
<ul>
<li>
<p>Como ya vimos anteriormente, <strong>Kafka</strong> sólo balancea las particiones líderes en el momento de la creacion.</p>
</li>
<li>
<p>Este balanceo, puede dejar de ser el adecuado al añadir nuevos brokers o al retirar o apagarlos.</p>
</li>
<li>
<p>Para solucionar esto, tenemos la utilidad <strong>kafka-preferred-replica-election.sh</strong>, que balanceará las particiones líderes entre los distintos <strong>brokers</strong>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-preferred-replica-election.sh --zookeeper localhost:2181</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hay que tener una cosa en cuenta, balancea las particiones líderes entre los distintos <strong>brokers</strong> siguiendo una definición de "réplica favorita" propia de <strong>kafka</strong>.</p>
</li>
<li>
<p>También tenemos que considerar que, si no hay réplicas en otros <strong>brokers</strong>, <strong>NO</strong> se va a usar otro <strong>broker</strong> como partición <strong>líder</strong>, ya que no tiene réplica de dicha partición.</p>
</li>
<li>
<p>Si queremos que este procedimiento se haga automáticamente (no bajo demanda), debemos agregar la siguiente línea en el fichero de configuración</p>
<div class="ulist">
<ul>
<li>
<p><strong>server.properties</strong> la opción <strong>auto.leader.rebalance.enable</strong>:</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>auto.leader.rebalance.enable=true</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Si lo cambiamos a rebalanceo activo, tendríamos failback, algo no deseable con picos altos de carga.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_leader_election_sh">8.1.2. kafka-leader-election.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Es la herramienta que sustituye a kafka-preferred-replica-election.</p>
</li>
<li>
<p>Posee distintas opciones en las que destacan:</p>
<div class="ulist">
<ul>
<li>
<p><strong>--topic</strong>: Permite definir que topic va a gestionar para la elección de réplicas líderes.</p>
</li>
<li>
<p><strong>--partition</strong>: Indica que partición va a modificar</p>
</li>
<li>
<p><strong>--all-topic-partitions</strong>: Para elegir todas las particiones basado en el tipo de elección.</p>
</li>
<li>
<p><strong>--election-type</strong>: Indica el tipo de elección que se va a realizar:</p>
<div class="ulist">
<ul>
<li>
<p>preferred: La elección solo se realiza si el preferido no es el lider</p>
</li>
<li>
<p>unclean: solo si no hay lider en la partición del topic</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>--path-to-json-file</strong>: Indica un fichero json con la lista de particiones y topics a gestionar</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de fichero JSON para modificar del topic 1 la particion 1 y del topic2 la particion 3</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{<span class="key"><span class="delimiter">&quot;</span><span class="content">partitions</span><span class="delimiter">&quot;</span></span>:
    [
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">topic1</span><span class="delimiter">&quot;</span></span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>: <span class="integer">1</span>},
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">topic2</span><span class="delimiter">&quot;</span></span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>: <span class="integer">3</span>}
    ]
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_mirror_maker_sh">8.1.3. kafka-mirror-maker.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Utilidad que permite copiar datos desde otro clúster <strong>Kafka</strong>.</p>
</li>
<li>
<p>Puede ser de interés si necesitáis realizar un backup, o tener una copia de producción para hacer pruebas.</p>
</li>
<li>
<p>Se invoca con los parámetros:</p>
<div class="ulist">
<ul>
<li>
<p><strong>consumer.config</strong> &#8594; Se le pasa un fichero con la configuración del clúster destino</p>
</li>
<li>
<p><strong>producer.config</strong> &#8594; Se le pasa un fichero con la configuración del clúster origen</p>
</li>
<li>
<p><strong>whitelist</strong> &#8594; los topics que queremos coger (admite expresiones regulares)</p>
</li>
<li>
<p><strong>num.streams</strong> &#8594; Número de hilos para los consumidores</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-mirror-maker.sh --consumer.config consumer.properties --producer.config producer.properties --whitelist testTopic</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_replay_log_producer_sh">8.1.4. kafka-replay-log-producer.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Otra herramienta útil para realizar pruebas.</p>
</li>
<li>
<p>Permite copiar los mensajes de un <strong>topic</strong> a otro, permitiéndonos por ejemplo realizar pruebas de nuestras aplicaciones contra datos reales extraídos de otro <strong>topic</strong>, y reproducir el comportamiento que hubo con los datos de ayer, por ejemplo.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-replay-log-producer.sh --broker-list localhost:9092 --inputtopic topic-input --outputtopic topic-output --threads 1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como se puede ver, en <strong>inputtopic</strong> se especifica el origen, en <strong>outputtopic</strong> el destino, y podemos configurar el número de hilos que se van a dedicar en dicha tarea con <strong>threads</strong></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_replica_verification_sh">8.1.5. kafka-replica-verification.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Nos va a permitir verificar las réplicas existentes de un conjunto de topics, para confirmar que todas tienen los mismos datos.</p>
</li>
<li>
<p>En su versión más simple, lo hace para todos los <strong>topics</strong>, pero el parámetro <strong>--topic-white-list</strong> permite especificar un conjunto de <strong>topics</strong> mediante una expresión regular.</p>
</li>
<li>
<p>Otra opción interesante es <strong>--time</strong>, que permite especificar a partir de qué timestamp realizar la verificación.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-replica-verification.sh --broker-list localhost:9092 --topic-white-list &quot;^to.*a$&quot;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el ejemplo vamos a verificar todos los topic cuyo nombre empiece por 'to', y acabe por la letra 'a'.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_broker_api_versions_sh">8.1.6. kafka-broker-api-versions.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Permite mostrar de un solo vistazo la información de todos los brokers del cluster.</p>
</li>
<li>
<p>La información muestra las instrucciones del api, las versiones existentes y la más moderna soportada por cada broker:</p>
<div class="ulist">
<ul>
<li>
<p>&lt;api(posicion)&gt;: &lt;rango de versiones&gt; [usable: &lt;versión máxima soportada&gt;]</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">kafka-node1.local:9092 (id: 1 rack: null) -&gt; (
        Produce(0): 0 to 8 [usable: 8],
        Fetch(1): 0 to 11 [usable: 11],
        ListOffsets(2): 0 to 5 [usable: 5],
...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si no es soportada, se indica como UNSUPPORTED</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">kafka-node1.local:9092 (id: 1 rack: null) -&gt; (
...
        DeleteTopics(20): UNSUPPORTED,
...</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_consumer_groups_sh">8.1.7. kafka-consumer-groups.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Con esta herramienta podemos listar todos los grupos de consumidores existentes.</p>
</li>
<li>
<p>Permite listarlos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[vagrant<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> kafka-consumer-groups.sh --bootstrap-server localhost:<span class="integer">9092</span> --list
perf-consumer-<span class="integer">59052</span>
perf-consumer-<span class="integer">72644</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Permite describir los offsets del grupo actual.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[vagrant<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> kafka-consumer-groups.sh --bootstrap-server localhost:<span class="integer">9092</span> --describe --group test-consumer-group

Consumer group <span class="string"><span class="delimiter">'</span><span class="content">test-consumer-group</span><span class="delimiter">'</span></span> has no active members.

GROUP               TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
test-consumer-group base-topic2     <span class="integer">0</span>          <span class="integer">5</span>               <span class="integer">5</span>               <span class="integer">0</span>               -               -               -
test-consumer-group base-topic2     <span class="integer">4</span>          <span class="integer">3</span>               <span class="integer">3</span>               <span class="integer">0</span>               -               -               -
test-consumer-group base-topic2     <span class="integer">3</span>          <span class="integer">3</span>               <span class="integer">3</span>               <span class="integer">0</span>               -               -               -
test-consumer-group base-topic2     <span class="integer">2</span>          <span class="integer">1</span>               <span class="integer">1</span>               <span class="integer">0</span>               -               -               -
test-consumer-group base-topic2     <span class="integer">1</span>          <span class="integer">1</span>               <span class="integer">1</span>               <span class="integer">0</span>               -               -               -</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Permite resetear offsets y manipularlos. Existen distintas opciones:</p>
<div class="ulist">
<ul>
<li>
<p>--to-datetime: Permite resetearlo a la fecha indicada</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">kafka-consumer-groups.sh --bootstrap-server kafka-server.local:9092
--group test-group --reset-offsets --all-topics --to-datetime 2017-08-04T00:00:00.000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>--by-duration: Tiempo de regresión. Formato P&lt;dias&gt;DT&lt;horas&gt;H&lt;minutos&gt;M&lt;segundos&gt;S.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">kafka-consumer-groups.sh --bootstrap-server kafka-server.local:9092
--group test-group --reset-offsets --all-topics --by-duration P30DT3H30M0S</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>--to-earliest: Al principio</p>
</li>
<li>
<p>--to-latest: Al último offset disponible.</p>
</li>
<li>
<p>--shift-by: avanza (positivo) o retrocede (negativo) n veces</p>
</li>
<li>
<p>to-current: A la posición actual.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_balanceando_las_particiones">8.2. Lab: Balanceando las particiones</h3>
<div class="ulist">
<ul>
<li>
<p>Para probar esto, vamos a volver a levantar los 3 brokers que habíamos dado de alta en ejercicioes anteriores, y probar a balancear la carga de los topics que habíamos creado.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Debe estar levantado <strong>zookeeper</strong></p>
</li>
<li>
<p>En caso de usar la instalación nativa:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[kafka@kafka-server ~]$ zkServer.sh status
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: standalone</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Levantamos los 3 brokers (tal como se hizo en el tema de configuración, apartado 2)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties1
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties2
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties3</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a ver cuál es el contenido de los <strong>Topics</strong> que teníamos con varias particiones:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe
Topic: topic-cluster-no-ha        PartitionCount: 3        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: topic-cluster-no-ha        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topic-cluster-no-ha        Partition: 1        Leader: 1        Replicas: 1        Isr: 1
        Topic: topic-cluster-no-ha        Partition: 2        Leader: 2        Replicas: 2        Isr: 2
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
Topic: topicRecienCreado        PartitionCount: 3        ReplicationFactor: 2        Configs: segment.bytes=1073741824
        Topic: topicRecienCreado        Partition: 0        Leader: 0        Replicas: 0,1        Isr: 0,1
        Topic: topicRecienCreado        Partition: 1        Leader: 2        Replicas: 1,2        Isr: 2,1
        Topic: topicRecienCreado        Partition: 2        Leader: 2        Replicas: 2        Isr: 2
Topic: __consumer_offsets        PartitionCount: 50        ReplicationFactor: 1        Configs: compression.type=producer,cleanup.policy=compact,segment.bytes=104857600
        Topic: __consumer_offsets        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
...
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0
Topic: topic-cluster-si-ha        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 0        Replicas: 1,2,0        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 0        Replicas: 2,0,1        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como podemos ver, casi todas las particiones líder están en el broker 0. Vamos a intentar reparticionar usando la nueva herramienta kafka-leader-election.sh</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-leader-election.sh --bootstrap-server host.broker1:9092 --election-type preferred --all-topic-partitions
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe
Topic: __consumer_offsets        PartitionCount: 50        ReplicationFactor: 1        Configs: compression.type=producer,cleanup.policy=compact,segment.bytes=104857600
...
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 1        Configs:
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0
Topic: topic-cluster-no-ha        PartitionCount: 3        ReplicationFactor: 1        Configs:
        Topic: topic-cluster-no-ha        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topic-cluster-no-ha        Partition: 1        Leader: 1        Replicas: 1        Isr: 1
        Topic: topic-cluster-no-ha        Partition: 2        Leader: 2        Replicas: 2        Isr: 2
Topic: topic-cluster-si-ha        PartitionCount: 3        ReplicationFactor: 3        Configs:
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 2        Replicas: 2,0,1        Isr: 0,1,2
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 1        Configs:
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
Topic: topicRecienCreado        PartitionCount: 3        ReplicationFactor: 2        Configs:
        Topic: topicRecienCreado        Partition: 0        Leader: 0        Replicas: 0,1        Isr: 0,1
        Topic: topicRecienCreado        Partition: 1        Leader: 1        Replicas: 1,2        Isr: 2,1
        Topic: topicRecienCreado        Partition: 2        Leader: 2        Replicas: 2        Isr: 2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un fichero json llamado <strong>cambiaTopic.json</strong> para reasignar las particiones</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{<span class="key"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">partitions</span><span class="delimiter">&quot;</span></span>:[
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemploConf1</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">0</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]},
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemploConf1</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]},
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemploConf1</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">2</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]}
]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicamos cambio de configuración para el topic</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file cambiaTopic.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started partition reassignments for topicEjemploConf1-0,topicEjemploConf1-1,topicEjemploConf1-2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Miramos cómo queda el topic, balanceamos, y volvemos a ver el estado del topic:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topicEjemploConf1
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 1        Leader: 1        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 2        Leader: 2        Replicas: 0,1,2        Isr: 0,2,1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Balanceamos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-leader-election.sh --bootstrap-server host.broker1:9092 --election-type preferred --all-topic-partitions
Successfully completed leader election (PREFERRED) for partitions topicEjemploConf1-2, topicEjemploConf1-1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y comprobamos como quedan ahora</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topicEjemploConf1
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pero&#8230;&#8203; nos ha cambiado el lider a 0!</p>
</li>
<li>
<p>Bien, <strong>Kafka</strong> tiene el concepto de dónde prefiere el líder.</p>
</li>
<li>
<p>En principio, donde se ubique la primera réplica, será donde <strong>kafka</strong> intente situar la primera réplica, y esto se hace en la creación del <strong>topic</strong>.</p>
</li>
<li>
<p>Es por eso que el <strong>topic-cluster-si-ha</strong> había balanceado correctamente, porque sencillamente había escogido como réplica la primera de la lista, observad:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topicEjemploConf1
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topic-cluster-si-ha
Topic: topic-cluster-si-ha        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 2        Replicas: 2,0,1        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La columna <strong>Leader</strong> y el primer valor de la lista de <strong>Replicas</strong>, coinciden.</p>
</li>
<li>
<p>Si nos fijamos en <strong>__consumer_offsets</strong>, todos están en el broker 0 por el mismo motivo.</p>
</li>
<li>
<p>Vamos a intentar corregir esto, dando una nueva lista de réplicas modificando <strong>cambiaTopic.json</strong></p>
</li>
<li>
<p>Si quisiéramos cambiarlo en versiones anteriores, habría que reasignar las particiones con el siguiente comando</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Contenido de cambiaTopic.json</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{&quot;version&quot;:1, &quot;partitions&quot;:[
        {&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:0, &quot;replicas&quot;:[0,1,2]},
        {&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:1, &quot;replicas&quot;:[1,2,0]},
        {&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:2, &quot;replicas&quot;:[2,1,0]}
]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicamos cambio de configuración para el topic</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file cambiaTopic.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started partition reassignments for topicEjemploConf1-0,topicEjemploConf1-1,topicEjemploConf1-2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y vemos el resultado:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-leader-election.sh --bootstrap-server host.broker1:9092 --election-type preferred --all-topic-partitions
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topicEjemploConf1
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 2        Leader: 2        Replicas: 2,0,1        Isr: 0,2,1</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_crecimiento_de_un_clúster">8.3. Crecimiento de un clúster</h3>
<div class="ulist">
<ul>
<li>
<p>Hemos visto en el punto anterior cómo asigna las particiones líder <strong>kafka</strong>, y hemos podido balancear correctamente las mismas definiendo un fichero con los destinos finales de cada partición de un <strong>topic</strong>, pero ¿es así como vamos a trabajar cada vez que nuestro clúster quiera escalar añadiendo (o incluso) retirando <strong>brokers</strong>?</p>
</li>
<li>
<p>En realidad, <strong>kafka-reassing-partitions.sh</strong> puede facilitarnos la vida más, generando automáticamente un fichero como el que hemos usado en el punto anterior para reasignar las particiones.</p>
</li>
<li>
<p>Si queremos que nos haga este fichero, tan sólo tenemos que indicarle para qué <strong>topics</strong> queremos que nos cree un nuevo particionado (entre todos los <strong>brokers</strong> que le indiquemos).</p>
</li>
<li>
<p>De esta forma, cada vez que añada un nuevo <strong>broker</strong>, yo puedo pedir a <strong>kafka</strong> que me genere un nuevo fichero de particionamiento, y posteriormente, aplicarlo.</p>
</li>
<li>
<p>Para ello, hay que llamar a <strong>kafka-reasign-partitions.sh</strong> con un fichero <strong>JSON</strong> que contenga los <strong>topics</strong> que queramos mover, tal como este:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{&quot;version&quot;:1, &quot;topics&quot;:[
        {&quot;topic&quot;:&quot;topic1&quot;},
        {&quot;topic&quot;:&quot;topic2&quot;},
        [...]
]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con el fichero <strong>JSON</strong> creado, ya sólo nos queda llamar a <strong>kafka-reasign-partitions</strong> indicándole</p>
<div class="ulist">
<ul>
<li>
<p><strong>--topics-to-move-json-file</strong> &#8594; El fichero origen que contenga los topics a mover</p>
</li>
<li>
<p><strong>--broker-list</strong> &#8594; Los broker destino de dichos topics</p>
</li>
<li>
<p><strong>--generate</strong> &#8594; Para que nos genere el fichero <strong>JSON</strong> con el que hacer luego la reasignación (hay que guardarlo)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --zookeeper localhost:2181 --topics-to-move-json-file topics_mover.json --broker-list &quot;1,2,3,4&quot; --generate</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Esto, devolverá un fichero por salida estándar, que tendremos que capturar.</p>
</li>
<li>
<p>Con ese fichero ya podremos llamar a <strong>kafka-reassign-partitions.sh</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file ficheroGenerado.json --execute</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_lab_crecimiento_del_cluster">8.4. Lab: Crecimiento del cluster</h3>
<div class="ulist">
<ul>
<li>
<p>Para probar esto, vamos a volver a tener la misma configuración que en el ejercicio anterior (zookeeper levantado, y los 3 brokers activos).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Tengo un <strong>Topic</strong> que cree al principio llamado <strong>base-topic2</strong>. Está por completo en el broker 0, y no tiene réplicas.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a pedir que distribuya las particiones de este <strong>Topic</strong>, para ello, creo un fichero <strong>JSON</strong> para pedir un nuevo reparticionado con él, de nombre <strong>topicsAMover.json</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{&quot;version&quot;:1, &quot;topics&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;}]}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora, llamo a <strong>kafka-reassign-partitions.sh</strong> con la opción <strong>--topics-to-move-json-file</strong>, pidiéndolo que lo mueva a los brokers 0 y 1</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --topics-to-move-json-file topicsAMover.json --broker-list &quot;0,1&quot; --generate
Current partition replica assignment
{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Proposed partition reassignment configuration
{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]}]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Copiamos lo que figura debajo de <strong>Proposed partitions reassignment configuration</strong> y lo guardamos con el nombre de <strong>nuevasParticiones.json</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]}]}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Podemos usar directamente un comando en <strong>UNIX</strong> para generarme el fichero, sabiendo que está en la línea marcada por awk como 5</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --topics-to-move-json-file topicsAMover.json --broker-list &quot;0,1&quot; --generate|awk 'NR==5 {print $0}' &gt; nuevasParticiones.json</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora lanzo <strong>kafka-reassign-partitions.sh</strong> con el <strong>JSON</strong> generado:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file nuevasParticiones.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions.</code></pre>
</div>
</div>
<div class="paragraph">
<p>Y verifico el resultado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic:base-topic2        PartitionCount:5        ReplicationFactor:1        Configs:
        Topic: base-topic2        Partition: 0        Leader: 1        Replicas: 1        Isr: 1
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 1        Replicas: 1        Isr: 1
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 1        Replicas: 1        Isr: 1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>¿Podéis volver a dejar el topic como estaba, todo en el broker 0?</p>
</li>
<li>
<p>Solución:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --topics-to-move-json-file topicsAMover.json --broker-list &quot;0&quot; --generate|awk 'NR==5 {print $0}' &gt; nuevasParticiones2.json
[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file nuevasParticiones2.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions.
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic:base-topic2        PartitionCount:5        ReplicationFactor:1        Configs:
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_kafka_tools">8.5. Kafka Tools</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Kafka Tools</strong> es un conjunto de herramientas desarrolladas por <strong>LinkedIn</strong> para facilitar la gestión de los clústers <strong>Kafka</strong>. Su finalidad es simplificar gestiones que con los comandos internos de <strong>Kafka</strong> se hacen tediosas o pesados (como cambiar el factor de replicación o balancear entre todos los brokers los líderes). Tienen los siguientes módulos:</p>
<div class="ulist">
<ul>
<li>
<p>clone</p>
</li>
<li>
<p>trim</p>
</li>
<li>
<p>remove</p>
</li>
<li>
<p>elect</p>
</li>
<li>
<p>set-replication-factor</p>
</li>
<li>
<p>reorder</p>
</li>
<li>
<p>balance</p>
</li>
</ul>
</div>
</li>
<li>
<p>Al invocar estas herramientas, hay que proporcionar la ruta a <strong>Zookeeper</strong> (con "-z") y es posible que os pida especificar la ruta a las <strong>kafka tools</strong> (con "--tools-path")</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_clone">8.5.1. Clone</h4>
<div class="ulist">
<ul>
<li>
<p>Clona las particiones de una lista de brokers en un broker destino. Normalmente se usa para probar nuevo hardware, no aporta mucho más.</p>
</li>
<li>
<p>Para invocarlo hay que usar</p>
<div class="ulist">
<ul>
<li>
<p><strong>--brokers</strong> &#8594; brokers a clonar</p>
</li>
<li>
<p><strong>--to_broker</strong> &#8594; broker destino</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_trim">8.5.2. trim</h4>
<div class="ulist">
<ul>
<li>
<p>Borra uno o más brokers del clúster, reduciendo el factor de replicación de las particiones en el proceso.</p>
</li>
<li>
<p>También tiene un uso limitado (orientado al testing), ya que altera las particiones</p>
<div class="ulist">
<ul>
<li>
<p><strong>--brokers</strong> &#8594; brokers a eliminar</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_remove">8.5.3. remove</h4>
<div class="ulist">
<ul>
<li>
<p>Elimina un <strong>Broker</strong>, manteniendo el factor de replicación.</p>
</li>
<li>
<p>Esta utilidad si es más ventajosa, ya que va a conservar el mismo factor de replicación previo a la retirada.</p>
<div class="ulist">
<ul>
<li>
<p><strong>--brokers</strong> &#8594; brokers a eliminar</p>
</li>
<li>
<p><strong>--to_broker</strong> &#8594; broker destino de las réplicas que guarda el broker a eliminar (si no se indica nada, lo distribuye entre todos)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e remove --broker 4 --to_brokers 1 2 3</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_elect">8.5.4. elect</h4>
<div class="ulist">
<ul>
<li>
<p>ejecuta una reelección del clúster.</p>
</li>
<li>
<p>Es análogo a usar <strong>kafka-preferred-replica-election.sh</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e elect</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_set_replication_factor">8.5.5. set-replication-factor</h4>
<div class="ulist">
<ul>
<li>
<p>Nos permite cambiar el factor de replicacion de un <strong>Topic</strong>.</p>
<div class="ulist">
<ul>
<li>
<p><strong>--topic</strong> &#8594; Topic que vamos a alterar</p>
</li>
<li>
<p><strong>--replication-factor</strong> &#8594; Nuevo factor de replicación</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e set-replication-factor --topic unTopic --replication-factor 3</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reorder">8.5.6. reorder</h4>
<div class="ulist">
<ul>
<li>
<p>La opción que queremos usar cuando buscamos asegurar que todos los brokers tienen el mismo número de particiones líderes.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e reorder</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_balance">8.5.7. balance</h4>
<div class="ulist">
<ul>
<li>
<p>Es el módulo más complejo de todos, se encarga de balancear las particiones a través del clúster.</p>
</li>
<li>
<p>Ofrece distintos modos:</p>
<div class="ulist">
<ul>
<li>
<p>count &#8594; las particiones más pequeñas del clúster son las movidas</p>
</li>
<li>
<p>size &#8594; las particiones más grandes del clúster son las movidas</p>
</li>
<li>
<p>even &#8594; Si el número de particiones del clúster es múltiplo del número de brokers, asegura que cada broker tiene el mismo número de particiones por topic</p>
</li>
<li>
<p>leader &#8594; Reordena la lista de réplicas para obtener un balance ideal de los líderes (análogo a usar reorder)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e balance --types size</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_usando_kafka_tools">8.6. Lab: Usando Kafka Tools</h3>
<div class="paragraph">
<p>Antes de empezar, asegúrate de que <strong>Zookeeper</strong> está levantado, y que tenemos los 3 brokers de las practicas anteriores en ejecución.</p>
</div>
<div class="paragraph">
<p>Vamos a instalar <strong>Kafka tools</strong> (para esta VM hay que instalar también el compilador de C++)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ sudo dnf -y install gcc-c++
[kafka@kafka-server ~]$ pip3 install kafka-tools --user</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como dependencia, kafka tools necesita tener declarada la variable JAVA_HOME</p>
</li>
<li>
<p>Para ello lanzamos los siguientes comandos que permiten buscar la versión de java y crear la variable para el usuario</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ echo export JAVA_HOME=$(alternatives --list | grep java_sdk | head -n 1 | awk '{print $3}') &gt;&gt; java_path.sh
[kafka@kafka-server ~]$ sudo mv java_path.sh /etc/profile.d/
[kafka@kafka-server ~]$ sudo chmod ugo+x /etc/profile.d/java_path.sh
[kafka@kafka-server ~]$ source /etc/profile.d/java_path.sh</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este apartado, vamos a volver a trabajar con <strong>base-topic2</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lo primero que vamos a hacer, es cambiar su factor de replicación usando las herramientas <strong>kafka tools</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-assigner -z localhost:2181 -e set-replication-factor --topic base-topic2 --replication-factor 3
[INFO] Connecting to zookeeper localhost:2181
[INFO] Getting partition list from Zookeeper
[INFO] Closing connection to zookeeper
[INFO] Partition moves required: 5
[INFO] Number of batches: 1
[INFO] Executing partition reassignment 1/1: {&quot;partitions&quot;: [{&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [0, 1, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 1, &quot;replicas&quot;: [0, 1, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 2, &quot;replicas&quot;: [0, 1, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 3, &quot;replicas&quot;: [0, 1, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 4, &quot;replicas&quot;: [0, 1, 2]}], &quot;version&quot;: 1}
[INFO] Number of replica elections: 1
[INFO] Executing preferred replica election 1/1</code></pre>
</div>
</div>
<div class="paragraph">
<p>Veamos el resultado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Genial, hemos sido capaces de cambiar el factor de replicación sin apenas esfuerzo, pero ¿Nos convence la distribucion de las particiones primarias?</p>
</li>
<li>
<p>Vamos a reordenarlas</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-assigner -z localhost:2181 -e reorder
[INFO] Connecting to zookeeper localhost:2181
[INFO] Getting partition list from Zookeeper
[INFO] Closing connection to zookeeper
[INFO] Partition moves required: 9
[INFO] Number of batches: 1
[INFO] Executing partition reassignment 1/1: {&quot;partitions&quot;: [{&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [1, 0, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 1, &quot;replicas&quot;: [2, 1, 0]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 2, &quot;replicas&quot;: [1, 0, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 3, &quot;replicas&quot;: [2, 1, 0]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 4, &quot;replicas&quot;: [1, 0, 2]}, {&quot;topic&quot;: &quot;topic-cluster-si-ha&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [2, 1, 0]}, {&quot;topic&quot;: &quot;topicEjemploConf1&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [1, 0, 2]}, {&quot;topic&quot;: &quot;topicEjemploConf1&quot;, &quot;partition&quot;: 1, &quot;replicas&quot;: [2, 1, 0]}, {&quot;topic&quot;: &quot;topicRecienCreado&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [1, 0]}], &quot;version&quot;: 1}
[INFO] Number of replica elections: 1
[INFO] Executing preferred replica election 1/1</code></pre>
</div>
</div>
<div class="paragraph">
<p>¿Habrá funcionado?</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic base-topic2
Topic:base-topic2        PartitionCount:5        ReplicationFactor:3        Configs:
        Topic: base-topic2        Partition: 0        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 1        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 2        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 3        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 4        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si, pero tened en cuenta que hay muchas particiones (correspondientes al topic de los offsets) ya en el broker 0, por lo que se han asignado a los brokers 1 y 2</p>
</li>
<li>
<p>Bueno, veamos qué pasa si llamo a balance, con la opción <strong>leader</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% kafka-assigner -z localhost:2181 -e balance --types leader</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Como no hemos dado de alta con un certificado a nuestro usuario, y <strong>balance</strong> se conecta por ssh, nos pedirá las claves. Esto puede solucionarse usando <strong>ssh-keygen</strong> y <strong>ssh-copy-id</strong> para permitir la conexión mediante certificados</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Veamos el aspecto (vamos a ver sólo nuestro topic, pero esto ha distribuido TODOS los topics)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 1        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 2        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 3        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 4        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>No ha cambiado. ¿Tal vez deberíamos cambiar <strong>__consumer_offsets</strong> para que no sature el broker 0?</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Durante las operaciones de balanceo, puede pedirnos conexión via SSH a los brokers.</p>
</li>
<li>
<p>Al pedir autorización del fingerprint, decimos yes.</p>
</li>
<li>
<p>Los datos de conexión para el usuario kafka es password kafka</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e set-replication-factor --topic __consumer_offsets --replication-factor 2
[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e balance --types leader
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 3        Configs:
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 1        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 2        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Esto ha resuelto nuestros problemas.</p>
</li>
<li>
<p>Si vemos el <strong>--describe</strong> de <strong>__consumer_offsets</strong>, veremos que ha sido distribuido por múltiples <strong>brokers</strong>, permitiendo así un balanceo de nuestro clúster</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic __consumer_offsets
Topic: __consumer_offsets        PartitionCount: 50        ReplicationFactor: 2        Configs: compression.type=producer,cleanup.policy=compact,segment.bytes=104857600
        Topic: __consumer_offsets        Partition: 0        Leader: 0        Replicas: 0,1        Isr: 0,1
        Topic: __consumer_offsets        Partition: 1        Leader: 2        Replicas: 2,0        Isr: 0,2
        Topic: __consumer_offsets        Partition: 2        Leader: 1        Replicas: 1,0        Isr: 0,1
...</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_desarrollo_con_kafka">9. Desarrollo con kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Para desarrollar con kafka, hay que tener en cuenta para kafka:</p>
<div class="ulist">
<ul>
<li>
<p>Cual va a ser la implementación utilizada de kafka (OpenSource/Confluent)</p>
</li>
<li>
<p>Que versión vamos a utilizar (2.6.0/6.0.0)</p>
</li>
<li>
<p>Que instalación vamos a usar (Entorno centralizado/entorno particular)</p>
</li>
<li>
<p>En caso de uso de un entorno particular, como vamos a instalarlo (Instalación común/Docker)</p>
</li>
<li>
<p>Tenemos memoria suficiente para albergar todo lo que necesitamos en el equipo?</p>
</li>
</ul>
</div>
</li>
<li>
<p>En cuanto al desarrollo hay que tener en cuenta:</p>
<div class="ulist">
<ul>
<li>
<p>Que lenguaje/lenguajes de programación vamos a utilizar para comunicarnos con kafka</p>
</li>
<li>
<p>Que IDE vamos a utilizar</p>
</li>
<li>
<p>Que librerias de apoyo vamos a utilizar</p>
</li>
<li>
<p>Que arquitecturas vamos a implementar.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_implementación_kafka">9.1. Implementación kafka</h3>
<div class="ulist">
<ul>
<li>
<p>En cuanto a la implementación de Kafka, en este curso nos centraremos en la versión OpenSource de Kafka, la versión 2.6.0</p>
</li>
<li>
<p>Usaremos Docker para crear los siguientes contenedores:</p>
<div class="ulist">
<ul>
<li>
<p>Contenedor de Zookeeper como base de metadatos de los brokers</p>
</li>
<li>
<p>Tres contenedores de Kafka que se usarán como brokers</p>
</li>
</ul>
</div>
</li>
<li>
<p>Se usará la interfaz host para que se alojen en local y funcione correctamente las comunicaciones entre brokers.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_lenguaje_de_programación">9.2. Lenguaje De programación</h3>
<div class="ulist">
<ul>
<li>
<p>En nuestro caso, usaremos Eclipse o STS según lo cómodo que esté cada alumno para usarlos.</p>
</li>
<li>
<p>Como lenguaje de programación, usaremos Java</p>
</li>
<li>
<p>Usaremos los frameworks de:</p>
<div class="ulist">
<ul>
<li>
<p>kafka-clients: Para uso de conexiones a kafka</p>
</li>
<li>
<p>kafka-streams: Para el uso de streams en Java</p>
</li>
<li>
<p>io.confluent: como librerias de confluent para uso de ciertos recursos con licencia confluent.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_objetivo">9.3. Objetivo</h3>
<div class="ulist">
<ul>
<li>
<p>El objetivo es poseer un cluster de Kafka suficientemente versatil para poder trabajar con él</p>
</li>
<li>
<p>El aspecto final será el siguiente:</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><span class="image"><img src="./images/kafka-entorno-desarrollo-01.png" alt="kafka entorno desarrollo 01" width="600"></span></p>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_lab_instalación_del_entorno_de_desarrollo_de_kafka">9.4. Lab: Instalación del entorno de desarrollo de Kafka</h3>
<div class="sect3">
<h4 id="_ejecución_de_prueba">9.4.1. Ejecución de prueba</h4>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>En caso de que no estén levantados los contenedores, los levantamos como se indica a continuación.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Para comprobar que todo ha ido correctamente, vamos a iniciar cada uno de los contenedores de forma individual</p>
</li>
<li>
<p>Primero iniciamos el servicio de Zookeeper.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server docker-kafka]$ docker-compose up -d zookeeper</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Esperamos unos segundos e iniciamos ya los contenedores de Kafka</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server docker-kafka]$ docker-compose up -d kafka1
[kafka@kafka-server docker-kafka]$ docker-compose up -d kafka2
[kafka@kafka-server docker-kafka]$ docker-compose up -d kafka3</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras iniciar los contenedores, deben estar disponibles en el sistema. Lo comprobamos con el siguiente comando.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server docker-kafka]$ docker ps
CONTAINER ID        IMAGE                                   COMMAND                  CREATED             STATUS              PORTS               NAMES
093e9d1c649e        bitnami/kafka:latest                    &quot;/opt/bitnami/script…&quot;   4 seconds ago       Up 3 seconds                               docker-kafka_kafka1_1
551540ef4ce4        bitnami/kafka:latest                    &quot;/opt/bitnami/script…&quot;   3 seconds ago       Up 2 seconds                               docker-kafka_kafka2_1
fbe3387824b3        bitnami/kafka:latest                    &quot;/opt/bitnami/script…&quot;   3 seconds ago       Up 2 seconds                               docker-kafka_kafka3_1
40c2020d1486        bitnami/zookeeper:latest                &quot;/opt/bitnami/script…&quot;   2 minutes ago       Up 2 mintues                               docker-kafka_zookeeper_1</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect3">
<h4 id="_preparación_de_proyecto_plantilla">9.4.2. Preparación de proyecto plantilla</h4>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear un proyecto plantilla el cual utilizaremos como base para los demás proyectos.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Usaremos como workspace /home/kafka/workspace_curso</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Para ello abrimos nuestro IDE favorito y creamos un nuevo proyecto:</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-01.png" alt="kafka entornos desarrollo lab 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Elegimos el <strong>Maven Project</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-02.png" alt="kafka entornos desarrollo lab 02" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Seleccionamos la opción de crear un proyecto simple</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-03.png" alt="kafka entornos desarrollo lab 03" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Rellenamos los siguientes campos</p>
<div class="ulist">
<ul>
<li>
<p><strong>Group id</strong>: com.curso.kafka</p>
</li>
<li>
<p><strong>Artifact id</strong>: PlantillaKafka</p>
</li>
<li>
<p><strong>Version</strong>: 0.0.1-SNAPSHOT</p>
</li>
<li>
<p><strong>Packaging</strong>: jar</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-04.png" alt="kafka entornos desarrollo lab 04" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pulsamos <strong>finish</strong></p>
</li>
<li>
<p>Ahora editamos el fichero pom.xml agregado las siguientes propiedades que permiten que se compile en Java 11 de forma automática:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;properties&gt;</span>
    <span class="tag">&lt;maven.compiler.source&gt;</span>11<span class="tag">&lt;/maven.compiler.source&gt;</span>
    <span class="tag">&lt;maven.compiler.target&gt;</span>11<span class="tag">&lt;/maven.compiler.target&gt;</span>
<span class="tag">&lt;/properties&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Agregamos las dependencias mínimas para trabajar con kafka. Las Kafka Clients</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="comment">&lt;!-- Librerias Kafka --&gt;</span>
<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.apache.kafka<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>kafka-clients<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>2.6.0<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Debajo agregamos la librería helper de slf4j, ya que no viene ninguna implementación en las librerías de kafka, y sino no podría generar el sistema de log, y fallaría el arranque</p>
</li>
<li>
<p>Y también jackson core para tratamiento de xml</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Cuando agreguemos kafka-streams, ya no será necesario, ya que viene incluida como dependencia.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="comment">&lt;!-- Helpers --&gt;</span>
<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.slf4j<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>slf4j-log4j12<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>1.7.5<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span>
<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>com.fasterxml.jackson.core<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>jackson-databind<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>2.11.3<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El resultado final del fichero pom.xml será el siguiente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;project</span> <span class="attribute-name">xmlns</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/POM/4.0.0</span><span class="delimiter">&quot;</span></span>
        <span class="attribute-name">xmlns:xsi</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://www.w3.org/2001/XMLSchema-instance</span><span class="delimiter">&quot;</span></span>
        <span class="attribute-name">xsi:schemaLocation</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd</span><span class="delimiter">&quot;</span></span><span class="tag">&gt;</span>
        <span class="tag">&lt;modelVersion&gt;</span>4.0.0<span class="tag">&lt;/modelVersion&gt;</span>
        <span class="tag">&lt;groupId&gt;</span>com.curso.kafka<span class="tag">&lt;/groupId&gt;</span>
        <span class="tag">&lt;artifactId&gt;</span>PlantillaKafka<span class="tag">&lt;/artifactId&gt;</span>
        <span class="tag">&lt;version&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/version&gt;</span>
  <span class="comment">&lt;!-- Java 11 OpenJDK como compilacion de proyecto --&gt;</span>
        <span class="tag">&lt;properties&gt;</span>
                <span class="tag">&lt;maven.compiler.source&gt;</span>11<span class="tag">&lt;/maven.compiler.source&gt;</span>
                <span class="tag">&lt;maven.compiler.target&gt;</span>11<span class="tag">&lt;/maven.compiler.target&gt;</span>
        <span class="tag">&lt;/properties&gt;</span>
        <span class="tag">&lt;dependencies&gt;</span>
                <span class="comment">&lt;!-- Librerias Kafka --&gt;</span>
                <span class="tag">&lt;dependency&gt;</span>
                        <span class="tag">&lt;groupId&gt;</span>org.apache.kafka<span class="tag">&lt;/groupId&gt;</span>
                        <span class="tag">&lt;artifactId&gt;</span>kafka-clients<span class="tag">&lt;/artifactId&gt;</span>
                        <span class="tag">&lt;version&gt;</span>2.6.0<span class="tag">&lt;/version&gt;</span>
                <span class="tag">&lt;/dependency&gt;</span>
                <span class="comment">&lt;!-- Helpers --&gt;</span>
                <span class="tag">&lt;dependency&gt;</span>
                        <span class="tag">&lt;groupId&gt;</span>org.slf4j<span class="tag">&lt;/groupId&gt;</span>
                        <span class="tag">&lt;artifactId&gt;</span>slf4j-log4j12<span class="tag">&lt;/artifactId&gt;</span>
                        <span class="tag">&lt;version&gt;</span>1.7.5<span class="tag">&lt;/version&gt;</span>
                <span class="tag">&lt;/dependency&gt;</span>
        <span class="tag">&lt;/dependencies&gt;</span>
<span class="tag">&lt;/project&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para completar el sistema de log, vamos a agregar también el fichero log4j.properties en el directorio src/main/resources</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Contenido de src/main/resources/log4j.properties</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">log4j.rootLogger=INFO, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d [%t] %-5p %c - %m%n</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez terminado, debemos de sincronizar el proyecto maven con el proyecto del IDE.</p>
</li>
<li>
<p>Para ello pulsamos botón derecho en la raiz del proyecto y seleccionamos <strong>Maven</strong> &#8594; <strong>Update Project</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-05.png" alt="kafka entornos desarrollo lab 05" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez que se sincronice y que guarde todas las dependencias, debemos cerciorarnos de que el IDE detecta el proyecto como Java 11</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-06.png" alt="kafka entornos desarrollo lab 06" width="300">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Fin del laboratorio.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kafka_java_api">10. Kafka Java API</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_dependencias">10.1. Dependencias</h3>
<div class="ulist">
<ul>
<li>
<p>Necesitamos añadir a un nuevo proyecto las dependencias a las librerías <strong>Kafka</strong>.</p>
</li>
<li>
<p>Si usamos <strong>Maven</strong>, con añadir dependencias a <strong>kafka-clients</strong> debería ser suficiente.</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Dependencia mínima a utilizar</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>&lt;dependency&gt;
	&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
	&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
	&lt;version&gt;2.6.0&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>En nuestro caso, vamos a crear una librearía de usuario con las librerías que hay en <strong>$KAFKA_HOME/lib</strong></p>
</div>
<div class="paragraph">
<p>NOTA: Al crear la librería incluímos jackson-databind, esto tendría que ser añadido también a las dependencias de <strong>maven</strong></p>
</div>
</div>
<div class="sect2">
<h3 id="_api_para_producer">10.2. API para Producer</h3>
<div class="ulist">
<ul>
<li>
<p>Para poder hacer nuestro propio <strong>productor</strong>, necestaremos conocer las siguientes clases:</p>
<div class="ulist">
<ul>
<li>
<p><strong>KafkaProducer</strong> &#8594; Las instancias de esta clase poseen un método <strong>send()</strong> que será usado para realizar los envíos al <strong>Topic</strong></p>
</li>
<li>
<p><strong>ProducerRecord</strong> &#8594; Las instancias de esta clase son los mensajes que queremos enviar a nuestros <strong>Topics</strong>. Poseen <strong>Clave</strong> y <strong>Valor</strong>, pero también debemos especificar el <strong>Topic</strong> destino, y podemos especificar la <strong>partición</strong> destino (o dejarlo a cargo de un particionador)</p>
</li>
<li>
<p><strong>ProducerConfig</strong> &#8594; Clase que contiene las constantes con las distintas configuraciones aplicables. Es recomendable hacer uso de ellas al crear el fichero <strong>properties</strong>, en lugar de escribirlas manualmente.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Vamos a empezar con la clase <strong>KafkaProducer</strong>, que está en el paquete <strong>org.apache.kafka.clients.producer</strong>.</p>
</li>
<li>
<p>Esta clase posee un método <strong>send()</strong>, que nos permite enviar los mensajes a los <strong>Topics</strong> destino de manera asíncrona.</p>
<div class="ulist">
<ul>
<li>
<p><strong>send(ProducerRecord&lt;K,V&gt; record, Callback callback)</strong> &#8594; Ejecutamos el envío del mensaje. Al ser procesado, se ejecutará el método proporcionado en callback. Podemos usar <strong>send(record)</strong> directamente, con lo que no invocaríamos un método al recibir el registro (o tener una excepción). Devuelve un objeto <strong>Future&lt;RecordMetadata&gt;</strong>.</p>
</li>
<li>
<p><strong>partitionsFor(String topic)</strong> &#8594; Devuelve un <strong>List&lt;PartitionInfo&gt;</strong>, para poder consultar la información de las particiones de un <strong>topic</strong>.</p>
</li>
<li>
<p><strong>close()</strong> &#8594; Cierra el productor.</p>
</li>
<li>
<p><strong>flush()</strong> &#8594; Fuerza el envío de los mensajes pendientes (aunque no lleguemos al linger.ms o batch.size) y bloquea hasta recibir la respuesta de estos.</p>
</li>
<li>
<p><strong>metrics()</strong> &#8594; Devuelve un <strong>Map&lt;MetricName,? extends Metric&gt;</strong>, con las métricas internas mantenidas por el <strong>productor</strong>.</p>
</li>
<li>
<p><strong>initTransactions()</strong> &#8594; Si vamos a usar transacciones debemos invocar este método antes de cualquier uso de las mismas (y <strong>transactional.id</strong> está puesto en la configuración)</p>
</li>
<li>
<p><strong>beginTransaction()</strong> &#8594; Para empezar una nueva transacción</p>
</li>
<li>
<p><strong>commitTransaction()</strong> &#8594; Valida la transacción actual</p>
</li>
<li>
<p><strong>abortTransaction()</strong> &#8594; Invalida la transacción actual</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Más información en: <a href="https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html" class="bare">https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Ya hemos dicho antes, que para enviar mensajes, necesitamos envolverlos en una instancia de <strong>ProducerRecord</strong>, que está en <strong>org.apache.kafka.clients.producer</strong>.</p>
</li>
<li>
<p>Las instancias de <strong>ProducerRecord</strong> contienen el mensaje que queremos enviar a nuestros <strong>topics</strong>. La parte más importante de esta clase es su constructor, ya que es donde especificamos tanto el contenido, como el destino.</p>
<div class="ulist">
<ul>
<li>
<p><strong>ProducerRecord(String topic, V value)</strong> &#8594; Enviamos a un topic un valor sin clave</p>
</li>
<li>
<p><strong>ProducerRecord(String topic, K key, V value)</strong> &#8594; Enviamos a un topic un mensaje con clave y valor</p>
</li>
<li>
<p><strong>ProducerRecord(String topic, Integer partition, K key, V value)</strong> &#8594; Enviamos a una partición concreta de un topic un mensaje con clave y valor</p>
</li>
</ul>
</div>
</li>
<li>
<p>También posee algunos métodos útiles para consultar el contenido:</p>
<div class="ulist">
<ul>
<li>
<p><strong>key()</strong> &#8594; Devuelve la clave del mensaje</p>
</li>
<li>
<p><strong>value()</strong> &#8594; Devuelve el valor del mensaje</p>
</li>
<li>
<p><strong>partition()</strong> &#8594; Devuelve la partición a la que queremos enviar el mensaje (si lo hemos especificado)</p>
</li>
<li>
<p><strong>timestamp()</strong> &#8594; Devuelve el timestamp del momento de creación del mensaje</p>
</li>
<li>
<p><strong>topic()</strong> &#8594; Devuelve el topic que hemos especificado como destino</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por último, vamos a ver las opciones de configuración.</p>
<div class="ulist">
<ul>
<li>
<p>Para poder instanciar un <strong>KafkaProducer</strong>, necesitamos facilitarle un objeto <strong>Properties</strong>.</p>
</li>
<li>
<p>Sobre él, tenemos que definir una serie de configuraciones (vamos a ver ahora las más importantes).</p>
</li>
<li>
<p>Para facilitarnos esto, <strong>Kafka</strong> nos ofrece la clase <strong>ProducerConfig</strong>, del paquete <strong>org.apache.kafka.clients.producer</strong>, que contiene las constantes con los nombres de las propiedades que podemos usar.</p>
<div class="ulist">
<ul>
<li>
<p><strong>ProducerConfig.CLIENT_ID_CONFIG</strong> &#8594; Para especificar el <strong>client.id</strong> del productor.</p>
</li>
<li>
<p><strong>ProducerConfig.COMPRESSION_TYPE_CONFIG</strong> &#8594; Para especificar el <strong>compression.type</strong> (tipo de compresión).</p>
</li>
<li>
<p><strong>ProducerConfig.ACKS_CONFIG</strong> &#8594; Especifica cuántas respuestas espera, propiedad <strong>acks</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.RETRIES_CONFIG</strong> &#8594; Especifica los reintentos, propiedad <strong>retries</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.BOOTSTRAP_SERVERS_CONFIG</strong> &#8594; Lista de los nodos a los que conectarnos para obtener el esquema, propiedad <strong>bootstrap.servers</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG</strong> &#8594; Clase para serializar la clave, propiedad <strong>key.serializer</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG</strong> &#8594; Clase para serializar el valor, propiedad <strong>value.serializer</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.BATCH_SIZE_CONFIG</strong> &#8594; Tamaño de mensajes antes del envío, propiedad <strong>batch.size</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.LINGER_MS_CONFIG</strong> &#8594; Tiempo máximo de almacenamiento de mensajes antes dle envío, propiedad <strong>linger.ms</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.PARTITIONER_CLASS_CONFIG</strong> &#8594; Clase usada para decidir a qué partición enviar los mensajes, propiedad <strong>partitioner.class</strong>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Con todo esto en juego, vamos a crear nuestro primer ejemplo, que enviará a <strong>topicEjemplo01</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Producer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;

<span class="comment">//kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topicEjemplo01 --property print.key=true --from-beginning</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">ProducerEjemplos01</span> {
        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);

        Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);
        <span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje </span><span class="delimiter">&quot;</span></span>+id));
            <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
        }
        producer.flush();
        producer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos añadir un <strong>Callback</strong> a nuestro <strong>send()</strong>, creamos la clase <strong>CallbackSimple</strong> implementando la interfaz <strong>org.apache.kafka.clients.producer.Callback</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Callback</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Producer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.RecordMetadata</span>;

<span class="comment">//kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topicEjemplo01 --property print.key=true --from-beginning</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">ProducerEjemplos02</span> {
        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);

        Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);
        <span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje </span><span class="delimiter">&quot;</span></span>+id),<span class="keyword">new</span> <span class="predefined-type">Callback</span>(){
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> onCompletion(RecordMetadata meta, <span class="exception">Exception</span> arg1) {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje escrito en </span><span class="delimiter">&quot;</span></span>+meta.topic()+<span class="string"><span class="delimiter">&quot;</span><span class="content"> particion </span><span class="delimiter">&quot;</span></span>+meta.partition()+<span class="string"><span class="delimiter">&quot;</span><span class="content"> con offset </span><span class="delimiter">&quot;</span></span>+meta.offset());
                        }});
            <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
        }
        producer.flush();
        producer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lo habitual es que mandemos los mensajes con una clave, así que vamos a modificar un poco nuestro ejemplo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Callback</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Producer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.RecordMetadata</span>;
<span class="directive">public</span> <span class="type">class</span> <span class="class">ProducerEjemplos03</span> {
        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);

        Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);
        <span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">ID_</span><span class="delimiter">&quot;</span></span>+id, <span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje </span><span class="delimiter">&quot;</span></span>+id),<span class="keyword">new</span> <span class="predefined-type">Callback</span>(){
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> onCompletion(RecordMetadata meta, <span class="exception">Exception</span> arg1) {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje escrito en </span><span class="delimiter">&quot;</span></span>+meta.topic()+<span class="string"><span class="delimiter">&quot;</span><span class="content"> particion </span><span class="delimiter">&quot;</span></span>+meta.partition()+<span class="string"><span class="delimiter">&quot;</span><span class="content"> con offset </span><span class="delimiter">&quot;</span></span>+meta.offset());
                        }});
            <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
        }
        producer.flush();
        producer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con respecto al <strong>particionador</strong>, si queremos especificar el nuestro propio, debemos implementar la clase <strong>Partitioner</strong> del paquete <strong>org.apache.kafka.clients.producer</strong>.</p>
</li>
<li>
<p>Quizás lo más interesante sea obtener del objeto <strong>Cluster</strong> información, concretamente <strong>partitionCountForTopic()</strong> que nos dice cuántas particiones existen para un <strong>Topic</strong> en concreto.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.producer</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Partitioner</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.Cluster</span>;
<span class="keyword">import</span> <span class="include">java.util.Map</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SimplePartitioner</span> <span class="directive">implements</span> Partitioner {

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">int</span> partition(<span class="predefined-type">String</span> topic, <span class="predefined-type">Object</span> key, <span class="type">byte</span><span class="type">[]</span> keyBytes, <span class="predefined-type">Object</span> value, <span class="type">byte</span><span class="type">[]</span> valueBytes, Cluster cluster) {
        <span class="keyword">return</span> <span class="predefined-type">Math</span>.abs(key.hashCode() % cluster.partitionCountForTopic(topic));
    }

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> close() {}

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> configure(<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, ?&gt; conf) {}
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>No nos vamos a meter tampoco a estudiar los serializadores y de-serializadores, pero son interfaces que hemos de implementar para serializar o de-serializar nuestras clases en caso de que no nos valga con los que <strong>Kafka</strong> proporciona.</p>
</li>
<li>
<p>La interfaz <strong>org.apache.kafka.common.serialization.Serializer</strong> obliga a implementar la función <strong>serialize(topic,map)</strong> debe convertir un <strong>Map&lt;String,Object&gt;</strong> en un array de bytes <strong>byte[]</strong></p>
</li>
<li>
<p>La interfaz <strong>org.apache.kafka.common.serialization.Deserializer</strong> obliga a implementar la función <strong>deserialize(topic,data)</strong> debe convertir un array de bytes <strong>byte[]</strong> en un <strong>Map&lt;String,Object&gt;</strong></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_api_para_consumer">10.3. API para Consumer</h3>
<div class="ulist">
<ul>
<li>
<p>Para poder hacer nuestro propio <strong>Consumer</strong>, necestaremos conocer las siguientes clases:</p>
<div class="ulist">
<ul>
<li>
<p><strong>KafkaConsumer</strong> &#8594; Las instancias de esta clase poseen un método <strong>subscribe()</strong>, que permite suscribirse a unos <strong>Topics</strong>, y hacer <strong>poll()</strong> de sus mensajes.</p>
</li>
<li>
<p><strong>ConsumerRecord</strong> &#8594; Las instancias de esta clase son los mensajes que consumimos de nuestros <strong>Topics</strong>. Poseen <strong>Clave</strong> y <strong>Valor</strong>, pero también tienen metainformación como <strong>offset</strong>, <strong>partición</strong>, <strong>topic</strong> o <strong>timestamp</strong></p>
</li>
<li>
<p><strong>ConsumerConfig</strong> &#8594; Clase que contiene las constantes con las distintas configuraciones aplicables. Es recomendable hacer uso de ellas al crear el fichero <strong>properties</strong>, en lugar de escribirlas manualmente.</p>
</li>
</ul>
</div>
</li>
<li>
<p>La clase <strong>KafkaConsumer</strong>, que está en el paquete <strong>org.apache.kafka.clients.consumer</strong>, tiene varios métodos que debemos conocer:</p>
<div class="ulist">
<ul>
<li>
<p><strong>assign(Collection&lt;TopicPartition&gt; c)</strong> &#8594; Permite asignar una lista de particiones al consumidor</p>
</li>
<li>
<p><strong>commitAsync()/commitSync()</strong> &#8594; Guardado manual del offset leído</p>
</li>
<li>
<p><strong>metrics()</strong> &#8594; Métricas internas del consumidor</p>
</li>
<li>
<p><strong>poll(t)</strong> &#8594; Trae los registros de los <strong>topics</strong> suscritos (si no hay, espera t milisegundos)</p>
</li>
<li>
<p><strong>seek(TopicPartition t,long offset)</strong> &#8594; Para especificar a partir de qué offset quiero traer datos de un topic y una partición concretas</p>
</li>
<li>
<p><strong>subscribe(Collection&lt;Sring&gt; topics)</strong> &#8594; Se suscribe a los <strong>topics</strong> especificados (Admite Regex en lugar de coleccion de String)</p>
</li>
<li>
<p><strong>subscription()</strong> &#8594; Nos da la lista de topics a los que está suscrito</p>
</li>
<li>
<p><strong>unsubscribe()</strong> &#8594; se retira de los topics (todos) a los que está suscrito</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Puedes obtener más información en: <a href="https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html" class="bare">https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>El <strong>KafkaConsumer</strong> se suscribe a una lista de <strong>Topics</strong>, y hace <strong>poll()</strong> sobre ella. Cuando realiza esta acción, nos devuelva una "colección" de mensajes leídos. Esta colección es un <strong>ConsumerRecords&lt;K,V&gt;</strong>, objeto sobre el que podemos iterar para tratar cada <strong>ConsumerRecord&lt;K,V&gt;</strong> individualmente.</p>
</li>
<li>
<p>Este objeto proporciona unos métodos para poder extrar la clave y el valor, y cualquier otro dato que pueda ser de utilidad:</p>
<div class="ulist">
<ul>
<li>
<p><strong>key()</strong> &#8594; Devuelve la clave del mensaje</p>
</li>
<li>
<p><strong>value()</strong> &#8594; Devuelve el valor del mensaje</p>
</li>
<li>
<p><strong>partition()</strong> &#8594; Devuelve la partición de la que hemos leído</p>
</li>
<li>
<p><strong>timestamp()</strong> &#8594; Devuelve el timestamp del momento de creación del mensaje</p>
</li>
<li>
<p><strong>topic()</strong> &#8594; Devuelve el topic del que hemos leído</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por último, vamos a ver las opciones de configuración. Para poder instanciar un <strong>KafkaConsumer</strong>, necesitamos facilitarle un objeto <strong>Properties</strong>. Sobre él, tenemos que definir una serie de configuraciones (vamos a ver ahora las más importantes).</p>
</li>
<li>
<p>Para facilitarnos esto, <strong>Kafka</strong> nos ofrece la clase <strong>ConsumerConfig</strong>, del paquete <strong>org.apache.kafka.clients.consumer</strong>, que contiene las constantes con los nombres de las propiedades que podemos usar.</p>
<div class="ulist">
<ul>
<li>
<p><strong>ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG</strong> &#8594; Lista de los nodos a los que conectarnos para obtener el esquema, propiedad <strong>bootstrap.servers</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.GROUP_ID_CONFIG</strong> &#8594; Para especificar el <strong>group.id</strong> del consumidor. Todos los consumidores con este grupo actuán como un único consumidor.</p>
</li>
<li>
<p><strong>ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG</strong> &#8594; Clase para serializar la clave, propiedad <strong>key.deserializer</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG</strong> &#8594; Clase para serializar el valor, propiedad <strong>value.deserializer</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG</strong> &#8594; Para que haga un commit manual del último offset leído, propiedad*"enable.auto.commit*.</p>
</li>
<li>
<p><strong>ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG</strong> &#8594; Especifica el tiempo entre commits, propiedad <strong>auto.commit.interval.ms</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG</strong> &#8594; Tiempo máximo de la sesión, propiedad <strong>session.timeout.ms</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.AUTO_OFFSET_RESET_CONFIG</strong> &#8594; Qué hacer si este grupo de clientes no tiene offset inicial, propiedad <strong>auto.offset.reset</strong>. Puede tomar:</p>
<div class="ulist">
<ul>
<li>
<p><strong>latest</strong>: El offset se fija en el último registro existente, es decir, sólo mensajes nuevos (por defecto)</p>
</li>
<li>
<p><strong>earliest</strong>: Si no hay offset, se empieza desde el primer registro</p>
</li>
<li>
<p><strong>none</strong>: Si no hay offset, salta una excepción</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Vamos a hacer nuestro primer consumidor (Fijaros, que sólo procesa a partir de los mensajes nuevos, si queremos que esto cambi hay que usar <strong>ConsumerConfig.AUTO_OFFSET_RESET_CONFIG</strong>):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ConsumerEjemplo01</span> {
         <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">consumer_base</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
                <span class="predefined-type">String</span> s=ConsumerConfig.AUTO_OFFSET_RESET_CONFIG;
                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
                consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>));
                <span class="type">int</span> leidos=<span class="integer">0</span>;
                <span class="keyword">while</span> (<span class="predefined-constant">true</span>) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="integer">1000</span>);
                        <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
                                <span class="keyword">if</span> (++leidos&gt;<span class="integer">10</span>) { <span class="keyword">break</span>;}
                }
                consumer.close();
         }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Esta configuración no es la que buscamos.</p>
</li>
<li>
<p>Normalmente no vamos a parar al leer una serie de mensajes, estaremos hasta que alguien pare la JVM.</p>
</li>
<li>
<p>Para evitar esto, vamos a usar una variable <strong>AtomicBoolean</strong>, que nos permita parar el proceso cuando se reciba una señal de parar en la JVM</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ConsumerEjemplo02</span> {
        <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);<span class="comment">//para cerrar al matar el proceso</span>

         <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
            <span class="annotation">@Override</span>
            <span class="directive">public</span> <span class="type">void</span> run() {
                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
                closed.set(<span class="predefined-constant">true</span>);
            }
        });

                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">consumer_base</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
                <span class="predefined-type">String</span> s=ConsumerConfig.AUTO_OFFSET_RESET_CONFIG;
                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
                consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>));
                <span class="type">int</span> leidos=<span class="integer">0</span>;
                <span class="keyword">while</span> (!closed.get()) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="integer">1000</span>);
                        <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
                                <span class="keyword">if</span> (++leidos&gt;<span class="integer">10</span>) { <span class="keyword">break</span>;}
                }
                consumer.close();
         }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_garantía_de_entrega">10.4. Garantía de entrega</h3>
<div class="ulist">
<ul>
<li>
<p>Existen tres configuraciones posibles en kafka para la garantía de entrega</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_at_most_once">10.4.1. At most once</h4>
<div class="ulist">
<ul>
<li>
<p>El mensaje se entregará como máximo una vez.</p>
</li>
<li>
<p>Una vez entregado, no se podrá enviar de nuevo.</p>
</li>
<li>
<p>Si el consumidor no puede tratarlo, el mensaje se perderá.</p>
</li>
<li>
<p>Esto se debe a que kafka generará un commit del último offset leido.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Es posible tener un escenario de tipo "al menos una vez"</p>
</li>
<li>
<p>Si procesamos el mensaje y kafka no tiene tiempo de hacer el autocommit, el consumidor leerá el mismo mensaje.</p>
</li>
<li>
<p>Debemos estar preparados para duplicados en estos escenarios.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_at_least_once">10.4.2. At least once</h4>
<div class="ulist">
<ul>
<li>
<p>El mensaje se enviará al menos una vez.</p>
</li>
<li>
<p>Es facil que el mensaje se duplique.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora debemos controlar manualmente el offset con la instrucción:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">consumer.commitSync()</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Igual que en el anterior, si el consumidor cae antes de lanzar el commitSync, el mensaje o mensajes se duplicarán.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_exactly_once">10.4.3. Exactly-once</h4>
<div class="ulist">
<ul>
<li>
<p>Garantizamos que uno y solo un mensaje se leerá.</p>
</li>
<li>
<p>En versiones anteriores, la implementación era manual, y había que implementar un ConsumerRebalanceListener que permitiera leer a partir de un offset concreto de una partición de un topic.</p>
</li>
<li>
<p>Para garantizarlo, ahora podemos usar las transacciones en Kafka.</p>
</li>
<li>
<p>La implementación debe ser tanto en el productor como en el consumidor.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_configuración_del_productor">10.4.3.1. Configuración del productor</h5>
<div class="ulist">
<ul>
<li>
<p>Para una garantía total, debemos definir idempotencia para que no permita duplicación de mensajes.</p>
</li>
<li>
<p>Podemos confirmar la escritura en todas las réplicas</p>
</li>
<li>
<p>Debemos definir un transactional.id que permita localizar quien es el productor que va a generar las transacciones y que kafka le haga un seguimiento.</p>
</li>
<li>
<p>Si queremos garantizar el orden, definimos que haya una sola petición por conexión.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// Configuración de transacción.</span>
properties.put(ProducerConfig.ACKS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">all</span><span class="delimiter">&quot;</span></span>);
properties.put(ProducerConfig.CLIENT_ID_CONFIG, TransactionalProducer.class.getName()+TOPIC);
properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, TransactionalProducer.class.getName()+TOPIC);
properties.put(ProducerConfig.RETRIES_CONFIG, <span class="integer">3</span>);
<span class="comment">// Permite garantizar el orden</span>
properties.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, <span class="integer">1</span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el productor se debe notificar al broker que vamos a usar transacciones</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">producer.initTransactions();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Antes de enviar los ProducerRecords, iniciamos la transacción</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">producer.beginTransaction();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras enviar todos los records que necesitemos enviar en la transacción, confirmamos por medio de la siguiente instrucción:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">producer.commitTransaction();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En caso de producir un error, podemos capturar la excepción y abortar la transacción</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">producer.abortTransaction();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si el productor cae, y no realiza el commit, los mensajes que no estuvieran en el commit no se leen por parte del consumidor, si está configurado adecuadamente.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_configuración_del_consumidor">10.4.3.2. Configuración del consumidor</h5>
<div class="ulist">
<ul>
<li>
<p>Nuestro consumidor se configurará para un nivel de aislamiento "read_committed".</p>
</li>
<li>
<p>Por defecto los consumidores leen "read_uncommitted", lo que les permitiría leer mensajes no confirmados por el productor.</p>
</li>
<li>
<p>Para confirmar la lectura de los mensajes, definimos el autocommit a false para poder gestionarlo manualmente.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">read_committed</span><span class="delimiter">&quot;</span></span>);<span class="comment">// default &quot;read_uncommitted&quot;</span>
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El consumidor debe confirmar los mensajes leidos y procesados.</p>
</li>
<li>
<p>Para ello, almacenamos un mapa con el offset por partición que queremos leer en caso de que nos tengamos que recurperar de una caida de servicio.</p>
</li>
<li>
<p>El objeto TopicPartition indica la partición del topic que queremos asignar el offset</p>
</li>
<li>
<p>El objeto OffsetAndMetadata nos permite indicar el offset del siguiente registro que queremos leer.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">HashMap</span>&lt;TopicPartition,OffsetAndMetadata&gt; partitionsWithOffset = <span class="keyword">new</span> <span class="predefined-type">HashMap</span>&lt;&gt;();
<span class="keyword">for</span> (TopicPartition partition: records.partitions()) {
        <span class="predefined-type">List</span>&lt;ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt;&gt; list = records.records(partition);
        <span class="type">long</span> offset = list.get(list.size() -<span class="integer">1</span>).offset();
        partitionsWithOffset.put(partition, <span class="keyword">new</span> OffsetAndMetadata(offset+<span class="integer">1</span>));
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por último, confirmamos los mensajes leidos en la transacción.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">consumer.commitSync(partitionsWithOffset);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>De esta forma kafka está notificado de la lectura del consumidor.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_coordinador">10.4.3.3. Coordinador</h5>
<div class="ulist">
<ul>
<li>
<p>Todo broker de kafka tiene un módulo de coordinador, responsable de gestionar las transacciones.</p>
</li>
<li>
<p>Para ello almacenará una marca en la partición (que ocupará un offset) para indicar que la transacción es correcta.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_invocando_productores_y_consumidores">10.5. Lab: Invocando productores y consumidores</h3>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Para realizar este laboratorio necesitamos tener iniciado tanto zookeeper como los brokers.</p>
</li>
<li>
<p>Comprobamos que nuestros brokers están correctamente registrados:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh
Connecting to localhost:2181
2019-01-23 19:34:34,042 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.14-e5259e437540f349646870ea94dc2658c4e44b3b, built on 03/27/2018 03:55 GMT
...
[zk: localhost:2181(CONNECTED) 0] ls /brokers/ids
[0, 1, 2]</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_creación_de_topics">10.5.1. Creación de topics</h4>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear topics por medio de una clase helper.</p>
</li>
<li>
<p>Para ello, vamos a copiar el proyecto PlantillaKafka y lo llamaremos kafka-utils.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-01.png" alt="kafka java api lab 01" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el pom.xml vamos a modificar el nombre del proyecto para que no haya conflictos, y cambiamos la versión.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">        &lt;groupId&gt;com.curso.kafka&lt;/groupId&gt;
        &lt;artifactId&gt;kafka-utils&lt;/artifactId&gt;
        &lt;version&gt;<span class="float">1.0</span><span class="float">.0</span>&lt;/version&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos una clase en el paquete com.curso.kafka.util llamada TopicCreator.java</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.util</span>;

<span class="keyword">import</span> <span class="include">java.util.ArrayList</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.ExecutionException</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.admin.AdminClient</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.admin.CreateTopicsResult</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.admin.NewTopic</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">TopicCreator</span> {
        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> createTopics(<span class="predefined-type">String</span> servers,<span class="predefined-type">String</span>... topics) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">bootstrap.servers</span><span class="delimiter">&quot;</span></span>, servers);
                AdminClient adminClient = AdminClient.create(props);
                <span class="predefined-type">ArrayList</span>&lt;NewTopic&gt; newTopics = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;&gt;();
                <span class="keyword">for</span>(<span class="predefined-type">String</span> topicName: topics) {
                        newTopics.add(<span class="keyword">new</span> NewTopic(topicName, <span class="integer">3</span>,<span class="predefined-type">Short</span>.parseShort(<span class="string"><span class="delimiter">&quot;</span><span class="content">1</span><span class="delimiter">&quot;</span></span>)));
                }
                CreateTopicsResult result = adminClient.createTopics(newTopics);

                <span class="keyword">try</span> {
                        result.all().get();
                } <span class="keyword">catch</span> (<span class="exception">InterruptedException</span> e) {
                        <span class="predefined-type">System</span>.out.println(e.getMessage());
                } <span class="keyword">catch</span> (<span class="exception">ExecutionException</span> e) {
                        <span class="predefined-type">System</span>.out.println(e.getMessage());
                }
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>De esta forma, podremos crear topics para el curso con tres particiones cada una.</p>
</li>
<li>
<p>Ahora, para facilitar el uso de la clase, vamos a agregar la dependencia al proyecto PlantillaKafka</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>com.curso.kafka<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>kafka-utils<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>1.0.0<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_creación_de_productor">10.5.2. Creación de productor</h4>
<div class="ulist">
<ul>
<li>
<p>Para ello vamos a copiar nuestra plantilla y llamamos al proyecto Ejemplo01ProducersConsumers</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Sería mucho más interesante generar un arquetipo en Maven para tener directamente el esquema del proyecto, pero por agilidad, copiaremos el proyecto</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Primero seleccionamos el proyecto y lo copiamos</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-02.png" alt="kafka java api lab 02" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Luego pegamos en el <strong>Package Explorer</strong> el proyecto</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-03.png" alt="kafka java api lab 03" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Llamamos al proyecto <strong>Ejemplo01ProductoresConsumidores</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-04.png" alt="kafka java api lab 04" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Modificamos el pom del proyecto para que se llame como el proyecto que hemos creado.</p>
</li>
<li>
<p>Solo modificamos el &lt;artifactId&gt;</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;project</span> <span class="attribute-name">xmlns</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/POM/4.0.0</span><span class="delimiter">&quot;</span></span>
        <span class="attribute-name">xmlns:xsi</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://www.w3.org/2001/XMLSchema-instance</span><span class="delimiter">&quot;</span></span>
        <span class="attribute-name">xsi:schemaLocation</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd</span><span class="delimiter">&quot;</span></span><span class="tag">&gt;</span>
        <span class="tag">&lt;modelVersion&gt;</span>4.0.0<span class="tag">&lt;/modelVersion&gt;</span>
        <span class="tag">&lt;groupId&gt;</span>com.curso.kafka<span class="tag">&lt;/groupId&gt;</span>
        <span class="tag">&lt;artifactId&gt;</span>Ejemplo01ProductoresConsumidores<span class="tag">&lt;/artifactId&gt;</span>
        <span class="tag">&lt;version&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/version&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Agregamos la dependencia</p>
</li>
<li>
<p>Vamos a producir mensajes, para ello creamos un productor:</p>
</li>
<li>
<p>Creamos una nueva clase:</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-05.png" alt="kafka java api lab 05" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La nueva clase se llamará:</p>
<div class="ulist">
<ul>
<li>
<p>Package: com.curso.kafka.producersconsumers.simple</p>
</li>
<li>
<p>Name: SimpleProducer</p>
</li>
<li>
<p>Public static void main: true</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-06.png" alt="kafka java api lab 06" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El contenido será el siguiente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.simple</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.ExecutionException</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Producer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringSerializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.TopicCreator</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SimpleProducer</span> {

        <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">String</span> BROKER_LIST = <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost:9092</span><span class="delimiter">&quot;</span></span>;
    <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">String</span> TOPIC = <span class="string"><span class="delimiter">&quot;</span><span class="content">topic-simple</span><span class="delimiter">&quot;</span></span>;

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span>, <span class="exception">ExecutionException</span> {

            TopicCreator.createTopics(BROKER_LIST, TOPIC);

        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

            Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);

        <span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
            <span class="predefined-type">String</span> key = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">key[%d]</span><span class="delimiter">&quot;</span></span>, id);
            <span class="predefined-type">String</span> message = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">message[%d]</span><span class="delimiter">&quot;</span></span>, id);
            <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Sending message with: </span><span class="delimiter">&quot;</span></span> + key);
            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC, key, message));
            <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
        }

        producer.flush();
        producer.close();
    }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al principio indicamos la creación síncrona de los topics</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">TopicCreator.createTopics(BROKER_LIST, TOPIC);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Aquí indicamos la configuración del productor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Estamos indicando la lista inicial de los brokers de kafka</p>
</li>
<li>
<p>Indicamos los serializadores por defecto para almacenar en el topic</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Aquí vemos como se crea el productor indicando la clave y el valor, y asignando las propiedades por defecto.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
    <span class="predefined-type">String</span> key = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">key[%d]</span><span class="delimiter">&quot;</span></span>, id);
    <span class="predefined-type">String</span> message = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">message[%d]</span><span class="delimiter">&quot;</span></span>, id);
    <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Sending message with: </span><span class="delimiter">&quot;</span></span> + key);
    producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC, key, message));
    <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el bucle, mandamos mensajes de tipo clave/valor al topic elegido</p>
</li>
<li>
<p>Esperamos un segundo por petición</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>El hecho de enviar no significa explicitamente que envie.</p>
</li>
<li>
<p>Debe cumplir una condición de número de mensajes encolados o un tiempo de terminado, y manda toda la información en paquetes.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    producer.flush();
    producer.close();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Forzamos a enviar los documentos que estén encolados con flush y cerramos el canal con close.</p>
</li>
<li>
<p>Ejecutamos la clase para conectarse a nuestro topic y enviar los datos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Sending message with: key[<span class="integer">0</span>]
Sending message with: key[<span class="integer">1</span>]
Sending message with: key[<span class="integer">2</span>]
...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nuestro <strong>Productor</strong> está funcionando!</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_simple_consumer">10.5.3. Simple Consumer</h4>
<div class="ulist">
<ul>
<li>
<p>Veamos ahora con nuestro consumidor. Creamos la clase <strong>com.curso.kafka.api.consumer.simple.SimpleConsumer</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.simple</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SimpleConsumer</span> {

        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> KAFKA_HOST = <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost:9092</span><span class="delimiter">&quot;</span></span>;
    <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);<span class="comment">//para cerrar al matar el proceso</span>

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
            <span class="annotation">@Override</span>
            <span class="directive">public</span> <span class="type">void</span> run() {
                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
                closed.set(<span class="predefined-constant">true</span>);
            }
        });

        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_HOST);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">simple-consumer</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(SimpleProducer.TOPIC));

        <span class="keyword">while</span> (!closed.get()) {
            ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofMillis(<span class="integer">1000</span>));
            <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                        record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
        }

        consumer.close();
    }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Primero definimos el shutdown hook para cerrar el consumidor correctamente.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> run() {
        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
        closed.set(<span class="predefined-constant">true</span>);
    }
});</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Configuramos el consumidor:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_HOST);
    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
    props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
    props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">simple-consumer</span><span class="delimiter">&quot;</span></span>);
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Indicamos al menos un servidor para que sea alcanzable y pueda preguntar por el mapa de brokers que necesite para el topic.</p>
</li>
<li>
<p>Activamos el autocommit para que se acuerde cada 100 ms de donde estaba el consumidor</p>
</li>
<li>
<p>Indicamos cuales son los deserializadores para clave y valor.</p>
</li>
<li>
<p>Ahora creamos el consumidor y nos suscribimos al topic. Podríamos suscribirnos a una lista de topics.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
    consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(SimpleProducer.TOPIC));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por último, indicamos que mientras no esté cerrada la vm, vamos a consumir registros:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">while</span> (!closed.get()) {
    ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofMillis(<span class="integer">1000</span>));
    <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
        <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Obtenemos el record y vemos que información relevante posee publicandola directamente en el log</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_prueba_de_ejecución">10.5.4. Prueba de ejecución</h4>
<div class="ulist">
<ul>
<li>
<p>Ejecutamos el consumidor y confirmamos que consume los mensajes nuevos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">...
partition =  1   offset =     3   key = key[13] timestamp = 1603106530616  value =  message[13]
partition =  1   offset =     4   key = key[14] timestamp = 1603106531617  value =  message[14]
partition =  0   offset =     6   key = key[15] timestamp = 1603106532619  value =  message[15]
partition =  2   offset =     4   key = key[16] timestamp = 1603106533621  value =  message[16]
partition =  1   offset =     5   key = key[17] timestamp = 1603106534622  value =  message[17]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Paramos el consumidor y nos fijamos en que offset estaba trabajando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">partition =  1   offset =    15   key = key[37] timestamp = 1603106554646  value =  message[37]
partition =  2   offset =    10   key = key[38] timestamp = 1603106555647  value =  message[38]
partition =  0   offset =    12   key = key[39] timestamp = 1603106556648  value =  message[39]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Volvemos a arrancarlo al cabo de unos segundos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">partition =  0   offset =    13   key = key[41] timestamp = 1603106558650  value =  message[41]
partition =  0   offset =    14   key = key[42] timestamp = 1603106559651  value =  message[42]
partition =  0   offset =    15   key = key[48] timestamp = 1603106565658  value =  message[48]
partition =  0   offset =    16   key = key[52] timestamp = 1603106569665  value =  message[52]
partition =  0   offset =    17   key = key[53] timestamp = 1603106570667  value =  message[53]
partition =  0   offset =    18   key = key[54] timestamp = 1603106571668  value =  message[54]
partition =  0   offset =    19   key = key[61] timestamp = 1603106578678  value =  message[61]
partition =  0   offset =    20   key = key[62] timestamp = 1603106579679  value =  message[62]
partition =  0   offset =    21   key = key[63] timestamp = 1603106580681  value =  message[63]
partition =  0   offset =    22   key = key[65] timestamp = 1603106582688  value =  message[65]
partition =  0   offset =    23   key = key[67] timestamp = 1603106584696  value =  message[67]
partition =  0   offset =    24   key = key[68] timestamp = 1603106585698  value =  message[68]
partition =  2   offset =    11   key = key[40] timestamp = 1603106557649  value =  message[40]
partition =  2   offset =    12   key = key[43] timestamp = 1603106560653  value =  message[43]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como sigue trabajando directamente desde donde lo dejó.</p>
</li>
<li>
<p>Hay que darse cuenta que el orden no está garantizado entre particiones.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_partitionproducer">10.5.5. PartitionProducer</h4>
<div class="ulist">
<ul>
<li>
<p>Si nos damos cuenta, a pesar de tener un topic con tres particiones, toda la información va a la primera partición.</p>
</li>
<li>
<p>Vamos a crear un nuevo particionador y un productor basado en el anterior para comprobar que podemos decidir a donde van los documentos por medio del mismo.</p>
</li>
<li>
<p>Primero creamos el particionador en com.curso.kafka.producersconsumers.partitioner.SimplePartitioner</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.partitioner</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Partitioner</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.Cluster</span>;
<span class="keyword">import</span> <span class="include">java.util.Map</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SimplePartitioner</span> <span class="directive">implements</span> Partitioner {

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">int</span> partition(<span class="predefined-type">String</span> topic, <span class="predefined-type">Object</span> key, <span class="type">byte</span><span class="type">[]</span> keyBytes, <span class="predefined-type">Object</span> value, <span class="type">byte</span><span class="type">[]</span> valueBytes, Cluster cluster) {
        <span class="keyword">return</span> <span class="predefined-type">Math</span>.abs(key.hashCode() % cluster.partitionCountForTopic(topic));
    }

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> close() {}

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> configure(<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, ?&gt; conf) {}
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este caso, usamos el codigo hash y calculamos el modulo con la información  de particiones que nos ofrece el cluster.</p>
</li>
<li>
<p>Ahora vamos a crear un nuevo productor que use el nuevo particionador.</p>
</li>
<li>
<p>Copiamos el productor y lo renombramos a PartitionProducer.</p>
</li>
<li>
<p>Agregamos la información del partitioner en la configuración:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, SimplePartitioner.class.getName());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La clase resultante es la siguiente.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.partitioner</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringSerializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.TopicCreator</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">PartitionProducer</span> {

        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> BROKER_LIST = <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost:9092</span><span class="delimiter">&quot;</span></span>;
        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> TOPIC = <span class="string"><span class="delimiter">&quot;</span><span class="content">partition-producer-topic</span><span class="delimiter">&quot;</span></span>;

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
                <span class="comment">// Topics creados</span>

                TopicCreator.createTopics(BROKER_LIST, TOPIC);

                <span class="comment">// Config</span>
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
                props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, SimplePartitioner.class.getName());

                KafkaProducer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);

                <span class="keyword">for</span>(<span class="type">int</span> id=<span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
                        <span class="predefined-type">String</span> key = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">key[%d]</span><span class="delimiter">&quot;</span></span>, id);
                        <span class="predefined-type">String</span> value = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">value[%d]</span><span class="delimiter">&quot;</span></span>, id);
                        ProducerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC, key, value);
                        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Enviando mensaje : </span><span class="delimiter">&quot;</span></span> + record.toString());
                        producer.send(record);
                        <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
                }
                producer.flush();
                producer.close();
        }

}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Realizamos la misma operación para el consumidor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">package com.curso.kafka.producersconsumers.partitioner;

import java.time.Duration;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import java.util.concurrent.atomic.AtomicBoolean;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;

public class PartitionConsumer {
        private static final AtomicBoolean closed = new AtomicBoolean(false);

        public static void main(String[] args) {
                Runtime.getRuntime().addShutdownHook(new Thread() {
                        @Override
                        public void run() {
                                System.out.println(&quot;Apagando&quot;);
                                closed.set(true);
                        }
                });
                // Configs
                Properties props = new Properties();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;true&quot;);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;);// __consumer_offsets
                props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;PartitionConsumer&quot;);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

                KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);

                List&lt;TopicPartition&gt; particiones = new ArrayList&lt;&gt;();
                particiones.add(new TopicPartition(PartitionProducer.TOPIC, 0));
                particiones.add(new TopicPartition(PartitionProducer.TOPIC, 2));

                //consumer.subscribe(Collections.singletonList(SimpleProducer.TOPIC_BASE));
                consumer.assign(particiones);

                while(!closed.get()) {
                        ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));
                        for(ConsumerRecord&lt;String, String&gt; record: records) {
                                System.out.printf(&quot;particion = %2d offset = %5d key = %7s ts = %8s value %12s\n&quot;,
                                                record.partition(),
                                                record.offset(),
                                                record.key(),
                                                String.valueOf(record.timestamp()),
                                                record.value()
                                                );
                        }
                }
                consumer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Iniciamos el productor para que mande los mensajes y luego el consumidor si no lo hemos dejado levantado con anterioridad.</p>
</li>
<li>
<p>Comprobaremos como estamos usando nuestro propio particionador.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">partition =  1   offset =    53   key =  key[0] timestamp = 1603106685658  value =   message[0]
partition =  0   offset =    57   key =  key[1] timestamp = 1603106686672  value =   message[1]
partition =  2   offset =    45   key =  key[2] timestamp = 1603106687674  value =   message[2]
partition =  1   offset =    54   key =  key[3] timestamp = 1603106688677  value =   message[3]
partition =  0   offset =    58   key =  key[4] timestamp = 1603106689677  value =   message[4]
partition =  2   offset =    46   key =  key[5] timestamp = 1603106690681  value =   message[5]
partition =  1   offset =    55   key =  key[6] timestamp = 1603106691683  value =   message[6]
partition =  0   offset =    59   key =  key[7] timestamp = 1603106692686  value =   message[7]</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_groups">10.5.6. Groups</h4>
<div class="ulist">
<ul>
<li>
<p>Con el productor levantado, vamos iniciar de nuevo el partition consumer, ya que pertenecerá al mismo grupo.</p>
</li>
<li>
<p>En cuanto lo ejecutemos, veremos como se apodera de todas las particiones y consume todos los registros.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Adding    : [topicSimple-0, topicSimple-1, topicSimple-2]
....
partition =  2   offset =   176   key = key[394]   value = message[394]
partition =  0   offset =   188   key = key[395]   value = message[395]
partition =  1   offset =   185   key = key[396]   value = message[396]
partition =  2   offset =   177   key = key[397]   value = message[397]
partition =  0   offset =   189   key = key[398]   value = message[398]
partition =  1   offset =   186   key = key[399]   value = message[399]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora ejecutamos otra instancia de la misma clase con run as &#8594; Java Application.</p>
</li>
<li>
<p>Comprobaremos como en la instancia inicial aparece el siguiente mensaje</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Removing  : [topicSimple-0, topicSimple-1, topicSimple-2]
Adding    : [topicSimple-0, topicSimple-1]
partition =  0   offset =   190   key = key[401]   value = message[401]
partition =  1   offset =   187   key = key[402]   value = message[402]
partition =  0   offset =   191   key = key[404]   value = message[404]
partition =  1   offset =   188   key = key[405]   value = message[405]
partition =  0   offset =   192   key = key[407]   value = message[407]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y en la nueva instancia aparece la partición que no está asignada, y a partir de ahi, los mensajes solo se leen desde las particiones que posee</p>
</li>
<li>
<p>En cuanto a la segunda instancia:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Adding    : [topicSimple-2]
partition =  2   offset =   179   key = key[403]   value = message[403]
partition =  2   offset =   180   key = key[406]   value = message[406]
partition =  2   offset =   181   key = key[409]   value = message[409]
partition =  2   offset =   182   key = key[412]   value = message[412]
partition =  2   offset =   183   key = key[415]   value = message[415]
partition =  2   offset =   184   key = key[418]   value = message[418]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como se agrupan y obtienen los mensajes de la partición adicional.</p>
</li>
<li>
<p>Arrancamos una tercera instancia y veremos como cada uno posee el acceso a una sola partición.</p>
</li>
<li>
<p>Así garantizamos que las instancias leen mensajes distintos.</p>
</li>
<li>
<p>Pero, y si agregamos un cuarto,</p>
</li>
<li>
<p>Veremos como una de las instancias se queda sin recibir mensajes.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">partition =  2   offset =   322   key = key[832]   value = message[832]
Removing  : [topicSimple-2]
Adding    : []</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si paramos cualquier otra instancia, el sistema lo entiende y reasigna las particiones</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Removing  : <span class="type">[]</span>
Adding    : [topicSimple-<span class="integer">2</span>]
partition =  <span class="integer">2</span>   offset =   <span class="integer">345</span>   key = key[<span class="integer">901</span>]   value = message[<span class="integer">901</span>]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Paramos todos los consumidores</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_autocommit">10.5.7. Autocommit</h4>
<div class="ulist">
<ul>
<li>
<p>En este caso vamos a gestionar el commit de forma manual.</p>
</li>
<li>
<p>Para ello creamos una clase llamada ManualCommitConsumer.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.commit</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ManualCommitConsumer</span> {
        <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
                <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>() {
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> run() {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Apagando</span><span class="delimiter">&quot;</span></span>);
                                closed.set(<span class="predefined-constant">true</span>);
                        }
                });
                <span class="comment">// Configs</span>
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">AutoCommitConsumer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
                consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(PartitionProducer.TOPIC));
                <span class="keyword">while</span>(!closed.get()) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofSeconds(<span class="integer">1</span>));
                        <span class="keyword">for</span>(ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record: records) {
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">particion = %2d offset = %5d key = %7s ts = %8s value %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                                record.partition(),
                                                record.offset(),
                                                record.key(),
                                                <span class="predefined-type">String</span>.valueOf(record.timestamp()),
                                                record.value()
                                                );

                        }
                        consumer.commitSync();
                        <span class="predefined-type">Thread</span>.sleep(<span class="integer">5000</span>);

                }
                consumer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ejecutamos el nuevo productor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">partition =  <span class="integer">0</span>   offset =   <span class="integer">470</span>   key = key[<span class="integer">1242</span>]   value = message[<span class="integer">1242</span>]
partition =  <span class="integer">0</span>   offset =   <span class="integer">471</span>   key = key[<span class="integer">1245</span>]   value = message[<span class="integer">1245</span>]
partition =  <span class="integer">0</span>   offset =   <span class="integer">472</span>   key = key[<span class="integer">1248</span>]   value = message[<span class="integer">1248</span>]
partition =  <span class="integer">0</span>   offset =   <span class="integer">473</span>   key = key[<span class="integer">1251</span>]   value = message[<span class="integer">1251</span>]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ejecutamos este consumidor, posteriormente el productor. Vemos como va consumiendo. Hacemos una parada después de unos 10 segundos y volvemos a levantarlo.</p>
</li>
<li>
<p>Paramos entonces el consumidor y lo dejamos parado 10 segundos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">partition =  <span class="integer">0</span>   offset =   <span class="integer">470</span>   key = key[<span class="integer">1242</span>]   value = message[<span class="integer">1242</span>]
partition =  <span class="integer">0</span>   offset =   <span class="integer">471</span>   key = key[<span class="integer">1245</span>]   value = message[<span class="integer">1245</span>]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hay registros que ha vuelto a procesar. Como no llegó a guardar el último offset, no registró los últimos mensajes procesados.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_partitionconsumer">10.5.8. PartitionConsumer</h4>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear un consumidor que se conecte a una partición concreta.</p>
</li>
<li>
<p>Para ello creamos la siguiente clase:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.manualpartition</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.ArrayList</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.TopicPartition</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ManualPartitionConsumer</span> {
        <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
                <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>() {
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> run() {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Apagando</span><span class="delimiter">&quot;</span></span>);
                                closed.set(<span class="predefined-constant">true</span>);
                        }
                });
                <span class="comment">// Configs</span>
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);<span class="comment">// __consumer_offsets</span>
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">SeekConsumer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);

                <span class="predefined-type">List</span>&lt;TopicPartition&gt; particiones = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;&gt;();
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">0</span>));
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">2</span>));

                consumer.assign(particiones);

                <span class="keyword">while</span>(!closed.get()) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofSeconds(<span class="integer">1</span>));
                        <span class="keyword">for</span>(ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record: records) {
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">particion = %2d offset = %5d key = %7s ts = %8s value %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                                record.partition(),
                                                record.offset(),
                                                record.key(),
                                                <span class="predefined-type">String</span>.valueOf(record.timestamp()),
                                                record.value()
                                                );
                        }
                }
                consumer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al ejecutarlo, vemos como solo usa las particiones que hemos decidido.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">topic = topicSimple partition =  2   offset =   764   key = key[2132]   value = message[2132]
topic = topicSimple partition =  0   offset =   767   key = key[2133]   value = message[2133]
topic = topicSimple partition =  2   offset =   765   key = key[2135]   value = message[2135]
topic = topicSimple partition =  0   offset =   768   key = key[2136]   value = message[2136]</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_seekconsumer">10.5.9. SeekConsumer</h4>
<div class="ulist">
<ul>
<li>
<p>Usando el truco de las particiones, vamos a buscar en este caso un offset concreto.</p>
</li>
<li>
<p>Para ello vamos a crear la siguiente clase</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.manualpartition</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.ArrayList</span>;
<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.TopicPartition</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SeekConsumer</span> {
        <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
                <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>() {
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> run() {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Apagando</span><span class="delimiter">&quot;</span></span>);
                                closed.set(<span class="predefined-constant">true</span>);
                        }
                });
                <span class="comment">// Configs</span>
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);<span class="comment">// __consumer_offsets</span>
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">SeekConsumer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);

                <span class="predefined-type">List</span>&lt;TopicPartition&gt; particiones = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;&gt;();
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">0</span>));
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">1</span>));
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">2</span>));

                <span class="comment">//consumer.subscribe(Collections.singletonList(SimpleProducer.TOPIC_BASE));</span>
                consumer.assign(particiones);
                consumer.seekToBeginning(<span class="predefined-type">Collections</span>.singleton(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">0</span>)));
                consumer.seekToEnd(<span class="predefined-type">Collections</span>.singleton(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC,<span class="integer">1</span>)));
                consumer.seek(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">2</span>), <span class="integer">37</span>);
                <span class="keyword">while</span>(!closed.get()) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofSeconds(<span class="integer">1</span>));
                        <span class="keyword">for</span>(ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record: records) {
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">particion = %2d offset = %5d key = %7s ts = %8s value %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                                record.partition(),
                                                record.offset(),
                                                record.key(),
                                                <span class="predefined-type">String</span>.valueOf(record.timestamp()),
                                                record.value()
                                                );
                        }
                }
                consumer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este caso, vamos a ejecutarlo con las siguientes condiciones:</p>
<div class="ulist">
<ul>
<li>
<p>Leemos de la partición 0 desde el principio.</p>
</li>
<li>
<p>Leemos de la partición 1 a partir del último registro</p>
</li>
<li>
<p>Leemos de la partición 2 a partir del offset 600 (Si no tenemos offset 600 no dará error y leerá desde el final).</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">topic = topicSimple partition =  2   offset =   600   key = key[1666]   value = message[1666]
topic = topicSimple partition =  2   offset =   601   key = key[1669]   value = message[1669]
topic = topicSimple partition =  2   offset =   602   key = key[1672]   value = message[1672]
topic = topicSimple partition =  2   offset =   603   key = key[1675]   value = message[1675]
topic = topicSimple partition =  2   offset =   604   key = key[1678]   value = message[1678]
...
topic = topicSimple partition =  0   offset =     0   key =  key[0]   value =   message[0]
topic = topicSimple partition =  0   offset =     1   key =  key[5]   value =   message[5]
topic = topicSimple partition =  0   offset =     2   key =  key[7]   value =   message[7]
topic = topicSimple partition =  0   offset =     3   key =  key[8]   value =   message[8]
...
topic = topicSimple partition =  0   offset =   709   key = key[1959]   value = message[1959]
topic = topicSimple partition =  2   offset =   698   key = key[1960]   value = message[1960]
topic = topicSimple partition =  1   offset =   707   key = key[1961]   value = message[1961]</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_consumer_info">10.5.10. Consumer Info</h4>
<div class="ulist">
<ul>
<li>
<p>Los consumidores poseen información relevante de los topics donde están conectados.</p>
</li>
<li>
<p>Para comprobarlo, creamos la siguiente clase:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.info</span>;

<span class="keyword">import</span> <span class="include">java.util.HashSet</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Map</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.Set</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.Node</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.PartitionInfo</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.TopicPartition</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.simple.SimpleProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">InfoConsumer</span> {
    <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> KAFKA_HOST = <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost:9092</span><span class="delimiter">&quot;</span></span>;
    <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
            <span class="annotation">@Override</span>
            <span class="directive">public</span> <span class="type">void</span> run() {
                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
                closed.set(<span class="predefined-constant">true</span>);
            }
        });

        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_HOST);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">info-simple</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);

        <span class="keyword">for</span>(<span class="predefined-type">Map</span>.Entry&lt;<span class="predefined-type">String</span>, <span class="predefined-type">List</span>&lt;PartitionInfo&gt;&gt; entry : consumer.listTopics().entrySet()){
            <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Topic: </span><span class="delimiter">&quot;</span></span> + entry.getKey());
            <span class="keyword">for</span>(PartitionInfo partition : entry.getValue()) {
                <span class="predefined-type">Set</span>&lt;<span class="predefined-type">Integer</span>&gt; replicas = <span class="keyword">new</span> <span class="predefined-type">HashSet</span>&lt;&gt;();
                <span class="predefined-type">Set</span>&lt;<span class="predefined-type">Integer</span>&gt; inSync = <span class="keyword">new</span> <span class="predefined-type">HashSet</span>&lt;&gt;();

                <span class="keyword">for</span>(Node node : partition.replicas()) replicas.add(node.id());
                <span class="keyword">for</span>(Node node : partition.inSyncReplicas()) inSync.add(node.id());

                <span class="predefined-type">System</span>.out.println(<span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">  P: %2s   Leader: %2s   Replicas: %4s   InSync: %4s</span><span class="delimiter">&quot;</span></span>,
                        partition.partition(), partition.leader().id(), replicas, inSync));
            }
        }

        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">---------------------------</span><span class="delimiter">&quot;</span></span>);
        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">---------------------------</span><span class="delimiter">&quot;</span></span>);
        TopicPartition topic = <span class="keyword">new</span> TopicPartition(SimpleProducer.TOPIC, <span class="integer">0</span>);
        <span class="predefined-type">Set</span>&lt;TopicPartition&gt; topics = <span class="keyword">new</span> <span class="predefined-type">HashSet</span>&lt;TopicPartition&gt;();
        topics.add(topic);

        <span class="predefined-type">System</span>.out.println(<span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">Last offsets for %s : %s</span><span class="delimiter">&quot;</span></span>, topic, consumer.committed(topics)));

        consumer.close();
    }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si ejecutamos, el resultado será el siguiente</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Topic: topicSimple
  P:  0   Leader:  2   Replicas:  [2]   InSync:  [2]
  P:  2   Leader:  1   Replicas:  [1]   InSync:  [1]
  P:  1   Leader:  3   Replicas:  [3]   InSync:  [3]
Topic: __consumer_offsets
  P:  0   Leader:  1   Replicas:  [1]   InSync:  [1]
  P: 10   Leader:  2   Replicas:  [2]   InSync:  [2]
  P: 20   Leader:  3   Replicas:  [3]   InSync:  [3]
  ....
---------------------------
---------------------------
Last offsets for topicSimple-0 : {topicSimple-0=null}
Shutting down</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_transaccionalidad">10.5.11. Transaccionalidad</h4>
<div class="ulist">
<ul>
<li>
<p>Para comprobar el modelo "exactly-once" de kafka, configuraremos un productor y un consumidor.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_productor">10.5.11.1. Productor</h5>
<div class="ulist">
<ul>
<li>
<p>Para ello primero creamos un productor:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.transactional</span>;

<span class="keyword">import</span> <span class="include">java.io.IOException</span>;
<span class="keyword">import</span> <span class="include">java.util.Arrays</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.Random</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.ExecutionException</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.errors.ProducerFencedException</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringSerializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">TransactionalProducer</span> {

        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; CITIES = <span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">madrid</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">barcelona</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">burgos</span><span class="delimiter">&quot;</span></span>);
        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> TOPIC = <span class="string"><span class="delimiter">&quot;</span><span class="content">topic-transactions</span><span class="delimiter">&quot;</span></span>;

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span>, <span class="exception">ExecutionException</span> {
                <span class="predefined-type">Properties</span> properties = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                <span class="comment">// Configuración de transacción.</span>
                properties.put(ProducerConfig.ACKS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">all</span><span class="delimiter">&quot;</span></span>);
                properties.put(ProducerConfig.CLIENT_ID_CONFIG, TransactionalProducer.class.getName()+TOPIC);
                properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, TransactionalProducer.class.getName()+TOPIC);
                properties.put(ProducerConfig.RETRIES_CONFIG, <span class="integer">3</span>);
                <span class="comment">// Permite garantizar el orden</span>
                properties.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, <span class="integer">1</span>);
                <span class="comment">//properties.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 600000);</span>

                KafkaProducer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);
                <span class="comment">// Notificación de gestión de transacciónes</span>
                producer.initTransactions();

                <span class="predefined-type">Thread</span> thread = <span class="keyword">new</span> <span class="predefined-type">Thread</span>(producer::close);
                <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(thread);
                <span class="type">int</span> i = <span class="integer">1</span>;
                <span class="predefined-type">Random</span> random = <span class="keyword">new</span> <span class="predefined-type">Random</span>();
                <span class="keyword">while</span> (<span class="predefined-constant">true</span>) {

                        <span class="keyword">try</span> {
                                producer.beginTransaction();
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Inicio de transacción ...</span><span class="delimiter">&quot;</span></span>);
                                <span class="comment">//HashMap&lt;TopicPartition,OffsetAndMetadata&gt; partitionsWithOffset = new HashMap&lt;&gt;();</span>
                                <span class="keyword">for</span> (<span class="type">int</span> j = <span class="integer">0</span>; j &lt; <span class="integer">5</span>; j++) {
                                        ProducerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC,
                                                        CITIES.get(random.nextInt(CITIES.size())), <span class="string"><span class="delimiter">&quot;</span><span class="content">String </span><span class="delimiter">&quot;</span></span> + i++);
                                        <span class="comment">// Garantía síncrona.</span>
                                        producer.send(record).get();
                                        <span class="comment">//System.out.println(&quot;Metadatos recibidos : &quot; + recordMetadata);</span>
                                        <span class="comment">//partitionsWithOffset.put(new TopicPartition(TOPIC, recordMetadata.partition()), new OffsetAndMetadata(recordMetadata.offset()));</span>
                                        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Record : </span><span class="delimiter">&quot;</span></span> + record.toString());

                                        <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
                                }
                                <span class="comment">//System.out.println(partitionsWithOffset);</span>
                                <span class="comment">//producer.sendOffsetsToTransaction(partitionsWithOffset, &quot;transactionalConsumer&quot;+ TransactionalProducer.TOPIC);</span>
                                producer.commitTransaction();
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Transacción confirmada!</span><span class="delimiter">&quot;</span></span>);
                        } <span class="keyword">catch</span> (ProducerFencedException e) {
                                producer.abortTransaction();
                        }
                }
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El productor está definido para que envie los mensajes de forma síncrona con garantía de entrega.</p>
</li>
<li>
<p>Definimos el id de transacción para que el consumidor pueda usarlo como control de lectura con garantía de entrega.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_consumidor">10.5.11.2. consumidor</h5>
<div class="ulist">
<ul>
<li>
<p>Para el consumidor, necesitamos definir el nivel de aislamiento para que lea solo mensajes confirmados.</p>
</li>
<li>
<p>Para hacer el seguimiento, obtendremos el último offset de cada partición para confirmar en el próximo commit cual es la próxima posición a leer</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.transactional</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.HashMap</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.OffsetAndMetadata</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.TopicPartition</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;
<span class="keyword">import</span> <span class="include">com.curso.kafka.util.TopicCreator</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">TransactionalConsumer</span> {

    <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);<span class="comment">//para cerrar al matar el proceso</span>

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
            <span class="annotation">@Override</span>
            <span class="directive">public</span> <span class="type">void</span> run() {
                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
                closed.set(<span class="predefined-constant">true</span>);
            }
        });
        TopicCreator.createTopics(PartitionProducer.BROKER_LIST, TransactionalProducer.TOPIC);
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);

        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">transactionalConsumer</span><span class="delimiter">&quot;</span></span>+ TransactionalProducer.TOPIC);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">read_committed</span><span class="delimiter">&quot;</span></span>);<span class="comment">// default &quot;read_uncommitted&quot;</span>
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">earliest</span><span class="delimiter">&quot;</span></span>);


        KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(TransactionalProducer.TOPIC));

        <span class="keyword">while</span> (!closed.get()) {
            ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofSeconds(<span class="integer">1</span>));
            <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                        record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
            <span class="predefined-type">HashMap</span>&lt;TopicPartition,OffsetAndMetadata&gt; partitionsWithOffset = <span class="keyword">new</span> <span class="predefined-type">HashMap</span>&lt;&gt;();
            <span class="keyword">for</span> (TopicPartition partition: records.partitions()) {
                    <span class="predefined-type">List</span>&lt;ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt;&gt; list = records.records(partition);
                    <span class="type">long</span> offset = list.get(list.size() -<span class="integer">1</span>).offset();
                    partitionsWithOffset.put(partition, <span class="keyword">new</span> OffsetAndMetadata(offset+<span class="integer">1</span>));
            }
            consumer.commitSync(partitionsWithOffset);
        }

        consumer.close();
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_prueba_de_ejecución_2">10.5.11.3. Prueba de ejecución</h5>
<div class="ulist">
<ul>
<li>
<p>Para ello ejecutaremos el productor y el consumidor (no crearemos particiones en el topic para ver como se mantiene la garantía de entrega y el orden)</p>
</li>
<li>
<p>Veremos como se crearán los mensajes de 5 en 5</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Inicio de transacción ...
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=barcelona, value=<span class="predefined-type">String</span> <span class="integer">2431</span>, timestamp=<span class="predefined-constant">null</span>)
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=burgos, value=<span class="predefined-type">String</span> <span class="integer">2432</span>, timestamp=<span class="predefined-constant">null</span>)
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=burgos, value=<span class="predefined-type">String</span> <span class="integer">2433</span>, timestamp=<span class="predefined-constant">null</span>)
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=burgos, value=<span class="predefined-type">String</span> <span class="integer">2434</span>, timestamp=<span class="predefined-constant">null</span>)
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=barcelona, value=<span class="predefined-type">String</span> <span class="integer">2435</span>, timestamp=<span class="predefined-constant">null</span>)
Transacción confirmada!</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras la confirmación, veremos como el consumidor lee solo los mensajes que se han confirmado, e ignora los demás hasta la próxima confirmación.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">partition =  <span class="integer">0</span>   offset =   <span class="integer">145</span>   key = barcelona timestamp = <span class="integer">1603884353438</span>  value =    <span class="predefined-type">String</span> <span class="integer">52</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">146</span>   key =  madrid timestamp = <span class="integer">1603884354442</span>  value =    <span class="predefined-type">String</span> <span class="integer">53</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">147</span>   key = barcelona timestamp = <span class="integer">1603884355446</span>  value =    <span class="predefined-type">String</span> <span class="integer">54</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">148</span>   key =  madrid timestamp = <span class="integer">1603884356450</span>  value =    <span class="predefined-type">String</span> <span class="integer">55</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">150</span>   key =  burgos timestamp = <span class="integer">1603884357456</span>  value =    <span class="predefined-type">String</span> <span class="integer">56</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">151</span>   key = barcelona timestamp = <span class="integer">1603884358462</span>  value =    <span class="predefined-type">String</span> <span class="integer">57</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">152</span>   key = barcelona timestamp = <span class="integer">1603884359466</span>  value =    <span class="predefined-type">String</span> <span class="integer">58</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">153</span>   key =  burgos timestamp = <span class="integer">1603884360470</span>  value =    <span class="predefined-type">String</span> <span class="integer">59</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">154</span>   key =  madrid timestamp = <span class="integer">1603884361479</span>  value =    <span class="predefined-type">String</span> <span class="integer">60</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">156</span>   key =  burgos timestamp = <span class="integer">1603884362486</span>  value =    <span class="predefined-type">String</span> <span class="integer">61</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos comprobar en el consumidor como cuando hay un commit desde el controlador, nos saltamos un offset de lectura.</p>
</li>
<li>
<p>Si paramos y levantamos el consumidor, veremos como reinicia en la última transacción no confirmada.</p>
</li>
<li>
<p>Si paramos y levantamos el productor, veremos como aquellos mensajes que no se confirmaron no se podrán leer nunca por parte del consumidor, y el productor generará nuevas transacciones que el consumidor podrá leer.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Fin del laboratorio</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_esquemas_en_kafka">11. Esquemas en Kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>La serialización es una forma de representar los datos en memoria como conjuntos de bytes para transferencia o almacenamiento en disco</p>
</li>
<li>
<p>La deserialización permite realizar la operación inversa, convirtiendo los bytes en objetos</p>
</li>
<li>
<p>Kafka posee su propia clase de serialización, como hemos visto anteriormente</p>
<div class="ulist">
<ul>
<li>
<p>org.apache.kafka.common.serialization</p>
</li>
</ul>
</div>
</li>
<li>
<p>Sin embargo, el tratamiento de datos de forma simple no es suficiente. La serialización en formatos de tipo texto es poco eficinet:</p>
<div class="ulist">
<ul>
<li>
<p>Almacenamiento no eficiente</p>
</li>
<li>
<p>Los datos de tipo no-texto deben pasarse a cadenas</p>
</li>
<li>
<p>Es ineficiente transformar datos de texto a binarios y viceversa</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_tipos_de_serialización_en_kafka">11.1. Tipos de serialización en kafka</h3>
<div class="ulist">
<ul>
<li>
<p>Existen cuatro tipos de formatos de serialización comunes en Apache kafka:</p>
<div class="ulist">
<ul>
<li>
<p>Avro</p>
<div class="ulist">
<ul>
<li>
<p>Es un formato binario, lo que beneficia en tamaño almacenado la mayoría de las veces</p>
</li>
<li>
<p>No es facilmente entendible, ya que se almacena en binario</p>
</li>
<li>
<p>Posee un esquema conocido.</p>
</li>
<li>
<p>Soporta schema registry y está muy integrado con kafka</p>
</li>
</ul>
</div>
</li>
<li>
<p>JSON</p>
<div class="ulist">
<ul>
<li>
<p>No almacena en formato binario</p>
</li>
<li>
<p>Es fácil de interpretar</p>
</li>
<li>
<p>No posee un esquema, aunque en los nuevos estándares esto se solucionará</p>
</li>
<li>
<p>Sencillo, sin curva de aprendizaje y muy común</p>
</li>
<li>
<p>No está indicado para alto rendimiento.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Protobuf</p>
<div class="ulist">
<ul>
<li>
<p>Almacena en formato binario</p>
</li>
<li>
<p>No es fácil de interpretar al ser binario</p>
</li>
<li>
<p>Posee esquema</p>
</li>
<li>
<p>Google Protobuf es altamente eficiente.</p>
</li>
<li>
<p>Uso de gRPC</p>
</li>
</ul>
</div>
</li>
<li>
<p>Thrift</p>
<div class="ulist">
<ul>
<li>
<p>Almacena en formato binario</p>
</li>
<li>
<p>No es fácil de interpretar al ser binario</p>
</li>
<li>
<p>Posee esquema</p>
</li>
<li>
<p>Usado por twitter y en las primeras versiones de Apache Cassandra</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Todos ellos son agnósticos a la plataforma y el lenguaje.</p>
</li>
<li>
<p>Sin embargo, aquellos que usan datos binarios permiten compactar los datos, usan esquemas y permiten un alto rendimiento.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_ejemplos_esquemas_idl">11.1.1. Ejemplos Esquemas-IDL</h4>
<div class="listingblock">
<div class="title">Ejemplo JSON - schema.json</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo Proto - schema.proto</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="protobuf">syntax = &quot;proto3&quot;
message UserCommand {
    string command = 1
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo avro - schema.avsc</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="avro">{
    &quot;type&quot;:&quot;string&quot;,
    &quot;name&quot;:&quot;command&quot;
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo thrift schema.thrift</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="thrift">struct UserCommand {
    1: string command
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Estos esquemas permiten ceñirnos a una estructura concreta de datos.</p>
</li>
<li>
<p>Definimos un grano fino de estructuras de datos.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_avro">11.2. Avro</h3>
<div class="ulist">
<ul>
<li>
<p>Se trata de un sistema que permite la serialización de datos, no es solo un serializador/deserializador</p>
</li>
<li>
<p>Creado por <em>Doug Cutting</em> , el creador de Hadoop</p>
</li>
<li>
<p>Pemite:</p>
<div class="ulist">
<ul>
<li>
<p>Posee estructuras de datos complejas y ricas</p>
</li>
<li>
<p>Uso de datos binarios compactados, ocupando menos espacio en disco y uso menor de red</p>
</li>
<li>
<p>Permite el uso de contenedores, es decir, el fichero contenedor puede almacenar el esquema en la cabecera y el objeto en el resto del mensaje.</p>
</li>
<li>
<p>Permite comunicación RPC, puede definir su propio protocolo.</p>
</li>
<li>
<p>Serialización de datos</p>
</li>
<li>
<p>Los datos se definen con un esquema</p>
</li>
<li>
<p>Soportado por diversos lenguajes de programación</p>
</li>
<li>
<p>Soporta generadores de código para los tipos de datos</p>
</li>
<li>
<p>La comprobación de tipos se realiza en tiempo de escritura.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_esquemas_de_avro">11.3. Esquemas de Avro</h3>
<div class="ulist">
<ul>
<li>
<p>Los esquemas definen la estructura de datos.</p>
</li>
<li>
<p>Se representan en formato JSON</p>
</li>
<li>
<p>Posee tres formas de creación de records</p>
<div class="ulist">
<ul>
<li>
<p><strong>Generic</strong> : Mapeo de cada campo al campo del objeto</p>
</li>
<li>
<p><strong>Reflection</strong> : Generación de esquema a partir de una clase java</p>
</li>
<li>
<p><strong>Específica</strong> : Generación de una clase java para nuestro esquema</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_tipos_de_datos">11.4. Tipos de datos</h3>
<div class="ulist">
<ul>
<li>
<p>Avro soporta dos tipos de datos, primitivos o complejos:</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-esquema-01.png" alt="kafka esquema 01" width="600">
</div>
<div class="title">Figure 2. Tipos de datos simples</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-esquema-02.png" alt="kafka esquema 02" width="600">
</div>
<div class="title">Figure 3. Tipos de datos complejos</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos destacar el tipo de datos fixed que permite almacenar una cadena fija de caracteres, lo que viene muy bien para almacenar hashes en avro.</p>
</li>
<li>
<p>Más información de los tipos de datos en:</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://avro.apache.org/docs/1.10.0/spec.html" class="bare">https://avro.apache.org/docs/1.10.0/spec.html</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_compactación">11.4.1. Compactación</h4>
<div class="ulist">
<ul>
<li>
<p>Avro utiliza un sistema de compactación para cada tipo de datos primitivo.</p>
</li>
<li>
<p>Para ello usa los siguientes criterios:</p>
<div class="ulist">
<ul>
<li>
<p>null: No almacena datos</p>
</li>
<li>
<p>boolean: bit 0 o 1</p>
</li>
<li>
<p>int/long: Uso de variable-length zig-zag encoding. Lo que le permite no distinguir entre int y long y no reservar ese espacio concreto para cada uno.</p>
</li>
<li>
<p>float/double: Almacenan 32bit IEEE 754 para float y 64bit IEEE 754 para double</p>
</li>
<li>
<p>Binary: En la cabecera almacena el tamaño como long con zig-zag encoding, y luego los bytes.</p>
</li>
<li>
<p>String: En la cabecera almacena el tamaño como long con zig-zag encoding, y luego almacena el texto en una cadena codificada en UTF-8</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_integración">11.4.2. Integración</h4>
<div class="ulist">
<ul>
<li>
<p>Este es un ejemplo de un esquema en Avro.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de esquema en Avro:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">model</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">SimpleCard</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">fields</span><span class="delimiter">&quot;</span></span>: [
        {
            <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">suit</span><span class="delimiter">&quot;</span></span>,
            <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>,
            <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The suit of the card</span><span class="delimiter">&quot;</span></span>
        }, {
            <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">card</span><span class="delimiter">&quot;</span></span>,
            <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>,
            <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The card number</span><span class="delimiter">&quot;</span></span>
        }
    ]
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por defecto, los esquemas se almacenan con extensión <strong>.avsc</strong> en el directorio src/main/avro</p>
</li>
<li>
<p>El namespace es el paquete java</p>
</li>
<li>
<p>Docs permite indicar comentarios del campo</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo con un array y un map</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">cards_list</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">array</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">items</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>
    },
    <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The cards played</span><span class="delimiter">&quot;</span></span>
},{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">cards_map</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">map</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">values</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>
    },
    <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The cards played</span><span class="delimiter">&quot;</span></span>
},{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">suit_type</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">enum</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">Suit</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">symbols</span><span class="delimiter">&quot;</span></span> : [<span class="string"><span class="delimiter">&quot;</span><span class="content">SPADES</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">HEARTS</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">DIAMONDS</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">CLUBS</span><span class="delimiter">&quot;</span></span>]
    },
    <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The suit of the card</span><span class="delimiter">&quot;</span></span>
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los esquemas de Avro se pueden actualizar.</p>
</li>
<li>
<p>Permite también la compatibilidad mediante esquemas</p>
<div class="ulist">
<ul>
<li>
<p>Retrocompatibilidad:</p>
<div class="ulist">
<ul>
<li>
<p>El código con una nueva versión de esquema puede leer la versión vieja</p>
</li>
<li>
<p>Los campos no existentes los deja con valores por defecto</p>
</li>
</ul>
</div>
</li>
<li>
<p>Compatibilidad a futuro</p>
<div class="ulist">
<ul>
<li>
<p>Si el código recibe nuevos esquemas, los campos nuevos son ingnorados</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_esquemas_en_avro">11.5. Esquemas en Avro</h3>
<div class="ulist">
<ul>
<li>
<p>Si lo que queremos es un tipo primitivo, el esquema que habría que generar es el siguiente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como normalmente no es el caso, lo común es que queramos tipos complejos.</p>
</li>
<li>
<p>Para ello generamos un esquema similar al siguiente</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">Esquema</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">com.curso.kafkaapp.model.avro</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="string"><span class="delimiter">&quot;</span><span class="content">fields: [
        {
            </span><span class="delimiter">&quot;</span></span><span class="error">n</span><span class="error">a</span><span class="error">m</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">E</span><span class="error">s</span><span class="error">q</span><span class="error">u</span><span class="error">e</span><span class="error">m</span><span class="error">a</span><span class="error">C</span><span class="error">o</span><span class="error">m</span><span class="error">p</span><span class="error">l</span><span class="error">e</span><span class="error">j</span><span class="error">o</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">t</span><span class="error">y</span><span class="error">p</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">r</span><span class="error">e</span><span class="error">c</span><span class="error">o</span><span class="error">r</span><span class="error">d</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">f</span><span class="error">i</span><span class="error">e</span><span class="error">l</span><span class="error">d</span><span class="error">s</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: [ ... ]
        },
        ...
    ]
}</span></span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La representación del <strong>name</strong> será el nombre de la clase</p>
</li>
<li>
<p>El <strong>namespace</strong> representa el paquete donde se creará</p>
</li>
<li>
<p>El <strong>type</strong> indica el tipo de dato a almacenar, en este caso record, que es un tipo complejo.</p>
</li>
<li>
<p>Los <strong>fields</strong> indican los campos, que pueden ser simples o complejos como en el ejemplo.</p>
</li>
<li>
<p>Algunos tipos de datos permiten solucionar problemas básicos como tipos de datos cerrados (Colores, dias de la semana, meses del año, etc)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">Esquema</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">com.curso.kafkaapp.model.avro</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="string"><span class="delimiter">&quot;</span><span class="content">fields: [
        {
            </span><span class="delimiter">&quot;</span></span><span class="error">n</span><span class="error">a</span><span class="error">m</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">d</span><span class="error">i</span><span class="error">a</span><span class="error">s</span><span class="error">D</span><span class="error">e</span><span class="error">L</span><span class="error">a</span><span class="error">S</span><span class="error">e</span><span class="error">m</span><span class="error">a</span><span class="error">n</span><span class="error">a</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">t</span><span class="error">y</span><span class="error">p</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">e</span><span class="error">n</span><span class="error">u</span><span class="error">m</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">s</span><span class="error">y</span><span class="error">m</span><span class="error">b</span><span class="error">o</span><span class="error">l</span><span class="error">s</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: [</span><span class="delimiter">&quot;</span></span><span class="error">L</span><span class="error">U</span><span class="error">N</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">M</span><span class="error">A</span><span class="error">R</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">M</span><span class="error">I</span><span class="error">E</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">J</span><span class="error">U</span><span class="error">E</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">V</span><span class="error">I</span><span class="error">E</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">S</span><span class="error">A</span><span class="error">B</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">D</span><span class="error">O</span><span class="error">M</span><span class="string"><span class="delimiter">&quot;</span><span class="content">]
        },
        ...
    ]
}</span></span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Estos campos declarados son obligatorios, sin embargo, es necesario crear campos opcionales, para ello, declaramos el doble tipo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">Esquema</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">com.curso.kafkaapp.model.avro</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="string"><span class="delimiter">&quot;</span><span class="content">fields: [
        {
            </span><span class="delimiter">&quot;</span></span><span class="error">n</span><span class="error">a</span><span class="error">m</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">c</span><span class="error">a</span><span class="error">m</span><span class="error">p</span><span class="error">o</span><span class="error">O</span><span class="error">p</span><span class="error">c</span><span class="error">i</span><span class="error">o</span><span class="error">n</span><span class="error">a</span><span class="error">l</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">t</span><span class="error">y</span><span class="error">p</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: [</span><span class="delimiter">&quot;</span></span><span class="value">null</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">s</span><span class="error">t</span><span class="error">r</span><span class="error">i</span><span class="error">n</span><span class="error">g</span><span class="string"><span class="delimiter">&quot;</span><span class="content">]
        },
        ...
    ]
}</span></span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este caso, el campo puede ser o no declarados</p>
</li>
<li>
<p>Si queremos por ejemplo, crear un campo con un tamaño concreto para un campo, como un hash md5, usamos fixed</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">Esquema</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">com.curso.kafkaapp.model.avro</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="string"><span class="delimiter">&quot;</span><span class="content">fields: [
        {
            </span><span class="delimiter">&quot;</span></span><span class="error">n</span><span class="error">a</span><span class="error">m</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">c</span><span class="error">a</span><span class="error">m</span><span class="error">p</span><span class="error">o</span><span class="error">F</span><span class="error">i</span><span class="error">x</span><span class="error">e</span><span class="error">d</span><span class="error">P</span><span class="error">a</span><span class="error">r</span><span class="error">a</span><span class="error">M</span><span class="error">d</span><span class="integer">5</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">t</span><span class="error">y</span><span class="error">p</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: </span><span class="delimiter">&quot;</span></span><span class="error">f</span><span class="error">i</span><span class="error">x</span><span class="error">e</span><span class="error">d</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">s</span><span class="error">i</span><span class="error">z</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: 16
        },
        ...
    ]
}</span></span></code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_schema_registry">12. Schema Registry</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Si analizamos los anteriores laboratorios, podemos ver como tenemos un acoplamiento entre el productor y el consumidor.</p>
</li>
<li>
<p>Este acomplamiento en ecosistemas más complejos no es adecuado, lo que impide un correcto desacomplamiento.</p>
</li>
<li>
<p>Para solucionar ese problema tenemos el <strong>Schema Registry</strong></p>
</li>
<li>
<p>Este registro permite:</p>
<div class="ulist">
<ul>
<li>
<p>Reforzar los contratos</p>
</li>
<li>
<p>Permite gestionar la evolución de los contratos.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Este producto no es totalmente público ya que pertenece a Confluent.</p>
</li>
<li>
<p>La licencia de uso indica que se puede acceder al código fuente, modificar y distribuir mientras no se haga competencia de los servicios SaaS que ofrece Confluent.</p>
</li>
<li>
<p>Todo esto pasa de forma transparente. Lo único que hay que hacer es publicar el serializador y deserializador usando:</p>
<div class="ulist">
<ul>
<li>
<p>KakaAvroSerializer</p>
</li>
<li>
<p>KafkaAvroDeserializer</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por otro lado, el registro necesita almacenar la información en un topic como persistencia.</p>
</li>
<li>
<p>El Schema Registry tiene un productor que envia los esquemas y un consumidor para obtener los que tenía previamente.</p>
</li>
<li>
<p>Se llama __schemas</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_integración_de_datos">12.1. Integración de datos</h3>
<div class="ulist">
<ul>
<li>
<p>Para integrar los datos, avro usa un esquema.</p>
</li>
<li>
<p>En Kafka debemos pensar que cientos de productores se conectan a kafka con un esquema propio y cientos de consumidores lo usan para deserializar los datos.</p>
</li>
<li>
<p>En resumen, al menos un esquema es usado por un productor y un consumidor.</p>
</li>
<li>
<p>Para solucionar el problema, usamos un repositorio de esquemas centralizado.</p>
</li>
<li>
<p>Propietario de Confluent</p>
</li>
<li>
<p>Provee de un sistema centralizado de gestión de esquemas</p>
</li>
<li>
<p>Posee una interfaz RESTful para almacenamiento y obtención de esquemas Avro</p>
</li>
<li>
<p>Comprobación de esquemas y lanzamiento de excepciones si los datos no cumplen el esquema</p>
</li>
<li>
<p>Permite la mejora de los esquemas según su configuración de compatibilidad.</p>
</li>
<li>
<p>Permite evitar mandar el esquema en cada mensaje</p>
</li>
<li>
<p>El registro almacena la información en un topic de Kafka</p>
</li>
<li>
<p>Es posible acceder al registro via API Rest o API Java.</p>
</li>
<li>
<p>Posee herramientas de línea de comandos</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_flujo_de_trabajo">12.2. Flujo de trabajo</h3>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-esquema-03.png" alt="kafka esquema 03" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los mensajes clave y valor se serializan de forma independiente</p>
</li>
<li>
<p>Los productores serializan los datos y usan preferentemente el ID de esquema</p>
</li>
<li>
<p>Los consumidores usan el id de esquema para deserializar los datos</p>
</li>
<li>
<p>Los esquemas son cacheados en productores y consumidores y solo mandan el id del esquema</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_ejemplos_2">12.3. Ejemplos</h3>
<div class="ulist">
<ul>
<li>
<p>Soporte de los clientes para el <em>Schema Registry</em></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(KafkaAvroSerializerConfig.SCHEMA_REGISTRY_URL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">http://localhost:8081</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Productor Avro</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">broker1:9092</span><span class="delimiter">&quot;</span></span>);
<span class="comment">// Configuración de clases de serialización</span>
props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
    io.confluent.kafka.serializers.KafkaAvroSerializer.class);
props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
    io.confluent.kafka.serializers.KafkaAvroSerializer.class);
<span class="comment">// Ruta al Schema Registry</span>
props.put(KafkaAvroSerializerConfig.SCHEMA_REGISTRY_URL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">http://localhost:8081</span><span class="delimiter">&quot;</span></span>);
<span class="comment">// Creando productor</span>
KafkaProducer&lt;<span class="predefined-type">Object</span>, <span class="predefined-type">Object</span>&gt; avroProducer = <span class="keyword">new</span> KafkaProducer&lt;<span class="predefined-type">Object</span>, <span class="predefined-type">Object</span>&gt;(props);
<span class="comment">// Creando objetos Avro</span>
CardSuit suit = <span class="keyword">new</span> CardSuit(<span class="string"><span class="delimiter">&quot;</span><span class="content">spades</span><span class="delimiter">&quot;</span></span>);
SimpleCard card = <span class="keyword">new</span> SimpleCard(<span class="string"><span class="delimiter">&quot;</span><span class="content">spades</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">ace</span><span class="delimiter">&quot;</span></span>);
<span class="comment">// Creando el ProducerRecord con objetos Avro</span>
ProducerRecord&lt;<span class="predefined-type">Object</span>, <span class="predefined-type">Object</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;<span class="predefined-type">Object</span>, <span class="predefined-type">Object</span>&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">my_avro_topic</span><span class="delimiter">&quot;</span></span>, suit, card);
avroProducer.send(record);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Consumidor Avro</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">CardConsumer</span> {
    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args){
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">broker1:9092</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">testgroup</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,<span class="string"><span class="delimiter">&quot;</span><span class="content">io.confluent.kafka.serializers.KafkaAvroDeserializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,<span class="string"><span class="delimiter">&quot;</span><span class="content">io.confluent.kafka.serializers.KafkaAvroDeserializer</span><span class="delimiter">&quot;</span></span>);
        props.put(KafkaAvroDeserializerConfig.SCHEMA_REGISTRY_URL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">http://localhost:8081</span><span class="delimiter">&quot;</span></span>);
                props.put(KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
        KafkaConsumer&lt;CardSuit, SimpleCard&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(<span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">my_avro_topic</span><span class="delimiter">&quot;</span></span>));
        <span class="keyword">while</span>(<span class="predefined-constant">true</span>){
            ConsumerRecords&lt;CardSuit, SimpleCard&gt; records = consumer.poll(<span class="integer">100</span>);
            <span class="keyword">for</span> (ConsumerRecord&lt;CardSuit, SimpleCard&gt; record : records) {
                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">offset = %d, key = %s, value = %s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>, record.offset(), record.key().getSuit(), record.value().getCard());
            }
        }
    }
}</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_estrategias_de_nombres">12.4. Estrategias de nombres.</h3>
<div class="ulist">
<ul>
<li>
<p>Cuando un productor almacena un nuevo esquema, por defecto utiliza la estrategia de indicar en que campo disponible del topic se puede almacenar.</p>
</li>
<li>
<p>Entre ellos está:</p>
<div class="ulist">
<ul>
<li>
<p>key</p>
</li>
<li>
<p>value</p>
</li>
</ul>
</div>
</li>
<li>
<p>En el caso de que se almacene en el value, el nombre sería:</p>
<div class="ulist">
<ul>
<li>
<p>&lt;topic&gt;-value</p>
</li>
</ul>
</div>
</li>
<li>
<p>Existen tres tipos:</p>
<div class="ulist">
<ul>
<li>
<p><strong>Topic Name Strategy</strong></p>
<div class="ulist">
<ul>
<li>
<p>&lt;topic_name&gt;-key</p>
</li>
<li>
<p>&lt;topic_name&gt;-value</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Record Name Strategy</strong></p>
<div class="ulist">
<ul>
<li>
<p>Se utiliza el nombre completo del esquema (Fully Qualified Schema Name), namespace+name</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Topic Record Name Strategy</strong></p>
<div class="ulist">
<ul>
<li>
<p>Es una mezcla de los dos, donde se usa el &lt;topic_name&gt; seguido del nombre completo del esquema</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Por defecto se usa el Topic Name Strategy</p>
</li>
<li>
<p>Sin embargo, para casos de un solo topic, podemos usar también el <strong>Record Name Strategy</strong></p>
</li>
<li>
<p>En el caso de que tengamos distintos tipos de records, podemos usar Record Name Strategy o Topic Record Name Stategy, la cual es más compleja de usar que las demás.</p>
</li>
<li>
<p>En este último caso, no se podría usar el Topic Name Strategy</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kafka_streams_api">13. Kafka Streams API</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Permite transformar y enriquecer los datos</p>
<div class="ulist">
<ul>
<li>
<p>Soporte de procesado de streams con latencias de milisegundos sin estado.</p>
</li>
<li>
<p>Soporte de procesado de streams por ventana con estado.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Posee tolerancia a fallos y soporte de procesamiento distribuido</p>
</li>
<li>
<p>Posee su propio DSL</p>
<div class="ulist">
<ul>
<li>
<p>Con operaciones comunes como map, flatMap, count, etc.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Existen implementaciones en diversos lenguajes.</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_características">13.1. Características</h3>
<div class="ulist">
<ul>
<li>
<p>Posee capacidades de streaming</p>
</li>
<li>
<p>No requiere su propio cluster, se trata de una librería</p>
</li>
<li>
<p>Puede ejecutarse en una o múltiples máquinas</p>
</li>
<li>
<p>Se trata de una implementación concreta de Productor/Consumidor</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_streams">13.2. Streams</h3>
<div class="ulist">
<ul>
<li>
<p>Un stream es un flujo de registros contínuo</p>
<div class="ulist">
<ul>
<li>
<p>No pedimos registros, sino que nos llegan</p>
</li>
</ul>
</div>
</li>
<li>
<p>Los registros son de tipo clave&#8594;valor</p>
</li>
<li>
<p>Un procesador de streams transforma los datos en streams</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_kstreams_y_ktables">13.3. KStreams y KTables</h3>
<div class="sect3">
<h4 id="_kstream">13.3.1. KStream</h4>
<div class="ulist">
<ul>
<li>
<p>Un KStream es una abstracción de un stream de record</p>
</li>
<li>
<p>Se pueden interpretar como inserts continuos.</p>
</li>
<li>
<p>Ningun record reemplaza el anterior.</p>
</li>
<li>
<p>Puede ser util para operaciones de tipo serverLog.</p>
<div class="ulist">
<ul>
<li>
<p>Cada record representa un trozo de datos autocontenido</p>
</li>
<li>
<p>Ejemplo, (1,1) (1,2) &#8594; Como KStream su resultado podría ser 3 para id 1, ya que se tienen en cuenta todos los datos.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_ktable">13.3.2. KTable</h4>
<div class="ulist">
<ul>
<li>
<p>Un KTable es una abstracción de un stream changelog.</p>
</li>
<li>
<p>Se puede interpretar como un Upsert. (Si no existe, es Insert, si existe es Update)</p>
<div class="ulist">
<ul>
<li>
<p>Cada record representa una actualización</p>
</li>
<li>
<p>Ejemplo, (1,1) (1,2) &#8594; Como KTable, se trata de una actualización del primero, luego para el id 1, su valor es el último, 2.</p>
</li>
<li>
<p>Para KTables es lógico activar el <em>Log Compaction</em> en el topic asociado, ya que solo importa el último valor por caada key.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_gobalktable">13.3.3. GobalKTable</h4>
<div class="ulist">
<ul>
<li>
<p>Representa una abstracción de un stream de changelog.</p>
</li>
<li>
<p>Permite compartir la información del global KTable con hilos.</p>
</li>
<li>
<p>Si usaramos KTable, cada instancia tendría su propio KTable.</p>
</li>
<li>
<p>Con GlobalKTable garantizamos que la información es compartida por todos los hilos.</p>
</li>
<li>
<p>Muy util para uso de joins, ya que podemos buscar tanto por claves como por valores, y además no tiene porqué estar co-particionados.</p>
</li>
<li>
<p>Incrementa el consumo de almacenamiento local comparado con el particionado.</p>
</li>
<li>
<p>Incrementa el consumo de red y de los brokers de kafka, ya que lee el topic completo.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ventanas_windows">13.4. Ventanas (Windows)</h3>
<div class="ulist">
<ul>
<li>
<p>Hay que tener en cuenta que el API de streams de Kafka se basa en ventanes de tiempo.</p>
</li>
<li>
<p>Los datos se dividen en buckets temporales</p>
</li>
<li>
<p>Podemos realizar agregaciones en lo records, como sum o count.</p>
</li>
<li>
<p>Podemos realizar join, merge para distintos sources.</p>
</li>
<li>
<p>Existen distintos tipos de windows:</p>
<div class="ulist">
<ul>
<li>
<p>Tumbling: Es de tamaño fijo, no se solapan las ventanas de tiempo, no genera espacios entre ventanas.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">TimeWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)).advanceBy(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hopping: Tamaño fijo, Las ventanas se solapan</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">TimeWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)).advanceBy(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">1</span>));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Sliding: Tamaño fijo, ventanas solapadas que trabaja con diferencias entre los timestamps de los records. Solo se usan en operaciones de tipo Join, por medio de la clase JoinWindows.</p>
</li>
<li>
<p>Session: Tamaño dinámico. Sin solapamiento, ventana gestionada por datos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">SessionWindows.with(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>));</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_transformaciones">13.5. Transformaciones</h3>
<div class="ulist">
<ul>
<li>
<p>Los datos pueden transformarse usando distintos operadores</p>
</li>
<li>
<p>Algunos operadores devuelven un objeto KStream, como filter o map</p>
</li>
<li>
<p>Otros devuelven KTables, como agregaciones</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_transformaciones_sin_estado">13.5.1. Transformaciones sin estado</h4>
<div class="ulist">
<ul>
<li>
<p><strong>branch</strong>: Permite dividir un KStream en varios KStreams según un predicado definido. Solo para KStreams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt;<span class="type">[]</span> branches = stream.branch(
    (key, value) -&gt; key.equals(<span class="string"><span class="delimiter">&quot;</span><span class="content">MADRID</span><span class="delimiter">&quot;</span></span>), <span class="comment">// KStream con los datos de clave madrid</span>
    (key, value) -&gt; key.equals(<span class="string"><span class="delimiter">&quot;</span><span class="content">BURGOS</span><span class="delimiter">&quot;</span></span>), <span class="comment">// KStream con los datos de burgos</span>
    (key, value) -&gt; <span class="predefined-constant">true</span>                <span class="comment">// KStream con todo lo demás</span>
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>filter</strong>: Creación de un KStream con records que cumplan criterios concretos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; masDe30 = stream.filter((key, value) -&gt; value.getDatos().getTemp() &gt; <span class="integer">30</span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Todos los datos con temperatura mayor de 30º</p>
</li>
<li>
<p><strong>inverseFilter</strong>: Función booleana que rechaza todos los datos que devuelvan true</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; menosOIgualA30 = stream.filterNot((key, value) -&gt; value.getDatos().getTemp() &gt; <span class="integer">30</span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>flatMap</strong>:  Creación de un KStream transformando cada elemento en 0, 1 o más elementos en el nuevo stream. Se permite la modificación de las claves y valores incluidos sus tipos de datos. Solo para KStreams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Integer</span>&gt; transformed = stream.flatMap(
    (key, value) -&gt; {
      <span class="predefined-type">List</span>&lt;KeyValue&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Integer</span>&gt;&gt; result = <span class="keyword">new</span> <span class="predefined-type">LinkedList</span>&lt;&gt;();
      result.add(KeyValue.pair(value.getDatos().getName()+<span class="string"><span class="delimiter">&quot;</span><span class="content">Max</span><span class="delimiter">&quot;</span></span>, value.getDatos().getTempMax()));
      result.add(KeyValue.pair(value.getDatos().getName()+<span class="string"><span class="delimiter">&quot;</span><span class="content">Min</span><span class="delimiter">&quot;</span></span>), value.getDatos().getTempMin()));
      <span class="keyword">return</span> result;
    }
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>flatMapValues</strong>:  Creación de un KStream transformando cada valor de cada elemento en 0 o 1 elemento distintos en el stream nuevo. Solo modifica el valor, manteniendo la clave. Solo para KStreams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">datos.flatMapValues(value -&gt; value.getDatos());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Foreach</strong>: Permite una operación sin estado en cada record. Es una operación final, es decir, no devuelve un kstream o un ktable.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">stream.foreach((key, value) -&gt; <span class="predefined-type">System</span>.out.println(key + <span class="string"><span class="delimiter">&quot;</span><span class="content"> =&gt; temp: </span><span class="delimiter">&quot;</span></span> + value.getDatos().getTemp()));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>GroupByKey</strong>: Agrupa records por claves (Para KStreams y KGroupedStreams)</p>
<div class="ulist">
<ul>
<li>
<p>Es un prerrequisito para agregaciones. Permite reparticionar si se marca explicitamente para ello.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KGroupedStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; streamGrouped = stream.groupByKey();
KGroupedStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; groupedStream = stream.groupByKey(
    Serialized.with(
      Serdes.String(),
      Serdes.Float())
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>GroupBy</strong>: Permite agrupar records por una nueva clave que puede ser de un tipo distinto.</p>
<div class="ulist">
<ul>
<li>
<p>Al agrupar una tabla, se debe especificar el valor y el tipo</p>
</li>
<li>
<p>Equivalente a selectKey().groupByKey()</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KGroupedStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; groupedStream = stream.groupBy(
    (key, value) -&gt; value,
    Serialized.with(
      Serdes.String(),
      Serdes.Float())
  );

KGroupedTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Float</span>&gt; groupedTable = table.groupBy(
    (key, value) -&gt; KeyValue.pair(value, value.getDatos().getTemp()),
    Serialized.with(
      Serdes.String(),
      Serdes.Float())
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>map</strong>: Creación de un KStream transformando cada elemento en otro distinto en el nuevo stream</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; transformed = stream.map(
    (key, value) -&gt; KeyValue.pair(value.getName().toUpperCase(), value.getDatos().getTemp()));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>mapValues</strong>:  Creación de un KStream transformando el valor de cada elemento en otro elemento distinto, pero solo modifica el valor</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>stream.mapValues(value &#8594; value.getDatos());</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Peek</strong>: Realiza una acción sin estado por cada record y devuelve un stream intacto. Similar a forEachm pero no finaliza.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; noModificado = stream.peek((key, value) -&gt; <span class="predefined-type">System</span>.out.println(key + <span class="string"><span class="delimiter">&quot;</span><span class="content"> =&gt; temp: </span><span class="delimiter">&quot;</span></span> + value.getDatos().getTemp()));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Print</strong>: Operación terminal. Permite mostrar los records por la salida estándar. Útil para desarrollo.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">stream.print(Printed.toFile(<span class="string"><span class="delimiter">&quot;</span><span class="content">salida.txt</span><span class="delimiter">&quot;</span></span>).withLabel(<span class="string"><span class="delimiter">&quot;</span><span class="content">a-topic-nuevo</span><span class="delimiter">&quot;</span></span>));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>SelectKey: Asigna una nueva key</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">stream.selectKey((key, value) -&gt; value.getName())</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo de Stateless Processing</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">SimpleStreamsExample</span> {

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) throwsException {
        <span class="predefined-type">Properties</span> streamsConfiguration = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        <span class="comment">// Aplicación con nombre único obligatorio para el cluster de Kafka</span>
        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">ejemplo-sencillo</span><span class="delimiter">&quot;</span></span>);
        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">broker1:9092</span><span class="delimiter">&quot;</span></span>);
        streamsConfiguration.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">earliest</span><span class="delimiter">&quot;</span></span>);
        <span class="comment">// Serializadores y deserializadores</span>
        streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.ByteArray().getClass());
        streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        <span class="comment">// Transformación de datos y ejecución</span>
        StreamsBuilder builder = <span class="keyword">new</span> StreamsBuilder();

        <span class="comment">// KStream desde el topic mi-topic-a-stream</span>
        KStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; textLines = builder.stream(<span class="string"><span class="delimiter">&quot;</span><span class="content">mi-topic-a-stream</span><span class="delimiter">&quot;</span></span>);

        <span class="comment">// UpperCase del KStream</span>
        KStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; uppercasedWithMapValues = textLines.mapValues(<span class="predefined-type">String</span>::toUpperCase);

        <span class="comment">// envio a un nuevo topic &quot;mi-stream-a-topic&quot;</span>
        uppercasedWithMapValues.to(<span class="string"><span class="delimiter">&quot;</span><span class="content">mi-stream-a-topic</span><span class="delimiter">&quot;</span></span>);

        <span class="comment">// Inicio de la aplicación</span>
        KafkaStreams streams = <span class="keyword">new</span> KafkaStreams(builder.build(), streamsConfiguration);
        streams.start();

        <span class="comment">//Apagado suave</span>
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(streams::close));
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_transformaciones_con_estado">13.5.2. Transformaciones con estado</h4>
<div class="ulist">
<ul>
<li>
<p>Las transformaciones con estado dependen del estado para procesar entradas y producir saldas.</p>
</li>
<li>
<p>Debe poseer un state store asociado al procesador de stream.</p>
</li>
<li>
<p>Estos almacenes permiten ser tolerantes a fallos</p>
</li>
<li>
<p>Las transformaciones disponibles son:</p>
<div class="ulist">
<ul>
<li>
<p>agregaciones</p>
</li>
<li>
<p>joins</p>
</li>
<li>
<p>windows</p>
</li>
<li>
<p>transformaciones personalizadas</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para saber como se pueden utilizar cada uno de los objetos, podemos ver el siguiente diagrama</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-streams-01.png" alt="kafka streams 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>aggregate</strong>: Permite agregar los valores de records por medio de la clave agrupada. Es una generalización del Reduce y permite tener diferentes tipos a los valores de entrada.</p>
<div class="ulist">
<ul>
<li>
<p>Se usa con KGroupedStream y KGroupedTable devolviendo un KTable</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">Long</span>&gt; streamAgregado = groupedStream.aggregate(
    () -&gt; <span class="integer">0L</span>,
    (aggKey, newValue, aggValue) -&gt; aggValue + newValue.length(),
    Materialized.as(<span class="string"><span class="delimiter">&quot;</span><span class="content">aggregated-stream-store</span><span class="delimiter">&quot;</span></span>)
        .withValueSerde(Serdes.Long());

KTable&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">Long</span>&gt; TablaAgregada = groupedTable.aggregate(
    () -&gt; <span class="integer">0L</span>,
    (aggKey, newValue, aggValue) -&gt; aggValue + newValue.length(),
    (aggKey, oldValue, aggValue) -&gt; aggValue - oldValue.length(),
    Materialized.as(<span class="string"><span class="delimiter">&quot;</span><span class="content">aggregated-table-store</span><span class="delimiter">&quot;</span></span>)
        .withValueSerde(Serdes.Long())</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Las claves nulas son ignoradas</p>
</li>
<li>
<p>Al recibir el primer record, se inicializa el valor de agregación en el caso de KStreams, en KTables se ejecuta luego la función</p>
</li>
<li>
<p>Al recibir un record con valor, se llama a la función lambda declarada.</p>
<div class="ulist">
<ul>
<li>
<p><strong>Agregación (Windowed)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Agrega los valores de los records por window, por la clave de grupo.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; StreamWindowed = groupedStream.windowedBy(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>))
    .aggregate(
        () -&gt; <span class="integer">0L</span>,
        (aggKey, newValue, aggValue) -&gt; aggValue + newValue,
        Materialized.&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>, WindowStore&lt;Bytes, <span class="type">byte</span><span class="type">[]</span>&gt;&gt;as(<span class="string"><span class="delimiter">&quot;</span><span class="content">miStoreWindow</span><span class="delimiter">&quot;</span></span>)
        .withValueSerde(Serdes.Long()));
KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; sessionizedAggregatedStream = groupedStream.windowedBy(SessionWindows.with(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)).
    aggregate(
            () -&gt; <span class="integer">0L</span>,
            (aggKey, newValue, aggValue) -&gt; aggValue + newValue,
        (aggKey, leftAggValue, rightAggValue) -&gt; leftAggValue + rightAggValue,
        Materialized.&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>, SessionStore&lt;Bytes, <span class="type">byte</span><span class="type">[]</span>&gt;&gt;as(<span class="string"><span class="delimiter">&quot;</span><span class="content">MiStoreSession</span><span class="delimiter">&quot;</span></span>)
        .withValueSerde(Serdes.Long()));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Count</strong>: Cuenta el número de records por clave agrupada. Necesita un KGroupedStream o un KGroupedTable</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; aggregatedStream = groupedStream.count();

KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; aggregatedTable = groupedTable.count();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Count (Windowed)</strong>: Realiza la misma operación en una ventana de tiempo.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; aggregatedStream = groupedStream.windowedBy(
    TimeWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)))
    .count();

KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; aggregatedStream = groupedStream.windowedBy(
    SessionWindows.with(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)))
    .count();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Reduce</strong>: Combina los valores de los records por una clave agregada.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; aggregatedStream = groupedStream.reduce(
    (aggValue, newValue) -&gt; aggValue + newValue);
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; aggregatedTable = groupedTable.reduce(
    (aggValue, newValue) -&gt; aggValue + newValue,
    (aggValue, oldValue) -&gt; aggValue - oldValue);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Reduce (Windowed)</strong>: Combina los valores de los records por windows y por clave agrupada.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; timeWindowedAggregatedStream = groupedStream.windowedBy(
  TimeWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)))
  .reduce(
    (aggValue, newValue) -&gt; aggValue + newValue
  );

KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; sessionzedAggregatedStream = groupedStream.windowedBy(
  SessionWindows.with(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)))
  .reduce(
    (aggValue, newValue) -&gt; aggValue + newValue
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Join:</p>
</li>
<li>
<p>Los streams y las tablas pueden realizar las operaciones de Join.</p>
</li>
<li>
<p>* Las operaciones que se pueden realizar son:</p>
<div class="ulist">
<ul>
<li>
<p>KStream-KStream</p>
</li>
<li>
<p>KStream-KTable</p>
</li>
<li>
<p>KStream-GlobalKTable</p>
</li>
<li>
<p>KTable-GlobalKTable</p>
</li>
</ul>
</div>
</li>
<li>
<p>Como condición, los joins deben estar co-particionados, es decir, que poseen la misma partición para poder hacer el join.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KeyValue&lt;K, JV&gt; joinOutputRecord = KeyValue.pair(
    leftRecord.key,
    joiner.apply(leftRecord.value, rightRecord.value)
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Inner join: Permite obtener solo los datos cuyas claves coincidan en ambos streams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// KStream + KStream</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.join(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue,
    JoinWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)),
    Joined.with(
      Serdes.String(), <span class="comment">/* key */</span>
      Serdes.Long(),   <span class="comment">/* left value */</span>
      Serdes.Double())  <span class="comment">/* right value */</span>
  );
<span class="comment">// KTable + KTable</span>
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.join(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue
  );
<span class="comment">// KStream + KTable</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.join(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue, /
    Joined.keySerde(Serdes.String())
      .withValueSerde(Serdes.Long())
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Left Join: Permite mantener las claves del primer stream y unir solo con las claves del segundo stream, ignorando las claves del segundo stream que no coincidan.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// KStream + KStream</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.leftJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue,
    JoinWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)),
    Joined.with(
      Serdes.String(),
      Serdes.Long(),
      Serdes.Double())
  );
<span class="comment">// KTable + KTable</span>
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.leftJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue
  );
<span class="comment">// KStream + KTable</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.leftJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue,
    Joined.keySerde(Serdes.String())
      .withValueSerde(Serdes.Long())
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>OuterJoin: Permite mantenre las claves de ambos streams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// KStream + KStream</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.outerJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue,
    JoinWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)),
    Joined.with(
      Serdes.String(),
      Serdes.Long(),
      Serdes.Double())
  );
<span class="comment">// KTable + KTable</span>
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.outerJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue
  );</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_salida_de_datos">13.6. Salida de datos</h3>
<div class="ulist">
<ul>
<li>
<p>En kafka, el resultado de un KStream o un KTable se envia a Kafka de nuevo.</p>
</li>
<li>
<p>Para ello usamos los siguientes métodos:</p>
<div class="ulist">
<ul>
<li>
<p>To: Operación terminal. Devuelve a un topic los registros. Se puede implementar como se producen los mensajes:</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">stream.to(<span class="string"><span class="delimiter">&quot;</span><span class="content">topic-salida</span><span class="delimiter">&quot;</span></span>, Produced.with(Serdes.String(), Serdes.Long());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Through: Permite enviar los datos a un topic y continuar con un stream.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; newStream = stream.through(<span class="string"><span class="delimiter">&quot;</span><span class="content">mitopic</span><span class="delimiter">&quot;</span></span>).map(...);
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; newTable = table.through(<span class="string"><span class="delimiter">&quot;</span><span class="content">mitopic</span><span class="delimiter">&quot;</span></span>).map(...);</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_estado_en_streams">13.7. Estado en Streams</h3>
<div class="ulist">
<ul>
<li>
<p>Hasta ahora hemos estado trabajando en desarrollos sin estado</p>
</li>
<li>
<p>Sin embargo, una de las grandes utilidades en kafka es el uso con estado.</p>
</li>
<li>
<p>Permite mejorar la información recolectada por la aplicación</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_transform_processor">13.7.1. Transform Processor</h4>
<div class="ulist">
<ul>
<li>
<p>Se trata de la función más simple con estado de los KStreams</p>
</li>
<li>
<p><strong>KStream.transformValues()</strong></p>
</li>
<li>
<p>Es el mismo que mapValues() pero, en este caso, accede al <strong>StateStore</strong> para completar la tarea.</p>
</li>
<li>
<p>Permite también programar tareas pare que se ejecuten a intervalos por medio del método <strong>punctuate()</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-streams-state-01.png" alt="kafka streams state 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por medio del almacenamiento local podemos actualizar la información de los records.</p>
</li>
<li>
<p>Como ejemplo, podríamos acumular la información de un cliente para ver cuanto se ha gastado.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kafka_connect">14. Kafka Connect</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Se trata de un framework para envio de flujos de datos entre Kafka y otros sistemas</p>
</li>
<li>
<p>Open Source y forma parte de la distribución de Apacha Kafka</p>
</li>
<li>
<p>Simple, escalable y seguro</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-connect-01.png" alt="kafka connect 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Permite streams de bases de datos SQL en kafka</p>
</li>
<li>
<p>Permite streams de kafka topics en HDFS para procesado en streams</p>
</li>
<li>
<p>Permite streams de topics en ElasticSearch para indexados</p>
</li>
<li>
<p>Básicamente, usa la misma filosofía de productor y consumidor para los clientes de Kafka Connect.</p>
</li>
<li>
<p>Se trata de clientes preconstruidos para realizar conexiones sencillas</p>
</li>
<li>
<p>Pueden ser extendidas por programadores</p>
</li>
<li>
<p>Los conectores son Jobs lógicos que gestionan la ingesta de datos entre kafka y otro sistema</p>
<div class="ulist">
<ul>
<li>
<p><strong>Connector sources</strong>: Leen datos de una fuente externa y lo inyectan en kafka (Productor)</p>
</li>
<li>
<p><strong>Connector Sinks</strong>: Escriben datso de kafka en un sistema de datos externo (Consumidor)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_tipos">14.1. Tipos</h3>
<div class="ulist">
<ul>
<li>
<p>La versión Opensource de Confluent provee de los siguientes conectores:</p>
<div class="ulist">
<ul>
<li>
<p>JDBC: Envio de filas nuevas o modificadas en mensajes kafka</p>
</li>
<li>
<p>HDFS: Envio de kafka a Hadoop Distributed File System. Integrado con Hive, y soporte de particiones</p>
</li>
<li>
<p>Elasticsearch</p>
</li>
<li>
<p>AWS S3</p>
</li>
<li>
<p>FileStream: Obtención del fin de fichero como un kafka message (logs), o viceversa, mensajes kafka a un fichero</p>
</li>
</ul>
</div>
</li>
<li>
<p>La versión enterprise</p>
<div class="ulist">
<ul>
<li>
<p>Replicator</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_modos_de_ejecución">14.2. Modos de ejecución</h3>
<div class="ulist">
<ul>
<li>
<p>Kafka Connect posee dos modos de ejecución</p>
<div class="ulist">
<ul>
<li>
<p>Standalone:</p>
<div class="ulist">
<ul>
<li>
<p>Proceso como un solo worker en una máquina</p>
</li>
<li>
<p>Uso para pruebas o procesos que no se van a distribuir</p>
</li>
</ul>
</div>
</li>
<li>
<p>Distribuido:</p>
<div class="ulist">
<ul>
<li>
<p>Multiples procesos worker en una o más máquinas</p>
</li>
<li>
<p>Uso para tolerancia a fallos y escalabilidad</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_replicator">14.3. Replicator</h3>
<div class="ulist">
<ul>
<li>
<p>Permite replicar topics entre clusters de Apache Kafka</p>
</li>
<li>
<p>Crea los topics exactamente igual que se crearon en el cluster original</p>
</li>
<li>
<p>Incluye también las modificaciones particulares del topic.</p>
</li>
<li>
<p>Mantiene el factor de replicación y las particiones por igual.</p>
</li>
<li>
<p>Soporta distintas versiones de replicación</p>
<div class="ulist">
<ul>
<li>
<p>Despliegue de Arquitecturas Multi-DC</p>
</li>
<li>
<p>Configuraciones Multi-Datacenter</p>
</li>
<li>
<p>Esquemas de migración</p>
</li>
<li>
<p>Redes en el Cloud de Confluent y otras soluciones Cloud o híbridas.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_características_2">14.3.1. Características</h4>
<div class="ulist">
<ul>
<li>
<p>Permite listas blancas y negras, y expresiones regulares</p>
</li>
<li>
<p>Creación de topics dinámicos en destino</p>
</li>
<li>
<p>Modificación de particiones en destino si lo han hecho en origen</p>
</li>
<li>
<p>Reconfiguración de topics si cambian en origen</p>
</li>
<li>
<p>Soporta la preservación de Timestamps, la prevención de repeticiones de mensajes cíclicos, y la traducción de los offsets de consumidores.</p>
</li>
<li>
<p>Se puede migrar de MirrorMaker a Replicator. No se puede migrar de forma inversa.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_monitorización_de_kafka">15. Monitorización de Kafka</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_métricas_de_los_brokers">15.1. Métricas de los Brokers</h3>
<div class="ulist">
<ul>
<li>
<p>A la hora de monitorizar nuestro clúster, es importante llevar un control de múltiples elementos, y los puntos de presión de cada pieza software son distintos en función de su naturaleza.</p>
</li>
<li>
<p>Los <strong>Brokers</strong> son el punto central de <strong>Kafka</strong>, por eso vamos a empezar por ellos.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_sistemas">15.1.1. Sistemas</h4>
<div class="ulist">
<ul>
<li>
<p>Los puntos que debemos controlar para ellos son:</p>
<div class="ulist">
<ul>
<li>
<p>El espacio disponible en disco (la falta de espacio es tremendamente peligrosa)</p>
</li>
<li>
<p>El uso de lectura y escritura de disco. Podemos tener cuellos de botella si hacemos un uso muy intenso del mismo</p>
</li>
<li>
<p>Cuántas páginas de logs están cacheadas</p>
</li>
<li>
<p>Cuál es el ratio de hits en esa caché</p>
</li>
</ul>
</div>
</li>
<li>
<p>Ya hablamos anteriormente del uso de disco, y cómo calcular con cierto margen de holgura lo que íbamos a necesitar.</p>
</li>
<li>
<p>Si tenemos correctamente configurada la rotación de los logs, y hemos calculado correctamente la carga de nuestro sistema, no deberíamos tener problemas.</p>
</li>
<li>
<p>Si lo monitorizamos veremos que tiene forma de sierra (va creciendo, y posteriormente la rotación de los logs libera espacio), así constantemente</p>
</li>
<li>
<p>Si nos estamos quedando sin espacio, vamos a tener que solucionarlo.</p>
<div class="ulist">
<ul>
<li>
<p>Modificando (si es posible) la política de rotación de los logs</p>
</li>
<li>
<p>Añadiendo más discos al nodo</p>
</li>
<li>
<p>Escalando, añadiendo más nodos (y brokers) al sistema</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>du</strong>: disk usage (opción -h para human readable, y --max-depth=0 para no ver el uso de subdirectorios)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% du -h /tmp/kafka-logs --max-depth=0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>df</strong>: Disk free, nos indica el espacio disponible en disco (de nuevo, -h para verlo más cómodo):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% df -h</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El uso de disco es otra métrica importante para nuestros <strong>Brokers</strong>.</p>
</li>
<li>
<p>Un uso elevado puede producir una caída de rendimiento, aunque no tengamos un problema de espacio. Si esto sucede:</p>
<div class="ulist">
<ul>
<li>
<p>Revisar que el balanceo sea correcto (puede que tengamos mál indicados los líderes)</p>
</li>
<li>
<p>Si no mejora, valora la opción de añadir más nodos, para repartirse el trabajo</p>
</li>
<li>
<p>Otra opción es hacer uso de discos de estado sólido, SSD.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Herramientas que pueden ayudarnos a monitorizar el uso de disco para lecturas/escrituras son:</p>
<div class="ulist">
<ul>
<li>
<p><strong>iostat</strong>: del paquete <strong>sysstat</strong>, que nos monitoriza el uso por cada disco (lecturas por segundo, escrituras&#8230;&#8203;)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% iostat -x 1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>sar</strong>: También de <strong>sysstat</strong>, nos muestra datos agrupados, para saber el tiempo que ha estado ocioso el disco durante unos intervalos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% sar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>También era interesante conocer las páginas que estaban cacheadas y el ratio de aciertos.</p>
</li>
<li>
<p>Evidentemente, cuanto más logs pueda tener en memoria, más eficiente va a ser mi sistema.</p>
</li>
<li>
<p>Si no puedo mantener todas en memoria, mantendré sólo los más recientes.</p>
</li>
<li>
<p>Si tenemos pocos logs cacheados, podemos intentar solucionarlo de la siguiente manera:</p>
<div class="ulist">
<ul>
<li>
<p>Verificando el tamaño de los logs, tal vez ficheros de tamaño más pequeño me permitan cachearlos con mayor facilidad</p>
</li>
<li>
<p>Añadir más RAM, esto permitirá tener más caché</p>
</li>
<li>
<p>Añadir Brokers, con nuevos nodos (bien balanceados), se podrá tener más caché de logs</p>
</li>
</ul>
</div>
</li>
<li>
<p>Podemos consultar la memoria virtual con el comando <strong>vmstat</strong>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% vmstat</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Existe una utilidad que puede ayudaros llamada <strong>cachestat</strong>, desarrollada por <strong>Brendan Gregg</strong> que puede sernos de utilidad (muestra cada x segundos el total de hits de la caché)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ wget https://raw.githubusercontent.com/brendangregg/perf-t/master/fs/cachestat
...
100%[======================================&gt;] 5,435       --.-K/s   in 0s

2019-01-23 20:01:41 (22.0 MB/s) - ‘cachestat’ saved [5435/5435]
[kafka@kafka-server ~]$ chmod +x cachestat
[kafka@kafka-server ~]$ sudo ./cachestat 10
Counting cache functions... Output every 10 seconds.
    HITS   MISSES  DIRTIES    RATIO   BUFFERS_MB   CACHE_MB
    1934        0       12   100.0%            2       2183
     346        0        6   100.0%            2       2183
    2711        0       20   100.0%            2       2183</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_métricas_de_los_consumidores_y_productores">15.2. Métricas de los Consumidores y Productores</h3>
<div class="ulist">
<ul>
<li>
<p>Los consumidores son procesos <strong>Java</strong>, y como tal vamos a analizarlos con más detalle cuando veamos las herramientas de monitorización <strong>Java</strong>.</p>
</li>
<li>
<p>Los puntos que más nos pueden interesar son:</p>
<div class="ulist">
<ul>
<li>
<p>El uso de RAM</p>
</li>
<li>
<p>El LAG que puedan estar experimentando (retraso entre la escritura del mensaje por un productor y la lectura por parte de un consumidor)..</p>
</li>
</ul>
</div>
</li>
<li>
<p>Un uso inadecuado de la RAM puede penalizar nuestro programa (o incluso acabar con él). La forma de uso de la RAM suele tener aspecto de dientes de sierra (debido a la naturaleza del GC de la JVM).</p>
</li>
<li>
<p>Si un Consumidor tiene problemas, recordar que podemos escalar facilmente añadiendo más consumidores con su mismo <strong>group.id</strong>.</p>
</li>
<li>
<p>Con respecto al LAG, el punto determinante es ver si va aumentando. Si cada vez estamos más lejos de los mensajes que se escriben, quiere decir que no podemos procesar tanto como desearíamos.</p>
</li>
<li>
<p>Soluciones para esto son:</p>
<div class="ulist">
<ul>
<li>
<p>Verificar que el Broker responde correctamente, puede que no esté cacheando los logs y por ello retrase al consumer</p>
</li>
<li>
<p>Aumentar el número de particiones, y por supuesto, añadir más consumidores. A ver si entre varios pueden estar al día</p>
</li>
<li>
<p>Incrementar la RAM de los consumidores. Puede que vayan lento porque no pueden almacenar en memoria muchos mensajes.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Kafka</strong> ofrece una herramienta para monitorizar los grupos de consumidores actuales y ver su LAG, <strong>kafka-consumer-groups.sh</strong>.</p>
</li>
<li>
<p>Lo primero se debe pedir una lista de los consumidores</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --list</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Después, se pide la información de un grupo de consumidores concretos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group consumer_base</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_herramientas_java_para_monitorizar">15.3. Herramientas JAVA para monitorizar</h3>
<div class="ulist">
<ul>
<li>
<p>La monitorización propia de la <strong>JVM</strong> es un tema vital a la hora de trabajar con <strong>Kafka</strong>.</p>
</li>
<li>
<p>En este tema vamos a hablar un poco de las herramientas que tenemos disponibles para poder monitorizar este apartado, poniendo especial énfasis en los <strong>Managed beans</strong> publicados por <strong>Kafka</strong> para  obtener información de especial interés.</p>
</li>
<li>
<p>Las herramientas que vamos a ver son:</p>
<div class="ulist">
<ul>
<li>
<p>GC Viewer</p>
</li>
<li>
<p>Visual GC</p>
</li>
<li>
<p>JVisualVM</p>
</li>
<li>
<p>JCMD</p>
</li>
<li>
<p>JMC</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_gcviewer">15.3.1. GCViewer</h4>
<div class="ulist">
<ul>
<li>
<p>Es una pequeña herramienta que visualiza los datos de recogida de basura detallada generados por las máquinas virtuales de Sun e IBM Java (JVM).</p>
</li>
<li>
<p>El análisis de estos datos puede ser útil en aplicaciones con el fin de ajustar y maximizar el rendimiento del colector de basura y por lo tanto la propia aplicación.</p>
</li>
<li>
<p><a href="https://github.com/chewiebug/GCViewer">Más información</a></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-01.png" alt="kafka monitorizacion 01" width="600">
</div>
<div class="title">Figure 4. Captura de gcviewer</div>
</div>
</div>
<div class="sect3">
<h4 id="_visualgc">15.3.2. visualgc</h4>
<div class="ulist">
<ul>
<li>
<p>Visual Garbage Collection Monitoring Tool.</p>
</li>
<li>
<p>Se asigna a un HotSpot JVM instrumentado y recoge y muestra gráficamente la recolección de basura, cargador de clases, y los datos de rendimiento del compilador HotSpot.</p>
</li>
<li>
<p>La JVM de destino se identifica por su identificador de la máquina virtual, o <strong>VMID</strong>.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://www.oracle.com/technetwork/java/visualgc-136680.html">Más información</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-02.png" alt="kafka monitorizacion 02" width="600">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>A partir de Java 8 ya no funciona (pues no hay área PermGen), pero usaremos un plugin de <strong>JVisualVM</strong> que es exáctamente igual</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_jconsole">15.3.3. JConsole</h4>
<div class="ulist">
<ul>
<li>
<p>Esta herramienta de interfaz gráfica de usuario JConsole permite monitorizar cualquier aplicación que cumpla con la especificación Java Management Extensions (JMX).</p>
</li>
<li>
<p>JConsole utiliza JMX de la JVM para proporcionar información sobre el rendimiento y el consumo de recursos de las aplicaciones que se ejecutan en la plataforma Java.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://docs.oracle.com/javase/6/docs/technotes/guides/management/jconsole.html">Más información</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-03.png" alt="kafka monitorizacion 03" width="600">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_jvisualvm">15.3.4. JVisualVM</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Java Virtual Machine Monitoring, Troubleshooting, and Profiling Tool</strong></p>
</li>
<li>
<p>Es una herramienta con interfaz gráfica de usuario que proporciona información detallada acerca de las aplicaciones basadas en la tecnología Java.</p>
</li>
<li>
<p>Java VisualVM combina la supervisión, la solución de problemas, y los servicios de perfilado en una sola herramienta.</p>
</li>
<li>
<p>Por ejemplo, la mayoría de la funcionalidad ofrecida por las herramientas independientes jmap, jinfo, jstat y jstack se han integrado en Java VisualVM.</p>
</li>
<li>
<p>Otras funcionalidades, como algunas de las que ofrece la herramienta JConsole, se pueden añadir como plug-ins opcionales.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://docs.oracle.com/javase/6/docs/technotes/tools/share/jvisualvm.html">Más información</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-04.png" alt="kafka monitorizacion 04" width="600">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_jcmd">15.3.5. JCMD</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Java Command</strong></p>
</li>
<li>
<p>El comando jcmd es nuevo en JDK 7 y ofrece muchas de las características de  JPS, además de alguna información adicional.</p>
</li>
<li>
<p>El comando jcmd le permite consultar diversos aspectos de las máquinas virtuales específicas.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://docs.oracle.com/javase/7/docs/technotes/tools/windows/jcmd.html">Más información</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-05.png" alt="kafka monitorizacion 05" width="600">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_jmc">15.3.6. JMC</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Java Mision Control</strong></p>
</li>
<li>
<p>Permite a los administradores y desarrolladores de Java recopilar información detallada de bajo nivel acerca de cómo la Máquina Virtual Java (JVM) y la aplicación Java se están comportando.</p>
</li>
<li>
<p>JMC es un avanzado conjunto de herramientas que permite el análisis eficiente y detallada de los datos recogidos por Java Fligh Recorder.</p>
</li>
<li>
<p>A partir de la versión de Oracle JDK 7 Actualización 40 (7u40), Java Misión de Control se incluye con el HotSpot JVM.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://www.oracle.com/technetwork/java/javaseproducts/mission-control/java-mission-control-1998576.html">Más información</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-06.png" alt="kafka monitorizacion 06" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con respecto a los valores publicados por <strong>Kafka</strong> a través de sus <strong>Managed Beans</strong>, podemos agrupar los más importantes según a lo que hacen referencia:</p>
<div class="ulist">
<ul>
<li>
<p>Estadísticas de los <strong>Brokers</strong></p>
</li>
<li>
<p>Estadísticas de los clientes <strong>Productores</strong></p>
</li>
<li>
<p>Estadísticas de los clientes <strong>Consumidores</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_jmx_brokers">15.4. JMX - Brokers</h3>
<div class="ulist">
<ul>
<li>
<p>Las estadísticas más destacables de los <strong>Brokers</strong>, podríamos destacar:</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypereplicamanager_underreplicatedpartitions">15.4.1. JMX MBean: kafka.server:type=ReplicaManager.UnderReplicatedPartitions</h4>
<div class="ulist">
<ul>
<li>
<p>Número de particiones que no están replicadas tantas veces como deberían (debería ser 0 si no hay problemas)</p>
</li>
<li>
<p>Cualquier valor distinto de 0 significa que es posible una pérdida de datos al no tener todas las réplicas.</p>
</li>
<li>
<p>Existen varias soluciones</p>
<div class="ulist">
<ul>
<li>
<p>auto.leader.rebalance.enable = false &#8594; si lo tenemos así, tendremos que lanzar el script kafka-leader-election.sh para recolocar y sincronizar los datos a todas las réplicas.</p>
</li>
<li>
<p>Si seguimos con un valor constante distinto a 0, posiblemente sea por un broker caido.</p>
</li>
<li>
<p>Si están todos los brokers activos, el problema será de rendimiento</p>
</li>
<li>
<p>En este caso, hay que localizar si se trata de un broker concreto o del cluster.</p>
</li>
<li>
<p>Podemos conectarnos a cada broker y lanzar el comando <strong>kafka-topics.sh --describe --under-replicated</strong> donde nos indicará el broker afectado.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_controllertypekafkacontroller_offlinepartitionscount">15.4.2. JMX MBean: kafka.controller:type=KafkaController.OfflinePartitionsCount</h4>
<div class="ulist">
<ul>
<li>
<p>Sólo consultable desde el controlador</p>
</li>
<li>
<p>Son las particiones que no tienen una partición líder accesible (por lo que no se puede ni leer ni escribir)</p>
</li>
<li>
<p>Significa que debe ser también 0</p>
</li>
<li>
<p>Es indicativo de caida de un broker</p>
</li>
<li>
<p>En caso de que los brokers estén bien, es indicativo de un lider "sucio" que no puede sincronizar con los seguidores.</p>
</li>
<li>
<p>Significa que el lider no está sincronizado y los clientes no pueden conectarse a él.</p>
</li>
<li>
<p>Hay que asegurarse de que no puede elegirse una partición no sincronizada.</p>
<div class="ulist">
<ul>
<li>
<p>unclean.leader.election.enable = false</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_controllertypekafkacontroller_activecontrollercount">15.4.3. JMX MBean: kafka.controller:type=KafkaController.ActiveControllerCount*</h4>
<div class="ulist">
<ul>
<li>
<p>Nos indica si el broker actual ejerce de controlador, con valor 0 o 1</p>
</li>
<li>
<p>En caso de que haya más de uno con valor 1 (por que haya un broker atascado) la solución es reiniciar ambos nodos y esperar a la reelección</p>
</li>
<li>
<p>En el caso de que haya 0, hay que revisar que zookeeper esté correctamente, ya que si tienen problemas de comunicación con zookeeper, habrá que solucionar el problema y comprobar que se vuelve a elegir controlador</p>
</li>
<li>
<p>Si zookeeper está correctamente, habrá que reiniciar todo el cluster para que vuelvan a realizar la elección de controlador.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypebrokertopicmetrics_bytesinoutpersec">15.4.4. JMX MBean: kafka.server:type=BrokerTopicMetrics.Bytes[In,Out]PerSec</h4>
<div class="ulist">
<ul>
<li>
<p>BytesIn es una buena métrica para comprobar el trabajo por broker</p>
</li>
<li>
<p>Podemos comprobar como trabajan los brokers a la hora de recibir datos, y si hay algún broker que trabaje más que los demás.</p>
</li>
<li>
<p>BytesOut Suele ser múltiples veces más que BytesIn ya que tiene que ver con las ordenes de replicación.</p>
</li>
<li>
<p>Posee varios atributos interesantes:</p>
<div class="ulist">
<ul>
<li>
<p>OneMinuteRate &#8594; no es muy util ya que suele fluctuar demasiado.</p>
</li>
<li>
<p>FiveMinuteRate</p>
</li>
<li>
<p>FifteenMinuteRate</p>
</li>
<li>
<p>MeanRate</p>
</li>
<li>
<p>Count</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypebrokertopicmetrics_messagesinpersec">15.4.5. JMX MBean: kafka.server:type=BrokerTopicMetrics.MessagesInPerSec</h4>
<div class="ulist">
<ul>
<li>
<p>El número de mensajes recibidos.</p>
</li>
<li>
<p>Sin embargo, no tenemos métrica de mensajes enviados.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypereplicamanager_partitionscount">15.4.6. JMX MBean: kafka.server:type=ReplicaManager.PartitionsCount</h4>
<div class="ulist">
<ul>
<li>
<p>Si tenemos la opción auto.create.topics.enable = true</p>
</li>
<li>
<p>Es una métrica que nos indica el número de particiones que disponemos.</p>
</li>
<li>
<p>Si la opción está desactivada, no es necesario monitorizarla ya que se hace de forma manual.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypereplicamanager_leadercount">15.4.7. JMX MBean: kafka.server:type=ReplicaManager.LeaderCount</h4>
<div class="ulist">
<ul>
<li>
<p>Indica el número de particiones lider por cada broker</p>
</li>
<li>
<p>En caso de caida y si tenemos la opción auto.leader.rebalance.enable = false</p>
</li>
<li>
<p>Si se cae una instancia, el cluster se desequilibrará, y el número de particiones líderes se repartirá entre el resto de brokers.</p>
</li>
<li>
<p>Se deben realizar periódicamente kafka-leader-election.sh para que se reequilibre de nuevo.</p>
</li>
<li>
<p>Es preferible hacerlo manualmente para evitar hacerlo en medio de los picos de carga.</p>
</li>
<li>
<p>El valor recomendado debe ser:</p>
<div class="ulist">
<ul>
<li>
<p>LeaderCount/PartitionCount = 1/ReplicationFactor</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_networktyperequestmetrics_tipo_nombre">15.4.8. JMX MBean: kafka.network:type=RequestMetrics.[tipo].[nombre]</h4>
<div class="ulist">
<ul>
<li>
<p>Permite monitorizar todas las métricas de kafka disponibles.</p>
</li>
<li>
<p>Se divide en varias categorías. Se elige una de cada categoria.</p>
<div class="ulist">
<ul>
<li>
<p>Metric Type:</p>
<div class="ulist">
<ul>
<li>
<p>TotalTimMs</p>
</li>
<li>
<p>RequestQueueTimeMs</p>
</li>
<li>
<p>LocalTimeMs</p>
</li>
<li>
<p>RemoteTimeMs</p>
</li>
<li>
<p>ThrottleTimeMs</p>
</li>
<li>
<p>ResponseQueueTimeMs</p>
</li>
<li>
<p>ResponseSendTimeMs</p>
</li>
<li>
<p>RequestsPerSec</p>
</li>
</ul>
</div>
</li>
<li>
<p>Request Name:</p>
<div class="ulist">
<ul>
<li>
<p>ApiVersion</p>
</li>
<li>
<p>ControlledShutdown</p>
</li>
<li>
<p>CreateTopics</p>
</li>
<li>
<p>DeleteTopics</p>
</li>
<li>
<p>DescribeGroups</p>
</li>
<li>
<p>Produce</p>
</li>
<li>
<p>SaslHandshake</p>
</li>
<li>
<p>StopReplica</p>
</li>
<li>
<p>SyncGroup</p>
</li>
<li>
<p>UpdateMetadata</p>
</li>
<li>
<p>etc.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Attributes</p>
<div class="ulist">
<ul>
<li>
<p>50thPercentile</p>
</li>
<li>
<p>75thPercentile</p>
</li>
<li>
<p>99thPercentile</p>
</li>
<li>
<p>999thPercentile</p>
</li>
<li>
<p>Count</p>
</li>
<li>
<p>Min</p>
</li>
<li>
<p>Max</p>
</li>
<li>
<p>Mean</p>
</li>
<li>
<p>StdDev</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>De todas ellas, es interesante el percentil 99, ya que nos dejará más claro los casos de picos de los valores comunes, indicando problemas de rendimiento.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_topicnombre_topicpartitionparticion">15.4.9. &#8230;&#8203;,topic=[nombre_topic],partition=[particion]</h4>
<div class="ulist">
<ul>
<li>
<p>Permite monitorizar las métricas a nivel de partición de un topic.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_controllertypecontrollerstats_uncleanleaderelectionspersec">15.4.10. JMX MBean: kafka.controller:type=ControllerStats.UncleanLeaderElectionsPerSec</h4>
<div class="ulist">
<ul>
<li>
<p>Si perdemos un broker con una partición líder y el resto de réplicas no habían copiado esa información, y se elije un líder nuevo, pero claro, se pueden haber perdido datos.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_jmx_productores">15.5. JMX - Productores</h3>
<div class="ulist">
<ul>
<li>
<p>Las estadísticas más interesantes de los clientes <strong>Productores</strong> son:</p>
<div class="ulist">
<ul>
<li>
<p>JMX MBean: kafka.producer:type=producer-metrics,client-id=[client-id]</p>
</li>
<li>
<p>JMX MBean: kafka.producer:type=producer-metrics,client-id=[client-id],node-id=node-[broker_id]</p>
</li>
<li>
<p>JMX MBean: kafka.producer:type=producer-metrics,client-id=[client-id],topic=[topic]</p>
</li>
</ul>
</div>
</li>
<li>
<p>Se recomienda que los clientes usen de client-id una indicación que favorezca la monitorización, como por ejemplo, ip o nombre del servidor origen. Sino se genera un id</p>
</li>
<li>
<p>Los atributos son:</p>
<div class="ulist">
<ul>
<li>
<p>record-error-rate: Indica la cantidad de mensajes que se han producido y han dado error. Solo indica aquellos que han fallado incluidos los reintentos.</p>
</li>
<li>
<p>request-latency-avg: Es interesante comprobar la media en uso normal, y si se incrementa, el rendimiento del cluster está cayendo, y suele acompañar con una caida de producción de mensajes.</p>
</li>
<li>
<p>record-send-rate: Tasa de envio de mensajes por segundo del broker.</p>
</li>
<li>
<p>request-rate: Media de peticiones recibidas por segundo por el broker</p>
</li>
<li>
<p>outgoing-byte-rate: Tasa de producción de datos</p>
</li>
<li>
<p>record-queue-time-avg: Trata el tiempo que tarda kafka desde la petición de mensaje hasta su envio</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_jmx_consumidores">15.6. JMX - Consumidores</h3>
<div class="ulist">
<ul>
<li>
<p>Las estadísticas más interesantes de los clientes <strong>Consumidores</strong> son:</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_jmx_mbeankafka_consumertypeconsumer_fetch_manager_metricsclient_idclient_idtopictopic_name">15.6.1. JMX MBean:kafka.consumer:type=consumer-fetch-manager-metrics,client-id=[client_id][,topic=&lt;topic_name]</h4>
<div class="ulist">
<ul>
<li>
<p>fetch-latency-avg: Permite indicar la latencia fetch.-.bytes fetch.max.wait.ms para optimizar esta variable</p>
</li>
<li>
<p>bytes-consumed-rate: Tasa de consumo de bytes.</p>
</li>
<li>
<p>records-consumed-rate: Tasa de consumo de mensajes</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbeankafka_consumertypeconsumer_coordinator_metricsclient_idclient_idtopictopic_name">15.6.2. JMX MBean:kafka.consumer:type=consumer-coordinator-metrics,client-id=[client_id][,topic=&lt;topic_name]</h4>
<div class="ulist">
<ul>
<li>
<p>Permite monitorizar la sincronización de los grupos de clientes, cuando el número de clientes consumidores en un mismo grupo cambia</p>
<div class="ulist">
<ul>
<li>
<p>sync-time-avg: Indica en ms lo que tarda en realizar la operación.</p>
</li>
<li>
<p>sync-rate: Sincronizaciones de grupo por segundo. Mas útil que la anterior. Debe ser 0 para grupos de consumidores estables.</p>
</li>
<li>
<p>commit-latency-avg: La velocidad de confirmación de los offsets. Debe cambiar poco, y si se incrementa, comprobar la caida de rendimiento.</p>
</li>
<li>
<p>assigned-partitions: Permite comprobar el consumo de particiones en los grupos.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_lag">15.6.3. Lag</h4>
<div class="ulist">
<ul>
<li>
<p>Existen métricas de análisis de lag.</p>
</li>
<li>
<p>Sin embargo son bastante complejas de entender.</p>
</li>
<li>
<p>Para solucionar este problema, existe un proyecto llamado Burrow de LinkedIn que permite monitorizar el lag de los consumidores de Kafka.</p>
</li>
<li>
<p>El proyecto se encuentra en:</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://github.com/linkedin/Burrow">Github Burrow</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Permite hacer un seguimiento del lag de los consumidores.</p>
</li>
<li>
<p>Permite definir endpoints HTTP que permite mostrar la información del cluster de kafka y de los grupos de consumidores.</p>
</li>
<li>
<p>Permite también notificar si algún grupo cumple un criterio concreto.</p>
</li>
<li>
<p>Existen una serie de subsistemas:</p>
<div class="ulist">
<ul>
<li>
<p>Clusters: Permite actualizar periódicamente la lista de topics y el último offset por partición.</p>
</li>
<li>
<p>Consumers: Permite mostrar la información de los grupos de consumidores como su lag.</p>
</li>
<li>
<p>Storage: Permite almacenar toda la información en el sistema</p>
</li>
<li>
<p>Evaluator: Obtiene la información del módulo Storage y comprueba el status de un grupo de consumidores. Usa reglas de evaluación para comprobaciones de consumidores.</p>
</li>
<li>
<p>Notifier: Consulta el estado de un grupo de consumidores y envia una notificación si cierto criterio se ha cumplido.</p>
</li>
<li>
<p>HTTP Server: Provee de un servidor HTTP para mostrar la información del cluster y sus consumidores.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_cuotas">15.6.4. Cuotas</h4>
<div class="ulist">
<ul>
<li>
<p>Tanto para productores como para consumidores, podemos definir cuotas.</p>
</li>
<li>
<p>Kafka ofrece los siguientes mbeans</p>
<div class="ulist">
<ul>
<li>
<p>JMX MBean:kafka.producer:type=producer-metrics,client-id=[client_id]</p>
<div class="ulist">
<ul>
<li>
<p>produce-throttle-time-avg: media de producción</p>
</li>
</ul>
</div>
</li>
<li>
<p>JMX MBean:kafka.consumer:type=consumer-fetch-manager-metrics,client-id=[client_id]</p>
<div class="ulist">
<ul>
<li>
<p>fetch-throttle-time-avg: media de consumo</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Permite definir cuotas por id de cliente, frenando tanto productores como consumidores con ese id de cliente.</p>
</li>
<li>
<p>Por defecto está deshabilitado.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_monitorizacion">15.7. Lab: Monitorizacion</h3>
<div class="ulist">
<ul>
<li>
<p>Vamos a probar a monitorizar las aplicaciones a través de <strong>JMX</strong>, y para esto tenemos que arrancar habiendo configurado la variable de entorno <strong>JMX_PORT</strong>.</p>
</li>
<li>
<p>Como nuestra configuración es un poco especial, vamos a levantar todos los brokers en distintos puertos (para que no se solapen).</p>
</li>
<li>
<p>Así que paramos todo el clúster y arrancamos con la siguiente configuración:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /usr/local/zookeeper-3.4.14/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[kafka@kafka-server ~]$ export JMX_PORT=9595
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties1
[kafka@kafka-server ~]$ export JMX_PORT=9596
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties2
[kafka@kafka-server ~]$ export JMX_PORT=9597
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties3</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>para publicarlo externamente, debemos editar <strong>kafka-run-class.sh</strong> para añadir las opciones propies de la <strong>JVM</strong> para publicar el acceso <strong>JMX</strong> remoto, por ejemplo esta configuración:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">-Dcom.sun.management.jmxremote.port=4433 -Dcom.sun.management.jmxremote.ssl=false  -Dcom.sun.management.jmxremote.authenticate=false</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Lo que hemos mostrado basicamente ya viene añadido (dentro de la variable <strong>KAFKA_JMX_OPTS</strong> de dicho script), pero evidentemente, si queremos cifrar la comunicación o añadir autenticación, debemos hacerlo de manera específica.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A través de <strong>JConsole</strong> o <strong>JMC</strong>, podemos consultar información de los <strong>Managed Beans</strong>, como se muestra en el ejemplo</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-07.png" alt="kafka monitorizacion 07" width="600">
</div>
</div>
<div class="sect3">
<h4 id="_cmak">15.7.1. CMAK</h4>
<div class="ulist">
<ul>
<li>
<p>Es el antiguo <em>Yahoo Kafka Manager</em>
Lo primero que tenemos que hacer es descargar los fuentes del <strong>CMAK</strong> de su repositorio de <strong>github</strong>. Podemos hacerlo directamente desde nuestra VM con el comando <strong>wget</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$  wget https://github.com/yahoo/CMAK/releases/download/3.0.0.5/cmak-3.0.0.5.zip</code></pre>
</div>
</div>
<div class="paragraph">
<p>Una vez descargado tenemos que descomprimirlo</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ unzip cmak-3.0.0.5.zip</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nos vamos a la ruta en la que ha desempaquetado los binarios y le indicamos el zookeeper para que pueda almacenar metadatos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cd cmak-3.0.0.5/conf</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Editamos el fichero application.conf y modificamos en el fichero las entradas del zookeeper</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code># Settings prefixed with 'kafka-manager.' will be deprecated, use 'cmak.' instead.
# https://github.com/yahoo/CMAK/issues/713
kafka-manager.zkhosts=&quot;kafka-server.local:2181&quot;
kafka-manager.zkhosts=${?ZK_HOSTS}
cmak.zkhosts=&quot;kafka-server.local:2181&quot;
cmak.zkhosts=${?ZK_HOSTS}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>También podríamos exportar la variable ZK_HOSTS con la ruta a los servidores de zookeeper y conseguiríamos el mismo efecto.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ export ZK_HOSTS=kafka-server.local:2181</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Ya estamos listos para trabajar. Vamos a arrancar nuestro programa</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server cmak-3.0.0.5]$ ./bin/cmak</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para hacer uso del programa, nos vamos a conectar vía web, ya que levanta un servidor en el puerto 9000.</p>
</li>
<li>
<p>Podemos ir directamente desde nuestra máquina virtual a la URL: <a href="http://kafka-server.local:9000" class="bare">http://kafka-server.local:9000</a></p>
</li>
<li>
<p>Al entrar en la ruta donde publica el <strong>CMAK</strong>, no vemos nada todavía</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-01.png" alt="kafka monitorizacion laboratorio 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tenemos que crear un clúster para monitorizarlo.</p>
</li>
<li>
<p>Para ello vamos a "cluster"  y "Add Cluster"</p>
</li>
<li>
<p>Damos de alta nuestro clúster con una configuración básica</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-02.png" alt="kafka monitorizacion laboratorio 02" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora vemos un resumen del clúster al que nos hemos conectado</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-03.png" alt="kafka monitorizacion laboratorio 03" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si vamos a <strong>Topics</strong>, tenemos un resumen de los mismos</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-04.png" alt="kafka monitorizacion laboratorio 04" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y también podemos consultar la información de los <strong>Brokers</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-05.png" alt="kafka monitorizacion laboratorio 05" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos crear nuevos <strong>Topics</strong> a través de esta herramienta</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-06.png" alt="kafka monitorizacion laboratorio 06" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y hasta podemos consultar información de los <strong>Consumers</strong> que hay actualmente trabajando en el clúster.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-07.png" alt="kafka monitorizacion laboratorio 07" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y si queremos ver qué está haciendo el <strong>consumer group</strong>, podemos pinchar sobre él y veremos dónde está trabajando</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-08.png" alt="kafka monitorizacion laboratorio 08" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>O conocer más información del <strong>Topic</strong> en cuestión sobre el que trabajamos</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-09.png" alt="kafka monitorizacion laboratorio 09" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pero podemos obtener más, vamos a obtener estadísticas a través de <strong>JMX</strong>.</p>
</li>
<li>
<p>Para ello vamos a parar todo el clúster, y arrancar habiendo definido la variable <strong>JMX_PORT</strong>.</p>
</li>
<li>
<p>Como mis 3 brokers están en el mismo nodo, voy a tener que hacer algún cambio adicional (poner varias veces esta variable para que no se pisen entre ellos).</p>
</li>
<li>
<p>Arrancaría de la siguiente forma:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server cmak-3.0.0.5]$ zkServer.sh start
[kafka@kafka-server cmak-3.0.0.5]$ export JMX_PORT=9595
[kafka@kafka-server cmak-3.0.0.5]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties1
[kafka@kafka-server cmak-3.0.0.5]$ export JMX_PORT=9596
[kafka@kafka-server cmak-3.0.0.5]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties2
[kafka@kafka-server cmak-3.0.0.5]$ export JMX_PORT=9597
[kafka@kafka-server cmak-3.0.0.5]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties3
[kafka@kafka-server cmak-3.0.0.5]$ export JMX_PORT=9595
[kafka@kafka-server cmak-3.0.0.5]$ ./bin/cmak</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez hecho esto, vuelvo a conectarme al <strong>CMAK</strong>, y edito la configuración de mi clúster para añadir soporte <strong>JMX</strong> (NOTA: si hemos habilitado usuario y contraseña, también debemos especificarlo aquí)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-10.png" alt="kafka monitorizacion laboratorio 10" width="600">
</div>
</div>
<div class="paragraph">
<p>Ahora, si nos vamos a <strong>Broker</strong>, veremos que somos capaces de obtener información relevante gracias a los Managed Beans accesibles a través del <strong>JMX</strong></p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-11.png" alt="kafka monitorizacion laboratorio 11" width="600">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_burrow">15.7.2. Burrow</h4>
<div class="ulist">
<ul>
<li>
<p>Las monitorizaciones de lag por medio de las métricas nativas llamadas MaxLag:</p>
<div class="ulist">
<ul>
<li>
<p>Sin embargo, se deben recolectar por consumidor, y se deben interpretar por separado</p>
</li>
<li>
<p>Solo es válido mientras el consumidor está activo, sin consumidor no hay métricas</p>
</li>
<li>
<p>No es objetivo al ser el propio consumidor quien emite la métrica. Podría dar valores erroneos.</p>
</li>
<li>
<p>Solo está disponible en java, mientras que podemos tener otros clientes en otros lenguajes.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para eso está burrow.</p>
</li>
<li>
<p>Para instalar Burrow, hay que tener instalado el lenguaje GO que es el lenguaje de programación utilizado.</p>
</li>
<li>
<p>Instalamos golang por medio del siguiente comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ sudo dnf -y install golang-bin</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras su instalación, vamos a bajar el proyecto:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ go get github.com/linkedin/Burrow</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora nos colocamos en el directorio go/src/github.com/linkedin/Burrow</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cd go/src/github.com/linkedin/Burrow</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>y ejecutamos el comando de resolución de dependencias</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ go mod tidy</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por último lo instalamos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ go install</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_configuración_3">15.7.2.1. Configuración</h5>
<div class="ulist">
<ul>
<li>
<p>La configuración de Burrow se realiza en distintos formatos.</p>
</li>
<li>
<p>Admite TOML, JSON y YAML</p>
</li>
<li>
<p>Vamos a modificar el fichero toml alojado en <strong>./config/burrow.toml</strong></p>
</li>
<li>
<p>Para ello creamos un fichero llamado burrow.toml y agregamos la siguiente información:</p>
</li>
<li>
<p>Se divide en distintos apartados:</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="_general">15.7.2.1.1. General</h6>
<div class="ulist">
<ul>
<li>
<p>Permite indicar la localización de los ficheros PID e indica las salidas STDOUT y STDERR</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[general]
pidfile=&quot;burrow.pid&quot;  # fichero PID
stdout-logfile=&quot;burrow.out&quot; # Redirección de STDOUT y STDERR
access-control-allow-origin=&quot;*&quot; # Permisos de control de acceso http</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_logging">15.7.2.1.2. Logging</h6>
<div class="ulist">
<ul>
<li>
<p>Permite indicar como generar los ficheros de log del burrow.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[logging]
filename=&quot;logs/burrow.log&quot; # Ruta y nombre de fichero del log
level=&quot;info&quot; # Nivel de log
maxsize=100 # Tamaño máximo en MB de un fichero de log MB
maxbackups=30 # Máximo número de iteraciones del fichero de log
maxage=10 # Tiempo máximo de mantenimiento de ficheros de log
use-localtime=false  # tipo de fecha a la hora de generar el log
use-compression=true # Compresión de los ficheros rotados</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_zookeeper_2">15.7.2.1.3. Zookeeper</h6>
<div class="ulist">
<ul>
<li>
<p>Especifica la localización del servicio Zookeeper usado para el módulo de almacenamiento y la sincronización de múltiples copias de ficheros.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[zookeeper]
servers=[&quot;kafka-server.local:2181&quot;, &quot;kafka-node1.local:2181&quot;, &quot;kafka-node2.local:2181&quot; ]
timeout=6 # Tiempo de expiración de sesiones zookeeper.
root-path=&quot;/kafka-monitor/burrow&quot; # Ruta completa de nodos para que escriba Burrow dentro del zookeeper.</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_perfil_de_cliente">15.7.2.1.4. Perfil de cliente</h6>
<div class="ulist">
<ul>
<li>
<p>Los perfiles se usan para agrupar configuraciones. Permite indicar por medio de un nombre distintas configuraciones a aplicar</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[client-profile.burrow-client] # Nombre de la configuración
kafka-version=&quot;2.6.0&quot;    #kafka server version
client-id=&quot;burrow-client&quot; # Indicamos el id de cliente a utilizar</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_servidor_http">15.7.2.1.5. Servidor HTTP</h6>
<div class="ulist">
<ul>
<li>
<p>Configuración del servidor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[httpserver.mylistener]
address=&quot;:8082&quot;
timeout=300</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_almacenamiento">15.7.2.1.6. Almacenamiento</h6>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[storage.mystorage]
class-name=&quot;inmemory&quot;
intervals=10  # Offsets a almacenar por partición
expire-group=604800 # Segundos que deben pasar antes de que un grupo sea purgado si no tiene un offset confirmado (commited offset)</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_clusters">15.7.2.1.7. Clusters</h6>
<div class="ulist">
<ul>
<li>
<p>Permite configurar la lista de nodos del cluster de kafka para obtener la información del cluster, los topics y los Offsets</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[cluster.kafka-cluster]
class-name=&quot;kafka&quot;
servers=[ &quot;kafka-server.local:9092&quot;, &quot;kafka-node1.local:9092&quot;, &quot;kafka-node2.local:9092&quot; ]
client-profile=&quot;burrow-client&quot;
topic-refresh=10
offset-refresh=10</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_consumidores">15.7.2.1.8. Consumidores</h6>
<div class="ulist">
<ul>
<li>
<p>Pemite configurar como extraer la configuración de los offsets.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[consumer.myconsumers]
class-name=&quot;kafka&quot;
cluster=&quot;kafka-cluster&quot;  # Nombre de la configuración del cluster de kafka
servers=[ &quot;kafka-server.local:9092&quot;, &quot;kafka-node1.local:9092&quot;, &quot;kafka-node2.local:9092&quot; ]
client-profile=&quot;burrow-client&quot;
offsets-topic=&quot;__consumer_offsets&quot;
start-latest=true</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_ejecución_3">15.7.2.2. Ejecución</h5>
<div class="ulist">
<ul>
<li>
<p>Para ejecutarlo, vamos a lanzar el servicio por medio del comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ /home/kafka/go/bin/Burrow --config-dir .
Reading configuration from .</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez iniciado, podemos realizar peticiones contra el servicio.</p>
</li>
<li>
<p>Para verlo con mas facilidad, instalamos el comando jq que permite formatear json en la shell</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ sudo dnf install jq</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora vamos a ejecutar el status para comprobar que el servicio está correcto:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/burrow/admin
GOOD</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Listamos los Clusters</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   136  100   136    0     0   132k      0 --:--:-- --:--:-- --:--:--  132k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;cluster list returned&quot;,
  &quot;clusters&quot;: [
    &quot;kafka-cluster&quot;
  ],
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Mostramos la información del cluster</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   406  100   406    0     0   396k      0 --:--:-- --:--:-- --:--:--  396k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;cluster module detail returned&quot;,
  &quot;module&quot;: {
    &quot;class-name&quot;: &quot;kafka&quot;,
    &quot;servers&quot;: [
      &quot;kafka-server.local:9092&quot;,
      &quot;kafka-node1.local:9092&quot;,
      &quot;kafka-node2.local:9092&quot;
    ],
    &quot;client-profile&quot;: {
      &quot;name&quot;: &quot;burrow-client&quot;,
      &quot;client-id&quot;: &quot;burrow-client&quot;,
      &quot;kafka-version&quot;: &quot;2.6.0&quot;,
      &quot;tls&quot;: null,
      &quot;sasl&quot;: null
    },
    &quot;topic-refresh&quot;: 10,
    &quot;offset-refresh&quot;: 10
  },
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Listamos los consumidores actuales</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/consumer | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   146  100   146    0     0   142k      0 --:--:-- --:--:-- --:--:--  142k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;consumer list returned&quot;,
  &quot;consumers&quot;: [],
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/consumer&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos la lista de topics</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/topic | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   276  100   276    0     0   134k      0 --:--:-- --:--:-- --:--:--  134k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;topic list returned&quot;,
  &quot;topics&quot;: [
    &quot;base-topic&quot;,
    &quot;base-topic2&quot;,
    &quot;topic-log-compaction&quot;,
    &quot;my_topic&quot;,
    &quot;topic-log-compaction2&quot;,
    &quot;test&quot;,
    &quot;topic-kafka-mirror-maker&quot;,
    &quot;__consumer_offsets&quot;
  ],
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/topic&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un nuevo topic:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[vagrant@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --create --topic burrow-topic --partitions 3
Created topic burrow-topic.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a agregar un productor de pruebas que nos muestre información de lo que está haciendo.</p>
</li>
<li>
<p>Para eso vamos a usar kafka-verifiable-producer.sh</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[vagrant@kafka-server ~]$ kafka-verifiable-producer.sh --broker-list localhost:9092 --max-messages 10000000 --repeating-keys 5 --value-prefix 100 --throughput 5 --topic burrow-topic</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lanzamos ahora dos consumidores del mismo grupo de consumidores llamado burrow-group</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejecución en shell 1</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[vagrant@kafka-server ~]$ kafka-verifiable-consumer.sh --broker-list localhost:9092 --max-messages 10000 --topic burrow-topic --group-id burrow-group</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejecución en shell 2</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[vagrant@kafka-server ~]$ kafka-verifiable-consumer.sh --broker-list localhost:9092 --max-messages 10000 --topic burrow-topic --group-id burrow-group</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>En los consumidores podremos comprobar como cada uno obtiene una partición distinta.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Volvemos a listar los consumidores y comprobamos como aparece el consumidor de burrow y nuestro grupo de consumidores</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/consumer | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   181  100   181    0     0   176k      0 --:--:-- --:--:-- --:--:--  176k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;consumer list returned&quot;,
  &quot;consumers&quot;: [
    &quot;burrow-group&quot;,
    &quot;burrow-myconsumers&quot;
  ],
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/consumer&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como nos indica de forma sencilla que un grupo está funcionando correctamente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/consumer/burrow-group/status | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   608  100   608    0     0   593k      0 --:--:-- --:--:-- --:--:--  593k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;consumer status returned&quot;,
  &quot;status&quot;: {
    &quot;cluster&quot;: &quot;kafka-cluster&quot;,
    &quot;group&quot;: &quot;burrow-group&quot;,
    &quot;status&quot;: &quot;OK&quot;,
    &quot;complete&quot;: 1,
    &quot;partitions&quot;: [],
    &quot;partition_count&quot;: 3,
    &quot;maxlag&quot;: {
      &quot;topic&quot;: &quot;burrow-topic&quot;,
      &quot;partition&quot;: 0,
      &quot;owner&quot;: &quot;/192.168.15.100&quot;,
      &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
      &quot;status&quot;: &quot;OK&quot;,
      &quot;start&quot;: {
        &quot;offset&quot;: 28,
        &quot;timestamp&quot;: 1604851337376,
        &quot;observedAt&quot;: 1604851337000,
        &quot;lag&quot;: 0
      },
      &quot;end&quot;: {
        &quot;offset&quot;: 37,
        &quot;timestamp&quot;: 1604851346471,
        &quot;observedAt&quot;: 1604851346000,
        &quot;lag&quot;: 0
      },
      &quot;current_lag&quot;: 0,
      &quot;complete&quot;: 1
    },
    &quot;totallag&quot;: 0
  },
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/consumer/burrow-group/status&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En caso de no funcionar correctamente mostraría algo como:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">...
&quot;status&quot;:&quot;WARN&quot;
...
&quot;lag&quot;:113441213</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Consultamos explícitamene el lag</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/consumer/burrow-group/lag | jq
% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  1536  100  1536    0     0   750k      0 --:--:-- --:--:-- --:--:--  750k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;consumer status returned&quot;,
  &quot;status&quot;: {
    &quot;cluster&quot;: &quot;kafka-cluster&quot;,
    &quot;group&quot;: &quot;burrow-group&quot;,
    &quot;status&quot;: &quot;OK&quot;,
    &quot;complete&quot;: 1,
    &quot;partitions&quot;: [
      {
        &quot;topic&quot;: &quot;burrow-topic&quot;,
        &quot;partition&quot;: 0,
        &quot;owner&quot;: &quot;/192.168.15.100&quot;,
        &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
        &quot;status&quot;: &quot;OK&quot;,
        &quot;start&quot;: {
          &quot;offset&quot;: 47,
          &quot;timestamp&quot;: 1604851356381,
          &quot;observedAt&quot;: 1604851356000,
          &quot;lag&quot;: 0
        },
        &quot;end&quot;: {
          &quot;offset&quot;: 56,
          &quot;timestamp&quot;: 1604851365429,
          &quot;observedAt&quot;: 1604851365000,
          &quot;lag&quot;: 0
        },
        &quot;current_lag&quot;: 0,
        &quot;complete&quot;: 1
      },
      {
        &quot;topic&quot;: &quot;burrow-topic&quot;,
        &quot;partition&quot;: 1,
        &quot;owner&quot;: &quot;/192.168.15.100&quot;,
        &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
        &quot;status&quot;: &quot;OK&quot;,
        &quot;start&quot;: {
          &quot;offset&quot;: 47,
          &quot;timestamp&quot;: 1604851356989,
          &quot;observedAt&quot;: 1604851356000,
          &quot;lag&quot;: 0
        },
        &quot;end&quot;: {
          &quot;offset&quot;: 56,
          &quot;timestamp&quot;: 1604851366031,
          &quot;observedAt&quot;: 1604851366000,
          &quot;lag&quot;: 0
        },
        &quot;current_lag&quot;: 0,
        &quot;complete&quot;: 1
      },
      {
        &quot;topic&quot;: &quot;burrow-topic&quot;,
        &quot;partition&quot;: 2,
        &quot;owner&quot;: &quot;/192.168.15.100&quot;,
        &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
        &quot;status&quot;: &quot;OK&quot;,
        &quot;start&quot;: {
          &quot;offset&quot;: 160,
          &quot;timestamp&quot;: 1604851363214,
          &quot;observedAt&quot;: 1604851363000,
          &quot;lag&quot;: 0
        },
        &quot;end&quot;: {
          &quot;offset&quot;: 169,
          &quot;timestamp&quot;: 1604851366230,
          &quot;observedAt&quot;: 1604851366000,
          &quot;lag&quot;: 0
        },
        &quot;current_lag&quot;: 0,
        &quot;complete&quot;: 1
      }
    ],
    &quot;partition_count&quot;: 3,
    &quot;maxlag&quot;: {
      &quot;topic&quot;: &quot;burrow-topic&quot;,
      &quot;partition&quot;: 0,
      &quot;owner&quot;: &quot;/192.168.15.100&quot;,
      &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
      &quot;status&quot;: &quot;OK&quot;,
      &quot;start&quot;: {
        &quot;offset&quot;: 47,
        &quot;timestamp&quot;: 1604851356381,
        &quot;observedAt&quot;: 1604851356000,
        &quot;lag&quot;: 0
      },
      &quot;end&quot;: {
        &quot;offset&quot;: 56,
        &quot;timestamp&quot;: 1604851365429,
        &quot;observedAt&quot;: 1604851365000,
        &quot;lag&quot;: 0
      },
      &quot;current_lag&quot;: 0,
      &quot;complete&quot;: 1
    },
    &quot;totallag&quot;: 0
  },
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/consumer/burrow-group/lag&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Fin del laboratorio</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_seguridad_en_kafka">16. Seguridad en Kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>Kafka</strong> ofrece distintas opciones de seguridad, son bastante interesantes si queremos aplicarlas a nuestro clúster.</p>
</li>
<li>
<p>Las distintas funcionalidades que podemos tener son:</p>
<div class="ulist">
<ul>
<li>
<p>Autenticación mediante <strong>SSL</strong></p>
</li>
<li>
<p>Autenticación de conexiones entre los <strong>Brokers</strong> y <strong>Zookeeper</strong></p>
</li>
<li>
<p>Autorización de lecturas y/o escrituras para los clientes</p>
</li>
<li>
<p>Soporte de servicios externos de autenticación</p>
</li>
<li>
<p>Cifrado de los datos mediante <strong>SSL</strong> para la comunicación.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_cómo_funciona_la_seguridad">16.1. Cómo funciona la seguridad</h3>
<div class="ulist">
<ul>
<li>
<p>La seguridad en las comunicaciones es algo vital.</p>
</li>
<li>
<p>Los primeros ejemplos documentados de comunicación cifrada, datan de la época del Imperio Romano, donde Julio César usaba un método simple para comunicarse con sus generales, desplazaban 13 veces en el alfabeto la letra leída, de tal manera que el mensaje "Ataquen" se convertía en "MFMCGQZ".</p>
</li>
<li>
<p>Cuando los generales recibían el mensaje realizaban la operación inversa (es decir, se movían 13 veces en el alfabeto en sentido inverso).</p>
</li>
<li>
<p>Este es un ejemplo de <strong>cifrado con clave simétrica</strong>, en el que para cifrar y descifrar el mensaje, hacemos uso de una misma clave.</p>
</li>
<li>
<p>De hecho, las claves simétricas eran la única opción que conocíamos hasta hace relativamente poco.</p>
</li>
<li>
<p>Un ejemplo claro de esto fue la máquina enigma, utilizada durante la segunda guerra mundial.</p>
</li>
<li>
<p>De forma esquemática, podríamos decir que el proceso es como se muestra en la imagen:</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-seguridad-01.png" alt="kafka seguridad 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A día de hoy seguimos contando con cifrados de clave simétrica, como AES, DES, TripleDES o Blowfish.</p>
<div class="ulist">
<ul>
<li>
<p>Su gran ventaja, son algoritmos muy veloces, ideales para el cifrado de gran cantidad de datos.</p>
</li>
<li>
<p>Su gran inconveniente, las dos partes deben poseer la clave, lo que supone un riesgo a la seguridad, ya que esta clave debe ser distribuida y en este momento podría ser interceptada y robada, compromentiendo la seguridad.  (¿Os acordáis de las típicas películas de espías, que iban con un maletín esposado?)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-seguridad-02.jpg" alt="kafka seguridad 02" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Frente a la criptografía de clave simétrica, tenemos la <strong>criptografía de clave asimétrica</strong>. Dicha técnica de cifrado no consiste en una única clave, si no en una pareja de ellas:</p>
<div class="ulist">
<ul>
<li>
<p>Clave privada, que jamás es distribuida, y cuyo propietario debe custodiar.</p>
</li>
<li>
<p>Clave pública, conocida por todos los usuarios y distribuida sin problemas.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Este sistema es mucho mas seguro, ya que suprime la necesidad del envío de una clave que da poder total y absoluto. (!Se acabaron los espías con maletines!)</p>
</li>
<li>
<p>Por otro lado, tiene un importante inconveniente, es mucho más lento (la operación es más compleja).</p>
</li>
<li>
<p>Para generar la pareja de claves se debe:</p>
<div class="ulist">
<ul>
<li>
<p>Escoger dos números primos, <strong>p</strong> y <strong>q</strong></p>
</li>
<li>
<p>Calcular <strong>N</strong>, que es el resultado de multpilicar <strong>p x q</strong>.</p>
</li>
<li>
<p>Escoger un número <strong>e</strong>, que debe ser primo a <strong>(p-1) x (q-1)</strong> (que no tengan divisores comunes entre ellos)</p>
</li>
<li>
<p>Calcular un número <strong>d</strong>, que es el número que cumple que <strong>(e x d) mod  p-1) x (q-1 = 1</strong></p>
</li>
<li>
<p>La clave pública es <strong>(N,e)</strong></p>
</li>
<li>
<p>La clave privada es <strong>(d)</strong></p>
</li>
<li>
<p>La información <strong>I</strong> se cifra con <strong>I^e mod N</strong></p>
</li>
<li>
<p>La información cifrada <strong>C</strong> se descifra con <strong>C^d mod N</strong></p>
</li>
</ul>
</div>
</li>
<li>
<p>Un ejemplo sería el siguiente</p>
<div class="ulist">
<ul>
<li>
<p>Escojo <strong>p=3</strong> y <strong>q=7</strong>, ambos números primos</p>
</li>
<li>
<p>Calculo <strong>N=3 x 7=21</strong></p>
</li>
<li>
<p>Busco número primo relativo a <strong>(p-1) x (q-1)=2 x 6=12</strong>, cojo <strong>e=5</strong> que es primo relativo a <strong>12</strong></p>
</li>
<li>
<p>Busco <strong>d</strong> en <strong>(e x d) mod  p-1) x (q-1 = 1</strong>, nos sale <strong>d=5</strong> (ya que <strong>25 mod 12 = 1</strong></p>
</li>
<li>
<p>Clave pública <strong>(N,e)</strong> es <strong>(21,5)</strong></p>
</li>
<li>
<p>Clave privada <strong>d</strong> es <strong>5</strong></p>
</li>
<li>
<p>Voy a cifrar un <strong>M</strong> que vale 4: <strong>C=M^e mod N</strong> que es <strong>4^5 mod 21 = 1024 mod 21=16</strong></p>
</li>
<li>
<p>Voy a descifrar <strong>C</strong> que es <strong>16</strong>: <strong>D=C^d mod N</strong> que es <strong>16^5 mod 21 = 1048576 mod 21 = 4</strong></p>
</li>
</ul>
</div>
</li>
<li>
<p>Ahora que entendemos cómo se generan las claves de cifrado asimétricas, vamos qué opciones tenemos para comunicar dos partes:</p>
<div class="ulist">
<ul>
<li>
<p>Una de las partes (A), posee una pareja de claves pública/privada.</p>
</li>
<li>
<p>La otra parte (B), no posee ninguna:</p>
</li>
<li>
<p><strong>A</strong> puede usar su clave privada para cifrar la información y enviarla a <strong>B</strong>.</p>
</li>
<li>
<p>Cualquiera puede usar la clave pública de <strong>A</strong> para abrir el mensaje, con lo que no existe confidencialidad, pero <strong>B</strong> se asegura de que el mensaje fue emitido por <strong>A</strong>, puesto que tuvo que cifrarlo con su clave privada. <strong>* Existe *autenticidad</strong> de emisor.</p>
</li>
<li>
<p><strong>B</strong> puede cifrar mensajes con la clave pública de <strong>A</strong> y enviárselos a <strong>A</strong>.</p>
</li>
<li>
<p>Nadie más puede ver este mensaje, por lo que aseguras la <strong>confidencialidad</strong>, ya que para descifrarlo sólo puede usarse la clave privada de <strong>A</strong>.</p>
</li>
<li>
<p>Sin embargo, cualquier emisor podría suplantar a <strong>B</strong> (tan sólo tiene que usar la clave pública de <strong>A</strong>), <strong>A</strong> no tiene la certeza de que su mensaje provenga de <strong>B</strong>.</p>
</li>
<li>
<p>Las dos partes tienen una pareja de claves pública/privada:</p>
</li>
<li>
<p>Ahora, podemos asegurar la <strong>confidencialidad</strong> y el <strong>autenticidad</strong>.</p>
</li>
<li>
<p>Cuando se van a intercambiar mensajes, se cifran dos veces.</p>
</li>
<li>
<p>Si <strong>A</strong> quiere enviar un mensaje a <strong>B</strong>, lo cifra primero con su clave privada, y luego con la clave pública de <strong>B</strong>.</p>
</li>
<li>
<p>Para que <strong>B</strong> lo pueda descifrar usa primero la clave pública de <strong>A</strong> (aseguramos emisor), y luego su propia clave privada (aseguramos confidencialidad).</p>
</li>
<li>
<p>De manera análoga, <strong>B</strong> puede enviar mensajes a <strong>A</strong> cifrandolos primero con su clave privada y luego con la clave pública de <strong>A</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Esto, es tremendamente costoso, con lo que por lo general, se usa esta comunicación para intercambiar de forma segura una clave simétrica, y tras intercambiar esta clave, el resto de la comunicación se cifra mediante ella.</p>
</li>
<li>
<p>Al intercambiar la clave como hemos dicho, nos aseguramos que nadie nos la intercepte.</p>
</li>
<li>
<p>Un ejemplo de una comunicación usando sólo una pareja de claves.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-seguridad-03.png" alt="kafka seguridad 03" width="600">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_certificados_keystores_y_trustores">16.2. Certificados, Keystores y Trustores</h3>
<div class="ulist">
<ul>
<li>
<p>En el tema anterior vimos qué eran las claves de cifrado, y cómo estaban compuestas de dos partes, la clave pública y la clave privada.</p>
</li>
<li>
<p>Con la intención de almacenar las claves privadas propias, y las claves públicas de otros, surge el <strong>keystore</strong>.</p>
</li>
<li>
<p>Este no es nada más que un almacén de claves.</p>
</li>
<li>
<p>Un fichero de nuestro disco que va a contener un conjunto de claves.</p>
</li>
<li>
<p>Llegados a este punto, podíamos asegurarnos de que la comunicación con otro sistema era segura, pero ¿quién nos certifica que quien está usando unas claves, es quien dice ser?.</p>
<div class="ulist">
<ul>
<li>
<p>Por ejemplo, yo me conecto a la web de la <strong>AEAT</strong>, y voy a hacer mi declaración.</p>
</li>
<li>
<p>Si un tercero lo suplantar y tuviera su propio conjunto de claves, ¿habría manera de saber si mi comunicación segura es realmente con dicho dominio, o no?</p>
</li>
<li>
<p>Para cubrir este supuesto surgen los <strong>certificados</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Un <strong>certificado</strong> es una pareja de claves (pública/privada) cuya parte pública ha sido <strong>firmada</strong> por una <strong>entidad certificadora</strong>, es decir, se han asegurado de que el dueño de dicho certificado es quien dice ser.</p>
</li>
<li>
<p>Ahora si nos roban nuestro dominio y nos intentan suplantar, podran tener comunicación segura pero les saltará una advertencia, de que no han podido comprobar la autenticidad de dicho dominio.</p>
</li>
<li>
<p>Pero <strong>who watches the watchmen?</strong>. ¿quién me asegura que la <strong>entidad certificadora</strong> ha hecho su trabajo?.</p>
</li>
<li>
<p>Existen varias entidades certificadoras, nosotros podemos decidir en cuál confiar y en cuál no.</p>
</li>
<li>
<p>Para aquellas entidades en las que confiemos, guardaremos su clave pública de cifrado en nuestro <strong>Trustore</strong>, que es otro almacén, donde almaceno sólo aquellas entidades en las que confío.</p>
</li>
<li>
<p>Ahora, si me comunico con un nuevo sistema, puedo confiar en quién dice ser porque posee una firma que puedo comprobar.</p>
</li>
<li>
<p>Brevemente, para conseguir un certificado digital, necesitamos:</p>
<div class="ulist">
<ul>
<li>
<p>Generar una pareja de claves pública/privada</p>
</li>
<li>
<p>Emitir una petición de firmado de certificado (que basicamente es la clave pública)</p>
</li>
<li>
<p>Enviar dicha petición a la entidad certificadora</p>
</li>
<li>
<p>La entidad verificadora se asegurará de que eres quien dices ser (nombres, direcciones, se pondrá en contacto, etc&#8230;&#8203;)</p>
</li>
<li>
<p>La entidad certificadora firma el certificado, y nos lo devuelve</p>
</li>
<li>
<p>Ya puedo comunicarme sin problemas con todos los demás sistemas que confíen en dicha entidad certificadora.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_seguridad_en_clientes">16.3. Seguridad en clientes</h3>
<div class="ulist">
<ul>
<li>
<p>La implementación de seguridad en productores y consumidores se realiza a partir del certificado cliente.</p>
</li>
<li>
<p>Este certificado cliente de confianza generado con los certificados del servidor permite autenticar y autorizar un cliente</p>
</li>
<li>
<p>La configuración que se debe definir es la siguiente:</p>
</li>
<li>
<p>Primero definimos el protocolo SSL como activo</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">security.protocol</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">SSL</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.truststore.location</span><span class="delimiter">&quot;</span></span>, trustStoreLocation);
props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.truststore.password</span><span class="delimiter">&quot;</span></span>, trustStorePassword);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si no está habilitada la autenticación de clientes, esta segunda parte no es necesaria.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.key.password</span><span class="delimiter">&quot;</span></span>, keyStorePassword);
props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.keystore.password</span><span class="delimiter">&quot;</span></span>, keyStorePassword);
props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.keystore.location</span><span class="delimiter">&quot;</span></span>, keyStoreLocation);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Otras opciones que podemos configurar:</p>
<div class="ulist">
<ul>
<li>
<p><strong>ssl.provider</strong>: El nombre del proveedor de seguridad usado para conexiones SSL</p>
</li>
<li>
<p><strong>ssl.cipher.suites</strong>: Un conjunto de cifrados usados para negociación</p>
</li>
<li>
<p><strong>ssl.enabled.protocols</strong>: Debe poseer alguno de los protocolos del broker (TLSv1.2,TLSv1.1,TLSv1)</p>
</li>
<li>
<p><strong>ssl.truststore.type</strong>: JKS</p>
</li>
<li>
<p><strong>ssl.keystore.type</strong>: JKS</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_sasl">16.3.1. SASL</h4>
<div class="ulist">
<ul>
<li>
<p>Kafka usa JAAS (Java Authentication and Authorization Service) para configurar SASL</p>
</li>
<li>
<p>Para configurar JAAS, debemos generar un fichero estático</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Contenido del fichero /etc/kafka/kafka_client_jaas.conf</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json"><span class="error">K</span><span class="error">a</span><span class="error">f</span><span class="error">k</span><span class="error">a</span><span class="error">C</span><span class="error">l</span><span class="error">i</span><span class="error">e</span><span class="error">n</span><span class="error">t</span> {
    <span class="error">c</span><span class="error">o</span><span class="error">m</span><span class="error">.</span><span class="error">s</span><span class="error">u</span><span class="error">n</span><span class="error">.</span><span class="error">s</span><span class="error">e</span><span class="error">c</span><span class="error">u</span><span class="error">r</span><span class="error">i</span><span class="error">t</span><span class="error">y</span><span class="error">.</span><span class="error">a</span><span class="error">u</span><span class="error">t</span><span class="error">h</span><span class="error">.</span><span class="error">m</span><span class="error">o</span><span class="error">d</span><span class="error">u</span><span class="error">l</span><span class="error">e</span><span class="error">.</span><span class="error">K</span><span class="error">r</span><span class="error">b</span><span class="integer">5</span><span class="error">L</span><span class="error">o</span><span class="error">g</span><span class="error">i</span><span class="error">n</span><span class="error">M</span><span class="error">o</span><span class="error">d</span><span class="error">u</span><span class="error">l</span><span class="error">e</span> <span class="error">r</span><span class="error">e</span><span class="error">q</span><span class="error">u</span><span class="error">i</span><span class="error">r</span><span class="error">e</span><span class="error">d</span>
    <span class="error">u</span><span class="error">s</span><span class="error">e</span><span class="error">K</span><span class="error">e</span><span class="error">y</span><span class="error">T</span><span class="error">a</span><span class="error">b</span><span class="error">=</span><span class="value">true</span>
    <span class="error">s</span><span class="error">t</span><span class="error">o</span><span class="error">r</span><span class="error">e</span><span class="error">K</span><span class="error">e</span><span class="error">y</span><span class="error">=</span><span class="value">true</span>
    <span class="error">k</span><span class="error">e</span><span class="error">y</span><span class="error">T</span><span class="error">a</span><span class="error">b</span><span class="error">=</span><span class="string"><span class="delimiter">&quot;</span><span class="content">/etc/security/keytabs/kafka_client.keytab</span><span class="delimiter">&quot;</span></span>
    <span class="error">p</span><span class="error">r</span><span class="error">i</span><span class="error">n</span><span class="error">c</span><span class="error">i</span><span class="error">p</span><span class="error">a</span><span class="error">l</span><span class="error">=</span><span class="string"><span class="delimiter">&quot;</span><span class="content">kafka-client@kafka.local</span><span class="delimiter">&quot;</span></span><span class="error">;</span>
}<span class="error">;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para poder cargar JAAS, en la ejecución de java, debemos indicar la siguiente directiva:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json"> <span class="error">-</span><span class="error">D</span><span class="error">j</span><span class="error">a</span><span class="error">v</span><span class="error">a</span><span class="error">.</span><span class="error">s</span><span class="error">e</span><span class="error">c</span><span class="error">u</span><span class="error">r</span><span class="error">i</span><span class="error">t</span><span class="error">y</span><span class="error">.</span><span class="error">a</span><span class="error">u</span><span class="error">t</span><span class="error">h</span><span class="error">.</span><span class="error">l</span><span class="error">o</span><span class="error">g</span><span class="error">i</span><span class="error">n</span><span class="error">.</span><span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">f</span><span class="error">i</span><span class="error">g</span><span class="error">=</span><span class="error">/</span><span class="error">e</span><span class="error">t</span><span class="error">c</span><span class="error">/</span><span class="error">k</span><span class="error">a</span><span class="error">f</span><span class="error">k</span><span class="error">a</span><span class="error">/</span><span class="error">k</span><span class="error">a</span><span class="error">f</span><span class="error">k</span><span class="error">a</span><span class="error">_</span><span class="error">c</span><span class="error">l</span><span class="error">i</span><span class="error">e</span><span class="error">n</span><span class="error">t</span><span class="error">_</span><span class="error">j</span><span class="error">a</span><span class="error">a</span><span class="error">s</span><span class="error">.</span><span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">f</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_autenticación_sasl">16.4. Autenticación SASL</h3>
<div class="ulist">
<ul>
<li>
<p>Como método adicional, poseemos la opción de aplicar SASL</p>
<div class="ulist">
<ul>
<li>
<p>Simple Authentication Service Layer</p>
</li>
</ul>
</div>
</li>
<li>
<p>Permite separar el mecanismo de autenticación del protocolo de Kafka.</p>
</li>
<li>
<p>Posee múltiples formas de configuración:</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_sasl_plaintext">16.4.1. SASL PLAINTEXT</h4>
<div class="ulist">
<ul>
<li>
<p>Permite definir usuario/password</p>
</li>
<li>
<p>Esta información se almacena en los brokers.</p>
</li>
<li>
<p>Cada modificación de este sistema necesita un reinicio de los brokers para.</p>
</li>
<li>
<p>No se recomienda para entornos productivos</p>
</li>
<li>
<p>Se debe definir también la capa SSL para evitar enviar los datos en plano por el protocolo http.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_sasl_scram">16.4.2. SASL SCRAM</h4>
<div class="ulist">
<ul>
<li>
<p>Permite usar username/password pero con encriptación de usuario.</p>
</li>
<li>
<p>Los datos se almacenan en Zookeeper, lo que permite escalar la autenticación</p>
</li>
<li>
<p>No es necesario su reinicio</p>
</li>
<li>
<p>Se debe unir junto a SSL para evitar enviar datos en plano</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_sasl_gssapi_kerberos">16.4.3. SASL GSSAPI (Kerberos)</h4>
<div class="ulist">
<ul>
<li>
<p>Permite usar el mecanismo de kerberos basado en tickets</p>
</li>
<li>
<p>Microsoft Active Directory es el mas común</p>
</li>
<li>
<p>Permite gestionar la seguridad desde un servidor kerberos</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_autorización">16.5. Autorización</h3>
<div class="ulist">
<ul>
<li>
<p>Tras la encriptación del canal y la autenticación, toca autorizar</p>
</li>
<li>
<p>Está controlado por las listas de control de acceso o ACLs</p>
</li>
<li>
<p>Permite</p>
<div class="ulist">
<ul>
<li>
<p><strong>Usuario</strong> A <strong>pueda/o no</strong> hacer la <strong>Operación</strong> B en el <strong>Host</strong> C en cualquier <strong>recurso</strong> D que cumpla el <strong>patrón</strong> E</p>
</li>
</ul>
</div>
</li>
<li>
<p>No está creado para agrupar reglas o aplicar REGEX para aplicación de reglas.</p>
</li>
<li>
<p>Cada regla de seguridad debe ser completamente escrita.</p>
</li>
<li>
<p>Admite wildcards</p>
</li>
<li>
<p>Permite que un topic sea escrito solo por un conjunto de clientes concreto y que sea leido por otro grupo concreto.</p>
</li>
<li>
<p>Podemos usar el comando kafka-acl.sh para gestionar productores y consumidores:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ kafka-acl.sh --topic acl-test --producer --authorizer-properties zookeeper.connect=kafka-server.local --add --allow-principal User:alumno</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si usamos el SimpleACLAuthorizer, los datos se guardarán en zookeeper.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>authorizer.class.name=kafka.security.authorizer.SimpleAclAuthorizer</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si no existe regla que gestione al usuario y al recurso, por defecto deniega el servicio</p>
</li>
<li>
<p>Se puede cambiar el comportamiento usando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>allow.everyone.if.no.acl.found=true</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos crear la lista de superusuarios desde el server.properties</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>super.users=User:alumno;User:profesor</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_operaciones">16.5.1. Operaciones</h4>
<div class="ulist">
<ul>
<li>
<p>Las operaciones disponibles son:</p>
<div class="ulist">
<ul>
<li>
<p>Read</p>
</li>
<li>
<p>Write</p>
</li>
<li>
<p>Create</p>
</li>
<li>
<p>Delete</p>
</li>
<li>
<p>Alter</p>
</li>
<li>
<p>Describe</p>
</li>
<li>
<p>ClusterAction</p>
</li>
<li>
<p>DescribeConfigs</p>
</li>
<li>
<p>AlterConfigs</p>
</li>
<li>
<p>IdempotentWrite</p>
</li>
<li>
<p>All</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_recursos">16.5.2. Recursos</h4>
<div class="ulist">
<ul>
<li>
<p>Los recursos disponibles son:</p>
<div class="ulist">
<ul>
<li>
<p>Topic: Incluye todas las operaciones contra un Topic</p>
</li>
<li>
<p>Group: Indica los grupos de consumidores en el broker</p>
</li>
<li>
<p>Cluster: Operaciones como apagado del servicio</p>
</li>
<li>
<p>TransactionalId: Implica acciones de transacciones como las confirmaciones (commit)</p>
</li>
<li>
<p>DelegationToken: Representa los tokens de delegación en el cluster.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_aplicando_seguridad_en_kafka">16.6. Lab: Aplicando seguridad en Kafka</h3>
<div class="ulist">
<ul>
<li>
<p>Para poder tener una comunicación segura con nuestro <strong>brokers</strong>, vamos a cifrar la comunicación mediante el uso de claves de cifrado asimétricas.</p>
</li>
<li>
<p>Para ello tendremos que crear</p>
<div class="ulist">
<ul>
<li>
<p>Una pareja de claves pública/privada, que tendremos en nuestro <strong>keystore</strong></p>
</li>
<li>
<p>Una entidad certificadora, que deberemos añadir a nuestro <strong>trustore</strong></p>
</li>
<li>
<p>Un certificado firmado (por nuestra entidad certificadora)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para ello, usaremos la herramienta <strong>keytool</strong> que viene disponible en el propio <strong>JDK</strong>.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_creación_del_keystore_y_la_pareja_de_claves_públicaprivada">16.6.1. Creación del keystore y la pareja de claves pública/privada</h4>
<div class="paragraph">
<p>Llamaremos a <strong>keytool</strong> (desde nuestro $HOME), indicando dónde va a crear ese <strong>keystore</strong>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Indicaremos que genere una clave con <strong>-genkey</strong>, y hemos especificado la validez de dicha clave (360 días).</p>
</li>
<li>
<p>El <strong>alias</strong> con el que almacenaremos esta clave en nuestro <strong>keystore</strong> es <strong>kafkakafka</strong></p>
</li>
<li>
<p>Al ejecutar dicho comando, nos van a pedir distintos datos, (para nuestro ejemplo usaremos la clave <strong>usuario</strong>)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore server.keystore.jks -alias kafka -keyalg RSA -validity 360 -genkey
Enter keystore password:
Re-enter new password:
What is your first and last name?
  [Unknown]:  Curso Kafka
What is the name of your organizational unit?
  [Unknown]:  N/A
What is the name of your organization?
  [Unknown]:  Curso
What is the name of your City or Locality?
  [Unknown]:  Madrid
What is the name of your State or Province?
  [Unknown]:  Madrid
What is the two-letter country code for this unit?
  [Unknown]:  ES
Is CN=Curso Kafka, OU=N/A, O=Curso, L=Madrid, ST=Madrid, C=ES correct?
  [no]:  yes</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al acabar, veremos que hay un fichero <strong>server.keystore.jks</strong> en la ruta en la que hemos ejecutado nuestro comando.</p>
</li>
<li>
<p>Siempre podemos consultar la información de nuestro <strong>keystore</strong> (siempre que tengamos su clave, claro) con el siguiente comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -list -v -keystore server.keystore.jks</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Desde la versión de JDK 8.51 a veces tiene problemas con los idiomas, si da error al ejecutarlo, probad a añadirle <strong>-J-Duser.language=en</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -J-Duser.language=en -list -v -keystore server.keystore.jks</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear ahora nuestro entidad certificadora, y para ello vamos a usar <strong>openssl</strong>.</p>
</li>
<li>
<p>Generaremos tanto la clave privada (que llamaremos ca-key) como la parte pública (que llamaremos ca-cert):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ openssl req -new -x509 -keyout ca-key -out ca-cert -days 365</code></pre>
</div>
</div>
<div class="paragraph">
<p>Al igual que cuando generamos nuestro <strong>keystore</strong>, nos solicitará cierta información (y vuelvo a usar <strong>usuario</strong> como clave)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Generating a 2048 bit RSA private key
............+++
...........+++
writing new private key to 'ca-key'
Enter PEM pass phrase:
Verifying - Enter PEM pass phrase:
[...]
Country Name (2 letter code) [XX]:ES
State or Province Name (full name) []:Madrid
Locality Name (eg, city) [Default City]:Madrid
Organization Name (eg, company) [Default Company Ltd]:Entidad Certificadora
Organizational Unit Name (eg, section) []:NA
Common Name (eg, your name or your server's hostname) []:
Email Address []:</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bien, tenemos nuestro <strong>keystore</strong>, tenemos una <strong>entidad certificadora</strong>.</p>
</li>
<li>
<p>Vamos a decir que confiamos en dicha entidad añadiendo su clave pública a nuestro <strong>trustore</strong> (que todavía no existe, lo crearemos con el nombre de <strong>server.trustore.jks</strong>).</p>
</li>
<li>
<p>Recordemos, si estamos con Java 8, mejor especificar el idioma con <strong>-J-Duser.language=en</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% keytool -keystore server.truststore.jks -alias EntidadNoFake -import -file ca-cert</code></pre>
</div>
</div>
<div class="paragraph">
<p>Una vez hecho esto, podemos confirmar que el certificado está disponible con <strong>-list</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -J-Duser.language=en -list -v -keystore server.truststore.jks</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ya tenemos un <strong>keystore</strong> y un <strong>trustore</strong>, en sus respectivos ficheros.</p>
</li>
<li>
<p>Generamos una petición de certificación para nuestra clave almacenada con el <strong>alias</strong> de <strong>kafka</strong>, es decir, vamos a generar un fichero que contiene nuestra clave pública y nuestros datos para enviar a una <strong>entidad certificadora</strong>, y que nos lo devuelva firmado, corroborando que dicha información es correcta. Para ello usaremos la opción <strong>-certreq</strong>, que nos generará un fichero para firmar (especificado en <strong>-file</strong>).</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore server.keystore.jks -alias kafka -certreq -file cert-file</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras introducir la clave de nuestro <strong>keystore</strong>, generamos el fichero <strong>cert-file</strong> que hemos solicitado, con lo que ya podemos realizar el firmado de nuestra clave.</p>
</li>
<li>
<p>Bueno, ahora vamos a usar <strong>openssl</strong> para firmar la petición de certificación que hemos creado en el punto anterior:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file -out cert-signed -days 360 -CAcreateserial -passin pass:usuario</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>-CA &#8594; La clave privada de la entidad certificadora</p>
</li>
<li>
<p>-in &#8594; fichero sobre el que vamos a realizar el firmado</p>
</li>
<li>
<p>-out &#8594; Fichero destino</p>
</li>
<li>
<p>Al acabar, tendremos en <strong>cert-signed</strong> nuestro certificado, ahora si, firmado.</p>
</li>
<li>
<p>Por último, vamos a importar el certificado generado y la clave pública de la entidad certificadora a nuestro <strong>keystore</strong> (acordaros del <strong>-J-Duser.language=en</strong> si usáis Java 8):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore server.keystore.jks -alias EntidadNoFake -import -file ca-cert
[kafka@kafka-server ~]$ keytool -keystore server.keystore.jks -alias kafka -import -file cert-signed</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si listáis ahora con la siguiente instrucción, veréis que tenéis dos entradas, y dentro de <strong>kafka</strong> figuran los datos de la entidad certificadora que nos ha firmado.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -list -v -keystore server.keystore.jks</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_securizando_los_brokers">16.6.2. Securizando los Brokers</h4>
<div class="ulist">
<ul>
<li>
<p>En primer lugar, tenemos que editar los ficheros de configuración de nuestros <strong>brokers</strong>, y cambiar la propiedad <strong>listeners</strong>, donde especificaremos cómo vamos a escuchar.</p>
</li>
<li>
<p>Antes teníamos algo como:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=PLAINTEXT://kafka-server.local:9092</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora tendremos algo como:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-server.local:9102</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Podríamos configurar para escuchar de las dos formas, en distintos puertos, podríamos hacer algo como:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-server.local:9102,PLAINTEXT://kafka-server.local:9092</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Modificaremos los 3 ficheros y cambiaremos los listeners por <strong>SSL</strong>, dejándolos así:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">kafka-server.local</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-server.local:9102</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">kafka-node1.local</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-node1.local:9102</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">kafka-node2.local</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-node2.local:9102</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hemos pedido que sólo se puedan comunicar vía <strong>SSL</strong>, pero ¿cómo saben dónde está su <strong>keystore</strong>? ¿y su <strong>trustore</strong>?.</p>
</li>
<li>
<p>Tenemos que especificarlo, así que tendremos que añadir a cada fichero las siguientes configuraciones:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">ssl.keystore.location=/home/kafka/server.keystore.jks
ssl.keystore.password=usuario
ssl.key.password=usuario
ssl.truststore.location=/home/kafka/server.truststore.jks
ssl.truststore.password=usuario
security.inter.broker.protocol=SSL
ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Iniciamos los tres <strong>Brokers</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ sudo systemctl restart kafka
[kafka@kafka-server ~]$ sudo systemctl -H kafka-node1.local restart kafka
[kafka@kafka-server ~]$ sudo systemctl -H kafka-node2.local restart kafka</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Recomendamos hacerlo de uno en uno, y vigilar las trazas con:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ tail -f $KAFKA_HOME/logs/kafkaServer.out</code></pre>
</div>
</div>
<div class="paragraph">
<p>Podemos verificar que está escuchando mediante <strong>SSL</strong> con el siguiente comando:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ openssl s_client -debug -connect kafka-server.local:9102 -tls1
CONNECTED(00000003)
write to 0x2683900 [0x269d383] (181 bytes =&gt; 181 (0xB5))
0000 - 16 03 01 00 b0 01 00 00-ac 03 01 a9 ad 97 c1 1f   ................
0010 - 4b 1c 3c b0 84 95 cd 68-67 b8 de ca d6 b0 e2 63   K.&lt;....hg......c
0020 - d8 f4 17 f8 de 9f 22 44-e9 2b bd 00 00 64 c0 14   ......&quot;D.+...d..
0030 - c0 0a 00 39 00 38 00 37-00 36 00 88 00 87 00 86   ...9.8.7.6......
0040 - 00 85 c0 0f c0 05 00 35-00 84 c0 13 c0 09 00 33   .......5.......3
0050 - 00 32 00 31 00 30 00 9a-00 99 00 98 00 97 00 45   .2.1.0.........E
0060 - 00 44 00 43 00 42 c0 0e-c0 04 00 2f 00 96 00 41   .D.C.B...../...A
0070 - c0 12 c0 08 00 16 00 13-00 10 00 0d c0 0d c0 03   ................
0080 - 00 0a 00 07 c0 11 c0 07-c0 0c c0 02 00 05 00 04   ................
0090 - 00 ff 01 00 00 1f 00 0b-00 04 03 00 01 02 00 0a   ................
00a0 - 00 0a 00 08 00 17 00 19-00 18 00 16 00 23 00 00   .............#..
00b0 - 00 0f 00 01 01
...</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_securizando_los_clientes">16.6.3. Securizando los Clientes</h4>
<div class="paragraph">
<p>Si queremos que nuestros clientes puedan conectarse mediante <strong>SSL</strong> a nuestros <strong>Brokers</strong>, tenemos que dar de alta la entidad certificadora en su propio <strong>keystore</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore client.truststore.jks -alias EntidadNoFake -import -file ca-cert</code></pre>
</div>
</div>
<div class="paragraph">
<p>Y en su fichero <strong>properties</strong>, tenemos que añadir las siguientes opciones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">security.protocol=SSL
ssl.truststore.location=client.truststore.jks
ssl.truststore.password=usuario
ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a hacer esto mismo con el productor y consumidor de consola.</p>
</li>
<li>
<p>Copiamos los ficheros <strong>$KAFKA_HOME/config/consumer.properties</strong> y <strong>$KAFKA_HOME/config/producer.properties</strong> a producer-ssl.properties y consumer-ssl.properties agregando la siguiente configuración:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">security.protocol=SSL
ssl.truststore.location=/home/kafka/client.truststore.jks
ssl.truststore.password=usuario
ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un <strong>Topic</strong> sobre el que hacer las pruebas:</p>
</li>
<li>
<p>Para ello creamos un fichero llamado ssl.properties con la misma configuración que los clientes</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">security.protocol=SSL
ssl.truststore.location=/home/kafka/client.truststore.jks
ssl.truststore.password=usuario
ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lanzamos la petición</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Aunque de warning el uso del fichero ssl indicando que las directivas no aplican, si están aplicando y son necesarias ya que sino no es capaz de conectar al servicio.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9102 --create --topic topic-seguro --partitions 5 --replication-factor 1 --command-config ssl.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y lanzamos nuestro productor:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-node1:9102 --topic topic-seguro --property parse.key=true --property key.separator=, --producer.config $KAFKA_HOME/config/producer-ssl.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lanzamos nuestro consumidor, y verificamos que todo marcha como esperábamos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-node2:9102 --topic topic-seguro --property print.key=true --consumer.config $KAFKA_HOME/config/consumer-ssl.properties --from-beginning</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_autenticar_clientes">16.6.4. Autenticar clientes</h4>
<div class="ulist">
<ul>
<li>
<p>Si os veis en la necesidad de autenticar clientes contra el broker, vamos a dejar escrito los pasos que se deberían dar:</p>
<div class="ulist">
<ul>
<li>
<p>Habitilar la opción <strong>ssl.client.auth=required</strong> en el <strong>server.properties</strong> de los <strong>brokers</strong></p>
</li>
<li>
<p>Generar un certificado para cada cliente, y firmarlo mediante la entidad certificadora</p>
</li>
<li>
<p>Importar el certificado del cliente firmado en el <strong>trustore</strong> de cada <strong>broker</strong></p>
</li>
</ul>
</div>
</li>
<li>
<p>Añadir <strong>ssl.client.auth=required</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ echo &quot;ssl.client.auth=required&quot; &gt;&gt; $KAFKA_HOME/config/server.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Generar y firmar certificados</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore client.keystore.jks -alias kafka -keyalg RSA -certreq -file cert-file-client
[kafka@kafka-server ~]$ openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file-client -out cert-signed-client -days 360 -CAcreateserial -passin pass:usuario</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Añadir al <strong>trustore</strong> del servidor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore server.truststore.jks -alias localhost -import -file cert-signed-client</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez hecho esto, bastaría con reiniciar los <strong>brokers</strong>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2021-02-16 16:24:51 +0100
</div>
</div>
<style>
/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid currentColor;opacity:.35;padding:0 .5em 0 0}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
</body>
</html>